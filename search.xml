<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Concurrent并发包入门(二)之BlockingQueue]]></title>
    <url>%2F2018%2F10%2F15%2Fconcurrent%E5%B9%B6%E5%8F%91%E5%8C%85%E5%85%A5%E9%97%A8(%E4%BA%8C)%2F</url>
    <content type="text"><![CDATA[concurrent并发包入门(二)之BlockingQueue[TOC] 1.BlockingQueue 阻塞队列 数组阻塞队列 ArrayBlockingQueue 延迟队列 DelayQueue 链阻塞队列 LinkedBlockingQueue 具有优先级的阻塞队列 PriorityBlockingQueue 同步队列 SynchronousQueue 阻塞双端队列 BlockingDeque 链阻塞双端队列 LinkedBlockingDeque 2.并发包使用BlockingQueue(接口) 阻塞队列 场景:BlockingQueue通常用于一个线程生产对象,另一个线程消费对象(生产者与消费者模式) 处理数据比较消耗时间，线程独占，生产数据不需要即时的反馈等 一个线程负责生产对象,将新生产的对象插入队列中,队列是有限的,到达队列临界点后,新生产的对象会处于阻塞状态中,直到队列有对象被消耗 一个线程负责消费对象,将队列中的对象按照顺序消费,直到队列中没有对象,则消费者处于阻塞状态,直到队列中被插入新的对象 方法 ~ 抛异常 特定值 阻塞 超时 插入 add(o) offer(o) put(o) offer(o,timeout,timeUnit) 移除 remove(o)指定 poll(o)头部 take(o)头部 poll(timeout,timeunit) 检查 element(o) peek(o) ~ ~ 抛异常:如果试图的操作无法立即执行,则该方法抛出一个异常 特定值:如果试图的操作无法立即执行,则该方法返回一个特定值(一般true/false) 阻塞:如果试图的操作无法立即执行,则该方法产生阻塞,直到能执行 超时:如果试图的操作无法立即执行,则该方法产生阻塞,直到能成功或者超时,返回一个特定值来判断是否成功 注意:无法向BolckingQueue中插入null,否则将抛出NullPointerException 可以访问BlockingQueue中所有的元素,不仅仅是开始和结束,如remove(o)移除指定元素(效率很低,不建议做该操作) 实现 BlockingQueue是个接口,可以使用它的实现来使用,concurrent包中有如下几个实现类: 2-1.ArrayBlockingQueue 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354/** * @ClassMame: DemoArrayBlockingQueue * @Description: TODO * @Author 宝全 * @Email wb-lbq444313@alibaba-inc.com * @Date 2018/10/11 10:16 * @Version 1.0 */public class DemoArrayBlockingQueue &#123; public static void main(String[] args) &#123; BlockingQueue queue=new ArrayBlockingQueue(1); new Thread(new ArrayBlockingQueueProvide(queue)).start(); new Thread(new ArrayBlockingQueueConsumer(queue)).start(); &#125;&#125;class ArrayBlockingQueueProvide implements Runnable&#123; private BlockingQueue queue=null; public ArrayBlockingQueueProvide(BlockingQueue queue) &#123; this.queue = queue; &#125; @Override public void run() &#123; try &#123; queue.put("1逻辑"); queue.put("2逻辑"); queue.put("3逻辑"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125;class ArrayBlockingQueueConsumer implements Runnable&#123; private BlockingQueue queue=null; public ArrayBlockingQueueConsumer(BlockingQueue queue) &#123; this.queue = queue; &#125; @Override public void run() &#123; try &#123; for(;;)&#123; System.out.println(queue.take()); /* 1逻辑 2逻辑 3逻辑 */ &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; ArrayBlockingQueue部分源码属性1234567final Object[] items; //队列数组int takeIndex; //拿出下标int putIndex; //插入下标int count; //元素统计final ReentrantLock lock; //重入锁 ,注意:插入和取出用的是同一把锁,因此同一时刻不会一起执行private final Condition notEmpty; //消费者takes操作(如await开头阻塞,signal开头唤醒)private final Condition notFull; //提供者puts操作(如await开头阻塞,signal开头唤醒) 阻塞插入put方法源码(如果立即添加不成功,进入阻塞) 123456789101112public void put(E e) throws InterruptedException &#123; checkNotNull(e); //判断非空 final ReentrantLock lock = this.lock; //重入锁,保证代码块安全 lock.lockInterruptibly(); //加锁,中断或超时等抛异常 try &#123; while (count == items.length) //队列满时 notFull.await(); //进入阻塞 enqueue(e); //加入队列 &#125; finally &#123; lock.unlock(); //释放锁 &#125;&#125; enqueue(e)源码(加入队列) 12345678private void enqueue(E x) &#123; final Object[] items = this.items; //取得队列(本质是Obj数组) items[putIndex] = x; //putIndex为添加元素下标 if (++putIndex == items.length) //如果数组容量装满时进入判断 putIndex = 0; //下标重新从0开始,因为队列的容量在声明时已经固定,通过下标清0的方法不断循环 count++; //未消费消息数+1; notEmpty.signal(); //唤醒等待消费元素的线程,上菜了!( • ̀ω•́ )✧&#125; 阻塞取出take方法源码 1234567891011public E take() throws InterruptedException &#123; final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; while (count == 0) //当队列中没有元素时,进入阻塞 notEmpty.await(); return dequeue(); //返回移除元素信息 &#125; finally &#123; lock.unlock(); &#125;&#125; dequeue方法源码 123456789101112private E dequeue() &#123; final Object[] items = this.items; E x = (E) items[takeIndex]; //获取当前元素 items[takeIndex] = null; if (++takeIndex == items.length) takeIndex = 0; count--; ////未消费消息数-1; if (itrs != null) //itrs为迭代器,通过迭代器操作来移除队列的头元素 itrs.elementDequeued(); notFull.signal(); //唤醒等待非满条件的线程进入,吃完了!( • ̀ω•́ )✧ return x; //返回移除的元素信息&#125; 非阻塞插入add方法源码 123456public boolean add(E e) &#123; if (offer(e)) //直接调用offer(e)方法,立即返回状态,成功则返回成功,失败则抛出异常 return true; else throw new IllegalStateException(&quot;Queue full&quot;); &#125; offer方法源码 123456789101112131415public boolean offer(E e) &#123; checkNotNull(e); final ReentrantLock lock = this.lock; lock.lock(); try &#123; if (count == items.length) //数组满了直接返回false,否则返回true return false; else &#123; enqueue(e); return true; &#125; &#125; finally &#123; lock.unlock(); &#125;&#125; 非阻塞取出poll方法源码 123456789public E poll() &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; return (count == 0) ? null : dequeue(); //如果没有,返回空,如果有,返回元素信息 &#125; finally &#123; lock.unlock(); &#125;&#125; 不超时阻塞插入offer(o,timeout,timeutil)源码 12345678910111213141516171819public boolean offer(E e, long timeout, TimeUnit unit) throws InterruptedException &#123; checkNotNull(e); long nanos = unit.toNanos(timeout); //获取超时时间 final ReentrantLock lock = this.lock; //上锁 lock.lockInterruptibly(); //中断或超时抛出异常 try &#123; while (count == items.length) &#123; //如果队列满了 if (nanos &lt;= 0) //如果超时时间到了,返回false return false; nanos = notFull.awaitNanos(nanos); //如果超时时间没到,进入限时阻塞 &#125; enqueue(e); return true; &#125; finally &#123; lock.unlock(); //释放重入锁 &#125;&#125; 不超时阻塞取出poll(o,timeout,timeUnit)方法源码 12345678910111213141516public E poll(long timeout, TimeUnit unit) throws InterruptedException &#123; long nanos = unit.toNanos(timeout); final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; while (count == 0) &#123; //如果没有元素,则进入判断 if (nanos &lt;= 0) return null; nanos = notEmpty.awaitNanos(nanos); &#125; return dequeue(); &#125; finally &#123; lock.unlock(); &#125;&#125; //同不超时阻塞插入原理 走一波瞎**想的场景,伪工具类吧= = . 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122package com.dony15.blockingQueue;import java.util.LinkedList;import java.util.concurrent.ArrayBlockingQueue;import java.util.concurrent.BlockingQueue;/** * @ClassMame: DemoArrayBlockingQueue * @Description: 边学边用,于是,就有了这么一个废物工具,多线程异步使我们不需要过多考虑性能,分类写到不同的地方,中断异常提醒 * BlockingQueue中ArrayBlockingQueue并非性能最高的方案,后续更新 ArrayBlockingQueue缺点:读写只能同时发生一个(底层靠同一把重入锁和两个方法来保证数据安全) * @Author 宝全 * @Email wb-lbq444313@alibaba-inc.com * @Date 2018/10/11 10:16 * @Version 1.0 */public class DemoArrayBlockingQueue &#123; public static void main(String[] args) &#123; DonY15.writeLog(&quot;1&quot;, &quot;2&quot;, 123, true, &apos;c&apos;, &quot;谢大脚&quot;, 12.554); DonY15.outFile(&quot;本地E盘&quot;, &quot;邮箱:666@qq.com&quot;, &quot;地址:127.0.0.1:6666&quot;, &quot;手机号:110&quot;); &#125;&#125;/** * 工具类:可批量加入XXX信息 * * 效果: * 1.适合信息比较大,数量较多容易产生阻塞(多线程缓解) * 2.该信息可以确保顺序(CLH列队实现,这个可以有) * 3.该信息不要求即时同步 * 4.该信息属于共享信息,不需要绑定用户(目测绑定也不好实现,ArrayBlockingQueue两个线程比较合适,测试如果多个线程读写可能会丢数据= = .反正有一些发出去了,收不到,而且那样做,顺序性的特点也会丢失) * 5.该信息需要写到不同的地方(本地/邮箱/XX服务器/XX短信)(伪代码概括) * 6.可以归类,用途:将不同类型信息发送到不同的数据库位置存储,提高阅读效率??吧(这些功能也不是BlockQueue的特性= = .) */class DonY15 &#123; //使用数组阻塞队列 private static BlockingQueue queue = new ArrayBlockingQueue(1024); //加工接收消息 public static void writeLog(Object... arg) &#123; new Thread(new ArrayBlockingQueueProvide(queue, arg)).start(); &#125; //消费消息到指定位置 public static void outFile(String localPath, String emailPath, String serverAddress, String phone) &#123; new Thread(new ArrayBlockingQueueConsumer(queue, localPath, emailPath, serverAddress, phone)).start(); &#125;&#125;/** * 提供者 */class ArrayBlockingQueueProvide implements Runnable &#123; private BlockingQueue queue = null; private LinkedList arg = new LinkedList(); public ArrayBlockingQueueProvide(BlockingQueue queue, Object... args) &#123; this.queue = queue; if (args != null &amp;&amp; args.length &gt; 0) &#123; for (Object arg : args) &#123; this.arg.add(arg); &#125; &#125; &#125; @Override public void run() &#123; try &#123; queue.put(arg); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;&#125;/** * 消费者 */class ArrayBlockingQueueConsumer implements Runnable &#123; private BlockingQueue queue = null; private String localPath; private String emailPath; private String serverAddress; private String phone; public ArrayBlockingQueueConsumer(BlockingQueue queue, String localPath, String emailPath, String serverAddress, String phone) &#123; this.queue = queue; this.localPath = localPath; this.emailPath = emailPath; this.serverAddress = serverAddress; this.phone = phone; &#125; @Override public void run() &#123; try &#123; for (; ; ) &#123; LinkedList takes = (LinkedList) queue.take(); System.out.println(&quot;------------------[根据信息分类功能]--------------------&quot;); for (Object takeData : takes) &#123; if (takeData instanceof String) &#123; System.out.println(&quot;这是字符串信息:&quot; + takeData); &#125; else if (takeData instanceof Integer) &#123; System.out.println(&quot;这是整型信息:&quot; + takeData); &#125; else if (takeData instanceof Character) &#123; System.out.println(&quot;这是字符信息:&quot; + takeData); &#125; else if (takeData instanceof Boolean) &#123; System.out.println(&quot;这是布尔信息:&quot; + takeData); &#125; else &#123; System.out.println(&quot;这TM是垃圾,不分了!--&gt;&quot; + takeData); &#125; &#125; System.out.println(&quot;------------------[根据需求分发功能]--------------------&quot;); System.out.println(takes + &quot;这条信息是写往:&quot; + localPath); System.out.println(takes + &quot;这条信息是写往:&quot; + emailPath); System.out.println(takes + &quot;这条信息是写往:&quot; + serverAddress); System.out.println(takes + &quot;这条信息是写往:&quot; + phone); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 2-2.PriorityBlockingQueue无界并发队列,使用了和 PriorityQueue 一样的排序规则,无法向队列中插入null值. 比PriorityQueue额外增加阻塞效果 优先级队列:是一个基于堆的无界并发安全的优先级队列 优先级队列比较规则:当前对象和其他对象做比较，当前优先级大就返回-1，优先级小就返回1 注意: 插入到PriorityBlockingQueue的元素必须实现Comparable接口或者构造中传入Comparator PriorityBlockingQueue对于具有相同优先级的元素并不强制任何特定行为(不会按照先进先出原则) 从PriorityBlockingQueue中获取Iterator遍历元素,并不能保证按照优先级顺序 源码: 123456789private static final int DEFAULT_INITIAL_CAPACITY = 11; //默认容量private static final int MAX_ARRAY_SIZE = Integer.MAX_VALUE - 8; //可分配最大队列容量,-8是VM实现数组头的内容private transient Object[] queue; //队列元素数组。平衡二叉堆实现，父节点下标是n，左节点则是2n+1，右节点是2n+2。最小的元素在最前面private transient int size; //当前队列中元素个数private transient Comparator&lt;? super E&gt; comparator; //决定队列中元素顺序的比较器private final ReentrantLock lock; //所有public方法的锁(重入锁)private final Condition notEmpty; //队列为空时阻塞private transient volatile int allocationSpinLock; //扩容数组分配资源时的自旋锁,CAS需要private PriorityQueue&lt;E&gt; q; //只用于序列化的时候,为了兼容之前的版本(只有在序列化和反序列化时不为null) offer和add(直接返回offer)方法 12345678910111213141516171819202122public boolean offer(E e) &#123; if (e == null) //不支持插入null throw new NullPointerException(); final ReentrantLock lock = this.lock; lock.lock(); int n, cap; Object[] array; while ((n = size) &gt;= (cap = (array = queue).length)) tryGrow(array, cap); try &#123; Comparator&lt;? super E&gt; cmp = comparator; if (cmp == null) siftUpComparable(n, e, array); else siftUpUsingComparator(n, e, array, cmp); size = n + 1; notEmpty.signal(); //队列为空时阻塞 &#125; finally &#123; lock.unlock(); &#125; return true;&#125; 使用 元素实现Comparable接口 12345678910111213141516171819class City implements Comparable&lt;City&gt;&#123; private int priority; private String name; private String desc; //getter setter略 @Override public int compareTo(City o) &#123;// return (this.priority&gt;o.priority)?1:(this.priority&lt;o.priority)?-1:0; return Integer.compare(this.priority, o.priority); &#125; @Override public String toString() &#123; return &quot;City&#123;&quot; + &quot;priority=&quot; + priority + &quot;, name=&apos;&quot; + name + &apos;\&apos;&apos; + &quot;, desc=&apos;&quot; + desc + &apos;\&apos;&apos; + &apos;&#125;&apos;; &#125;&#125; PriorityBlockingQueue示例 123456789101112131415161718192021/** * @ClassMame: DemoPriorityBlockingQueue * @Description: TODO * @Author 宝全 * @Email wb-lbq444313@alibaba-inc.com * @Date 2018/10/15 15:54 * @Version 1.0 */public class DemoPriorityBlockingQueue &#123; public static void main(String[] args) throws InterruptedException &#123; PriorityBlockingQueue&lt;Object&gt; queue = new PriorityBlockingQueue&lt;&gt;(); queue.add(new City(10,&quot;北京&quot;,&quot;北京好&quot;)); queue.put(new City(100,&quot;上海&quot;,&quot;上海好&quot;)); queue.offer(new City(101,&quot;南京&quot;,&quot;南京好&quot;)); System.out.println(queue.take()); System.out.println(queue.take()); System.out.println(queue.take()); &#125;&#125; 2-3.DelayQueue DelayQueue中内部使用的是PriorityQueue存放数据，使用ReentrantLock实现线程同步，阻塞队列。 DelayQueue = BlockingQueue + PriorityQueue + Delayed 注意:队列里面的元素要实现Delayed接口,一个是获取当前剩余时间的接口，一个是元素时间比较的接口. 优先级的队列:比较的基准为时间 框架:TimerThread底层使用(ScheduledThreadPoolExecutor) 场景: a)关闭空闲连接(如一些客户端连接,空闲过久后移除) b)缓存(缓存中的对象,超过空闲时间,需要从缓存中移除) c)任务超时处理(网络协议滑动窗口请求应答交互,超时处理) DelayQueue源码解析 1234private final transient ReentrantLock lock = new ReentrantLock(); //可重入锁private final PriorityQueue&lt;E&gt; q = new PriorityQueue&lt;E&gt;(); //调用PriorityQueue,优先级队列private Thread leader = null;private final Condition available = lock.newCondition(); //阻塞线程 Delayed接口(源码) 12345678910public interface Delayed extends Comparable&lt;Delayed&gt; &#123; /** * Returns the remaining delay associated with this object, in the * given time unit. * @param unit the time unit * @return the remaining delay; zero or negative values indicate * that the delay has already elapsed */ long getDelay(TimeUnit unit);&#125; offer操作 offer底层调用PriorityQueue优先级队列,所以peek不一定是当前添加的元素,如果peek(检测是否为当前头元素)为true,说明当前元素e的优先级最小,即将过期,激活available变量条件队列里的线程,通知队列中的所有元素 1234567891011121314public boolean offer(E e) &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; q.offer(e); if (q.peek() == e) &#123; leader = null; available.signal(); &#125; return true; &#125; finally &#123; lock.unlock(); &#125; &#125; put操作 put直接调用offer方法 123public void put(E e) &#123; offer(e);&#125; take()方法 123456789101112131415161718192021222324252627282930313233public E take() throws InterruptedException &#123; final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; for (;;) &#123; E first = q.peek(); //获取但不移除头元素 if (first == null) //如果没有头元素,则进行阻塞 available.await(); else &#123; long delay = first.getDelay(NANOSECONDS); //获取头元素过期时间 if (delay &lt;= 0) //如果过期时间到了,则移除该元素,否则进入阻塞 return q.poll(); first = null; // don&apos;t retain ref while waiting if (leader != null) available.await(); else &#123; Thread thisThread = Thread.currentThread(); leader = thisThread; try &#123; available.awaitNanos(delay); &#125; finally &#123; if (leader == thisThread) leader = null; &#125; &#125; &#125; &#125; &#125; finally &#123; if (leader == null &amp;&amp; q.peek() != null) available.signal(); lock.unlock(); &#125;&#125; poll方法 立即获取头元素,如果队列为空或者该元素未过期,则直接返回null 12345678910111213public E poll() &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; E first = q.peek(); //获取队列头部元素 if (first == null || first.getDelay(NANOSECONDS) &gt; 0) //精确到纳秒 return null; else return q.poll(); &#125; finally &#123; lock.unlock(); &#125; &#125; 超时时间内,获取队列头元素信息,否则返回null 12345678910111213141516171819202122232425262728293031323334353637383940public E poll(long timeout, TimeUnit unit) throws InterruptedException &#123; long nanos = unit.toNanos(timeout); final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; for (;;) &#123; E first = q.peek(); if (first == null) &#123; if (nanos &lt;= 0) return null; else nanos = available.awaitNanos(nanos); &#125; else &#123; long delay = first.getDelay(NANOSECONDS); if (delay &lt;= 0) return q.poll(); if (nanos &lt;= 0) return null; first = null; // don&apos;t retain ref while waiting if (nanos &lt; delay || leader != null) nanos = available.awaitNanos(nanos); else &#123; Thread thisThread = Thread.currentThread(); leader = thisThread; try &#123; long timeLeft = available.awaitNanos(delay); nanos -= delay - timeLeft; &#125; finally &#123; if (leader == thisThread) leader = null; &#125; &#125; &#125; &#125; &#125; finally &#123; if (leader == null &amp;&amp; q.peek() != null) available.signal(); lock.unlock(); &#125;&#125; 使用 需要实现Delayed接口,实现获取剩余时间和比较时间方法 1234567891011121314151617181920212223242526272829303132333435363738394041public class DelayeDto implements Delayed &#123; private final long delayTime; //延迟时间 private final long expire; //过期时间 private String data; //数据 public DelayeDto(String data,long delayTime) &#123; this.delayTime = delayTime; expire = System.currentTimeMillis()+delayTime; this.data = data; &#125; /** * 剩余时间 * @param unit * @return */ @Override public long getDelay(TimeUnit unit) &#123; return unit.convert(this.expire-System.currentTimeMillis(),unit); &#125; /** * 比较优先级 * @param o * @return */ @Override public int compareTo(Delayed o) &#123; return (int) (this.getDelay(TimeUnit.MILLISECONDS)-o.getDelay(TimeUnit.MILLISECONDS)); &#125; @Override public String toString() &#123; return &quot;DelayeDto&#123;&quot; + &quot;delayTime=&quot; + delayTime + &quot;, expire=&quot; + expire + &quot;, data=&apos;&quot; + data + &apos;\&apos;&apos; + &apos;&#125;&apos;; &#125;&#125; 实现 根据设置的过期时间顺序来获取元素,不一定是直接获取列表第一个元素,当时间相同时,根据加入顺序来获取 1234567891011121314151617181920212223242526/** * @ClassMame: DemoDelayQueue * @Description: TODO * @Author 宝全 * @Date 2018/10/15 13:37 * @Version 1.0 */public class DemoDelayQueue &#123; public static void main(String[] args) throws InterruptedException &#123; for (int i = 0; i &lt; 20; i++) &#123; BlockingQueue queue = new DelayQueue(); DelayeDto delayeDto1 = new DelayeDto(&quot;123&quot;, 200); DelayeDto delayeDto2 = new DelayeDto(&quot;456&quot;, 1000); queue.offer(delayeDto1); queue.offer(delayeDto2); System.out.println(queue.take()); System.out.println(queue.take()); &#125; &#125;&#125; DelayQueue缓存实现传送门 https://www.cnblogs.com/jobs/archive/2007/04/27/730255.html 2-4.LinkedBlockingQueue链阻塞同步队列(FIFO) 数据结构为链表 可以指定节点上限,默认Integer.MAX_VALUE 与ArrayBlockingQueue使用方法相同 使用场景: Executors线程池:newFixedThreadPool/newSingleThreadExecutor tomcat:TaskQueue(继承了LinkedBlockingQueue并且泛化类型固定了为Runnalbe.重写了offer,poll，take方法。) Tomcat源码分析 https://blog.csdn.net/u011109589/article/details/80518931 源码 123456789static class Node&lt;E&gt; //节点private final int capacity; //队列最大容量,默认Integer.MAX_VALUEprivate final AtomicInteger count = new AtomicInteger(); //队列内元素个数transient Node&lt;E&gt; head; //头结点private transient Node&lt;E&gt; last;//尾节点private final ReentrantLock takeLock = new ReentrantLock(); //取出锁(互斥锁)private final ReentrantLock putLock = new ReentrantLock(); //插入锁 private final Condition notEmpty = takeLock.newCondition(); //非空条件private final Condition notFull = putLock.newCondition(); //未满条件 offer方法 1234567891011121314151617181920212223public boolean offer(E e) &#123; if (e == null) throw new NullPointerException(); final AtomicInteger count = this.count; //统计元素个数 if (count.get() == capacity)//如果队列满了,返回false return false; int c = -1; Node&lt;E&gt; node = new Node&lt;E&gt;(e); final ReentrantLock putLock = this.putLock; //插入锁 putLock.lock(); try &#123; if (count.get() &lt; capacity) &#123; //队列未满,允许插入 enqueue(node); c = count.getAndIncrement(); if (c + 1 &lt; capacity) notFull.signal(); //激活插入条件 &#125; &#125; finally &#123; putLock.unlock(); &#125; if (c == 0) signalNotEmpty(); //激活等待条件 return c &gt;= 0; &#125; take方法 123456789101112131415161718192021public E take() throws InterruptedException &#123; E x; int c = -1; final AtomicInteger count = this.count; //统计元素个数 final ReentrantLock takeLock = this.takeLock; takeLock.lockInterruptibly(); try &#123; while (count.get() == 0) &#123; //队列空,则等待 notEmpty.await(); &#125; x = dequeue(); //移除头结点 c = count.getAndDecrement(); if (c &gt; 1) notEmpty.signal(); &#125; finally &#123; takeLock.unlock(); &#125; if (c == capacity) signalNotFull(); return x; &#125; remove方法 1234567891011121314151617public boolean remove(Object o) &#123; if (o == null) return false; fullyLock(); //移除操作时,插入和其他移除(take)操作将被阻塞,双重锁 try &#123; for (Node&lt;E&gt; trail = head, p = trail.next; p != null; trail = p, p = p.next) &#123; if (o.equals(p.item)) &#123; unlink(p, trail); return true; &#125; &#125; return false; &#125; finally &#123; fullyUnlock(); &#125; &#125; 并发队列对比之一：ConcurrentLinkedQueue、LinkedBlockingQueue对比分析https://www.cnblogs.com/duanxz/archive/2012/10/12/2721290.html 2-5. SynchronousQueue特殊的同步阻塞队列,他内部没有容器,队列中只有一个元素 如果队列中有1个元素,则插入线程进入阻塞 如果队列中没有元素,则移除线程进入阻塞 底层与ArrayBlockingQueue/LinkedBlockingQueue(依赖AQS实现线程安全)不同, 而是直接由大量CAS代码(Unsafe)保障其安全 匹配通信机制 特点 不能在同步队列上进行 peek，因为仅在试图要取得元素时，该元素才存在； 它非常适合于传递性设计，在这种设计中，在一个线程中运行的对象要将某些信息、事件或任务传递给在另一个线程中运行的对象，它就必须与该对象同步。 对于正在等待的生产者和使用者线程而言，此类支持可选的公平排序策略。默认情况下不保证这种排序。 但是，使用公平设置为 true 所构造的队列可保证线程以 FIFO 的顺序进行访问。 公平通常会降低吞吐量，但是可以减小可变性并避免得不到服务。 场景: ​ 线程池中运用较多 公平模式FIFO TransferQueue 非公平模式FILO TransferStack 源码详解 https://blog.csdn.net/chenssy/article/details/77371992 2-6. BlockingDeque阻塞双端队列 BlockingDeque接口实现BlockingQueue接口 在线程中,既可以是生产者,又可以是消费者 deque全称”Double Ended Queue”,可以从双端队列的任一端点执行插入或移除 在不能插入元素时,将阻塞试图插入元素的线程, 在不能移除元素时,将阻塞试图移除元素的线程 更加灵活,可以实现FIFO或者FILO ~ 抛异常 特定值 阻塞 超时 插入 addFirst(o) offerFirst(o) putFirst(o) offerFirst(o,timeout,timeUnit) 移除 removeFirst(o) pollFirst(o) takeFirst(o) pollFirst(timeout,timeunit) 检查 getFirst(o) peekFirst(o) ~ ~ ~ 抛异常 特定值 阻塞 超时 插入 addLast(o) offerLast(o) putLast(o) offerLast(o,timeout,timeUnit) 移除 removeLast(o) pollLast(o) takeLast(o) pollLast(timeout,timeunit) 检查 getLast(o) peekLast(o) ~ ~ 方法与BlockingQueue类似 双端队列可以使用BlockingQueue的方法,当然这些方法会遵循BlockingQueue的规则,FIFO 2-7.链阻塞双端队列 LinkedBlockingDequeLinkedBlockingDeque是BlockingDeque的唯一实现 可以指定队列容量,如果不指定,则默认Integer.MAX_VALUE 源码: 12345678static final class Node&lt;E&gt; //元素节点transient Node&lt;E&gt; first; //头元素transient Node&lt;E&gt; last; //尾元素private transient int count; //队列中元素统计private final int capacity; //队列最大容量,可指定,默认Integer.MAX_VALUEfinal ReentrantLock lock = new ReentrantLock(); //重入锁(互斥锁)private final Condition notEmpty = lock.newCondition(); //非空条件private final Condition notFull = lock.newCondition(); //未满条件 源码基础连接 https://www.cnblogs.com/skywang12345/p/3503480.html FIFO式使用 123456789101112131415161718192021222324252627282930313233343536/** * @ClassMame: DemoLinkedBlockingDequ * @Description: TODO * @Author 宝全 * @Date 2018/10/15 18:09 * @Version 1.0 */public class DemoLinkedBlockingDequ &#123; public static void main(String[] args) &#123; LinkedBlockingDeque&lt;Object&gt; deque = new LinkedBlockingDeque&lt;&gt;(); //插入 new Thread(() -&gt; &#123; try &#123; deque.putFirst(&quot;123&quot;); deque.putFirst(&quot;567&quot;); deque.putFirst(&quot;789&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;).start(); //取出 new Thread(() -&gt; &#123; try &#123; System.out.println(deque.takeLast()); //123 System.out.println(deque.takeLast()); //567 System.out.println(deque.takeLast()); //789 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;).start(); &#125;&#125; FILO式使用 123456789101112131415161718192021222324252627282930313233343536/** * @ClassMame: DemoLinkedBlockingDequ * @Description: TODO * @Author 宝全 * @Date 2018/10/15 18:09 * @Version 1.0 */public class DemoLinkedBlockingDequ &#123; public static void main(String[] args) &#123; LinkedBlockingDeque&lt;Object&gt; deque = new LinkedBlockingDeque&lt;&gt;(); //插入 new Thread(() -&gt; &#123; try &#123; deque.putFirst(&quot;123&quot;); deque.putFirst(&quot;567&quot;); deque.putFirst(&quot;789&quot;); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;).start(); //取出 new Thread(() -&gt; &#123; try &#123; System.out.println(deque.takeFirst()); //789 System.out.println(deque.takeFirst()); //567 System.out.println(deque.takeFirst()); //123 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;).start(); &#125;&#125; 3.JUC锁(互斥锁)http://www.cnblogs.com/skywang12345/p/3496101.html https://juejin.im/post/5a093ff551882531bb6c4ee3]]></content>
      <categories>
        <category>JAVA并发编程</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Concurrent并发包入门(一)]]></title>
    <url>%2F2018%2F10%2F10%2FConcurrent%E5%B9%B6%E5%8F%91%E5%8C%85%E5%85%A5%E9%97%A8(%E4%B8%80)%2F</url>
    <content type="text"><![CDATA[concurrent并发包入门(一)java.util.concurrent 简称(JUC) 作者:Doug Lea 1.概念JUC包含许多线程安全/测试良好/高性能的并发构建块 Concurrent可以实现Collection框架对数据结构所执行的兵法操作 通过并发模块,可以提高并发类的线程安全/可伸缩性/性能/可读性/可靠性 2.对比 synchronized通过(monitor)监视器锁来完成同步 每个对象有一个监视器锁（monitor）。当monitor被占用时就会处于锁定状态，线程执行monitorenter指令时尝试获取monitor的所有权,获取不到则进入阻塞状态 monitorenter 进入设置(初始为0,同一个线程每次进入+1,其他线程阻塞) monitorexit 离开设置(当值为0时,表示线程释放锁,所有线程可以再次争夺) java反编译字节码(同步方法)不显示monitor的两条指令,而是通过ACC_SYNCHRONIZED封装,隐式调用,但仍是执行monitor指令来加解锁 wait/notify 等方法的底层同样是基于监视器,因此只有在同步方法(块)中才能调用 JUC通过ASC/AQS/CLH等同步技术来完成同步 更加灵活,对资源的损耗较少等如上概念所提 3.构成Atomic : AtomicInteger 原子数据的构建 Locks : Lock, Condition, ReadWriteLock 基本的锁实现,最重要的AQS框架和lockSupport Collections : Queue, ConcurrentMap 构建一些集合的工具 Executer : Future, Callable, Executor 构建一些线程池的工具 Tools : CountDownLatch, CyclicBarrier, Semaphore 并发队列等 以上都用到了CAS(compare-and-swap)操作. 4.CAS介绍(compare-and-swap)比较和交换 CAS是一种低级别的/细粒度的技术,它允许多个线程更新一个内存位置,同时能够检测其他线程的冲突并进行恢复,他是许多高性能并发算法的基础. 在JDK5.0之前,java语言中用于协调线程之间的访问的唯一原语是同步(更重量级和粗粒度), 公开CAS可以开发高度可伸缩的并发java类,这些更改主要由JDK库类使用,而不是开发人员 CAS操作都封装在java不公开的类库中,sun.misc.Unsafe. 此类包含了对原子操作的封装,具体用本地代码实现,本地的C代码直接利用到了硬件上的原子操作 5.AQS介绍(abstract-queued-synchronizer)队列同步器 JDK1.6以前,synchronized重量级锁的性能一直都较为低下,虽然在1.6以后进行了大量的锁优化策略, 但与Lock相比,synchronized还是存在一些缺陷 5-1.synchronized优缺优点:提供了便捷性的隐式获取锁释放锁机制(基于JVM机制) 缺点:缺少了获取锁和释放锁的可操作性,可中断/超时获取锁等,且它为独立式,在高并发场景下性能大打折扣 5-2.AQS构建锁或其他同步组件的基础框架,如:ReentrantLock/ReentrantReadWriteLock/Semaphore等 JUC并发包的作者希望它能够成为实现大部分同步需求的基础,是JUC并发包中的核心基础组件 AQS解决了实现同步器时设计的大量细节问题,如:获取同步状态/FIFO同步队列 基于AQS来构同步器可以带来很多好处,不仅能极大地减少实现工作,也不必处理多个位置上发生竞争问题 基于AQS构建的同步器中,只能在同一时刻发生阻塞,从而降低上下文切换带来的开销,提高吞吐量. 设计AQS时充分考虑了可伸缩性,JUC中所有基于AQS构建的同步器均可获得这个优势 AQS通过内置的FIFO同步队列(CLH)来完成资源获取线程的排队工作,如果当前线程获取同步状态(锁)失败, AQS则会将当前线程以及等待状态等信息构建成一个节点(Node)并将其加入到同步队列中, 同时阻塞当前线程,当同步状态释放时,会把节点中的线程唤醒,使其再次尝试获取同步状态 5-3.AQS使用AQS主要使用方式是集成,子类通过集成同步器并实现它的抽象方法来管理同步状态 AQS使用一个int类型的成员变量state来表示同步状态 当state&gt;0表示获取锁 state=0表示释放锁 提供三个方法来对同步状态state进行操作 getState() 获取当前同步状态值； setState(int newState)设置当前同步状态； compareAndSetState(int expect,int update) 使用CAS设置当前状态，该方法能够保证状态设置的原子性； AQS可以确保对state的操作是安全的 AQS主要提供的方法 getState() 获取当前同步状态值 setState() 设置当前同步状态 compareAndSetState(int expect,int update) 使用CAS设置当前状态,该方法能够邦正状态设置的原子性 tryAcquire(int arg) 独占式获取同步状态,获取同步状态成功后,其他线程需要等待该线程释放同步状态才能获取同步状态 tryRelease(int arg) 独占式释放同步状态 —-共享式获取同步状态,返回值&gt;=0则表示获取成功,否则获取失败 tryReleaseShared(int arg) 共享式释放同步状态 isHeldExclusively() 当前同步器是否独占式模式下被线程占用,一般该方法表示是否被当前线程所占用 acquire(int arg) 独占式获取同步状态,如果当前线程同步状态成功,则由该方法返回,否则进入同步队列等待,该方法将会调用可重写的tryAcquire(int arg)方法 acquireInterruptibly(int arg) 与acquire(int arg)方法相同,但是该方法响应中断,当前线程会为获取到同步状态而进入到同步队列中,如果当前线程被中断,则该方法抛出InterruptedException异常并返回 tryAcquireNanos(int arg,long nanos) 超时获取同步状态,如果当前线程在nanos时间内没有获取到同步状态,那么将会返回false,已经获取则返回true acquireShared(int arg) 共享式获取同步状态,如果当前线程未获取到同步状态,将会进入同步队列等待,与独占式的主要区别是在同一时刻可以有多个线程获取到同步状态 acquireSharedInterruptibly(int arg) 共享式获取同步状态,响应中断,当前线程会为获取到同步状态而进入到同步队列中,如果当前线程被中断,则该方法抛出InterruptedException异常并返回 tryAcquireSharedNanos(int arg,long nanosTimeout) 共享式获取同步状态,增加超时限制 release(int arg) 独占式释放同步状态,该方法会释放同步状态之后,将同步队列中第一个节点包含的线程唤醒 releaseShared(int arg) 共享式释放同步状态,该方法会释放同步状态之后,将同步队列中第一个节点包含的线程唤醒 6.部分底层锁简介自旋锁/排队自旋锁/MSC锁/CLH锁 https://coderbee.net/index.php/concurrent/20131115/577 公平锁/非公平锁/可重入锁 独享锁/共享锁 互斥锁/读写锁 乐观锁/悲观锁 分段锁 偏向锁/轻量级锁/重量级锁 https://blog.csdn.net/weixin_38894058/article/details/78952585 7.CLH同步队列AQS内部维护的FIFO队列,即CLH同步队列 AQS依赖CLH同步队列才能完成同步状态的管理(自旋锁-&gt;公平锁,详情了解6章节内容) https://blog.csdn.net/chenssy/article/details/60781148 CLH同步队列中,一个节点表示一个线程,包含如下: 线程的引用(thread) 状态(waitStatus) 前驱节点(prev) 后继节点(next) AQS通过”死循环”(自旋)的方法保证节点的正确添加,只有添加成功后,当前线程才会从该方法返回,否则一直执行 CLH同步队列中,当首节点释放同步状态后,将会唤醒其后继节点,后继节点获取同步状态成功后将自己设为首节点 CLH唤醒方法简述 前驱节点:isLocked=true 后置节点:while(preNode.isLocked){} 后置节点会轮询前驱节点的锁状态,当前驱节点释放锁,isLocked=false,则后置节点跳出”死循环(自旋)”尝试获取锁 7-1.独占式独占式获取响应中断 AQS提供了acquire(int arg)方法让独占式获取同步状态,但是该方法对中断不响应,线程中断后仍然会在对联中等待获取同步状态,为了响应中断,可以使用acquireInterruptibly(int arg)方法,线程中断后立刻抛出InterruptedException异常 独占式超时获取 tryAcquireNano(int arg,long nanos),如果指定时间没有获得同步状态,则直接返回false,否则返回true 独占式同步状态释放 release(int arg) 释放同步状态 (该方法先调用自定义同步器定义的tryRelease(int arg)方法释放同步状态,释放成功后调用unparkSuccessor(Node node)方法唤醒后继节点) 7-2.共享式共享式和独占式最大的区别是同一时刻共享式可以有多个线程获得同步状态,而独占式只有一个线程可以获得 共享式读操作可以有多个线程同时执行,写操作同一时刻只有一个线程,其他线程会被阻塞 共享式获取同步状态 AQS提供acquireShared(int arg)方法让共享式获取同步状态,该方法中 首先调用tryAcquireShared(int arg)方法尝试获取同步状态,如果获取失败 则调用doAcquireShared(int arg)自旋方式获取同步状态,共享式获取同步状态的标志是返回&gt;=0 共享式获取同步状态响应中断 AQS提供acquireShared(int arg)方法让共享式获取同步状态,该方法对中断也不响应,需要使用,中断和超时的方法分别为 acquireSharedInterruptibly(int arg) tryAcquireSharedNanos(int arg,long nanos) 共享式同步状态释放 releaseShared(int arg)释放同步状态 内部调用tryReleaseShared(int arg)来尝试循环释放 因为可能存在多个线程同时释放同步状态资源,所以需要确保同步状态安全成功的释放,一般都是通过CAS和循环来完成 7-3.阻塞和唤醒线程在线程获取同步状态时,如果获取失败,则加入CLH同步队列,通过自旋的方式不断获取同步状态,但在自选的过程中需要判断该线程是否需要阻塞, 通过acquireQueued()方法 该方法内首先需要判断该线程的状态,再决定是否阻塞 主要通过该节点的前驱节点判断当前线程是否应该被阻塞,规则如下: 如果当前线程的前驱节点状态为SIGNAL,则表示当前线程需要被阻塞,调用unpark()方法唤醒,直接返回true,当前线程阻塞 如果当前线程的前驱节点状态为CANCELLED(取消)(ws&gt;0),表示该线程的前驱节点超时或中断 如果前驱节点非SIGNAL,非CANCELLED,则通过CAS(compareAndSetWaitStatus)的方式将其前驱节点设置为SIGNAL,返回false 如果shouldParkAfterFailedAcquire(Node pred, Node node) 方法返回true，则调用parkAndCheckInterrupt()方法阻塞当前线程; 当前线程release(int arg)释放同步状态后,调用unparkSuccessor(Node node)唤醒后继节点 注意 后继节点可能存在null,如超时/被中断等情况,需要跳过该节点, 所以不采用next的方法,而采用tail回溯的办法找第一个可用线程, 最后调用LockSupport的unpark(Thread thread)方法唤醒该线程 7-4.LockSupport阻塞或唤醒一个线程时,AQS都会使用LockSupport这个工具类来完成 原语:LockSupport是用来创建锁和其他同步类的基本线程阻塞 每个使用LockSupport的线程都会与一个许可关联, 如果该许可可用,并且可在进程中使用,则调用park()将会立即返回,否则进入阻塞状态 如果许可尚不可用,可以调用unpark使其可用,但是许可不可以重入,只能调用一次park()方法,否则一直进入阻塞状态 LockSupport定义了一系列park开头的方法用来阻塞当前线程,unark(Thread thread)方法唤醒一个被阻塞的线程 park(Object blocker)方法的blocker参数，主要是用来标识当前线程在等待的对象，该对象主要用于问题排查和系统监控。 park方法和unpark(Thread thread)都是成对出现的，同时unpark必须要在park执行之后执行，当然并不是说没有不调用unpark线程就会一直阻塞，park有一个方法，它带了时间戳（parkNanos(long nanos)：为了线程调度禁用当前线程，最多等待指定的等待时间，除非许可可用）。 park()和unpark()源码都是调用UNSAFE类中的方法,该方法都是native中的本地方法,比较危险,主要用于执行低级别,不安全的方法集合, 除非是授信代码,否则无法再java程序中直接使用 基础概括传送门 https://my.oschina.net/lifany/blog/146699 教全基础概括传送门 https://blog.csdn.net/windsunmoon/article/details/36903901 参考链接门(含部分源码与流程图): https://juejin.im/entry/5ae02a7c6fb9a07ac76e7b70 参考资料Doug Lea：《Java并发编程实战》方腾飞：《Java并发编程的艺术》]]></content>
      <categories>
        <category>JAVA并发编程</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[快速入门自定义Starter]]></title>
    <url>%2F2018%2F10%2F09%2F%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%E8%87%AA%E5%AE%9A%E4%B9%89Starter%2F</url>
    <content type="text"><![CDATA[快速入门自定义Starter[TOC] 1.概念依赖管理是任何复杂项目的关键所在,当项目布局比较大时,纯手工的去做依赖显然比较浪费时间和精力,其中产生各种小问题同样会减少工作核心部分的投入时间 Springboot starter作为Springboot四大神器之一,就是为了解决这一问题而诞生,分而治之,提高代码复用性,让代码的配置看起来更加简洁 (与Apollo结合使用将大大降低因配置而产生的维护难度,提高了配置的治理效率) 2.思路1.引入SpringBoot配置自动注入的依赖*2 123456789&lt;dependency&gt;&lt;!-- 以下两个依赖是自动配置的依赖 --&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-autoconfigure&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt; 2.创建配置类(定义properties的内容) 3.创建服务类(需要封装和处理的业务逻辑等) 4.创建自动配置类(将配置类和服务类注入) 5.创建resources/META-INF/spring.factories工厂配置文件,注入自动配置类 1org.springframework.boot.autoconfigure.EnableAutoConfiguration=com.dony15.config.PersonServiceAutoConfiguration 3.搭建3-1.配置类 123456789101112131415161718192021222324package com.dony15.config;/** * @ClassMame: PersonServiceProperties * @Description: 人员信息自动配置属性类 * @Author 宝全 * @Date 2018/9/18 10:50 * @Version 1.0 */import org.springframework.boot.context.properties.ConfigurationProperties;@ConfigurationProperties(prefix="person.proterties.set")// 定义application.properties配置文件中的配置前缀public class PersonServiceProperties &#123; // 姓名 private String name; // 年龄 private int age; // 性别，不配置的时候默认为person.proterties.set=man private String sex = "man"; // 身高 private String height; // 体重 private String weight; ...get/set略&#125; 3-2.服务类123456789101112131415161718192021222324252627282930package com.dony15.service;import com.dony15.config.PersonServiceProperties;/** * @ClassMame: PersonService * @Description: 编写服务类 * @Author 宝全 * @Date 2018/9/18 10:51 * @Version 1.0 */public class PersonService &#123; private PersonServiceProperties personServiceProperties; public PersonService(PersonServiceProperties personServiceProperties)&#123; this.personServiceProperties=personServiceProperties; &#125; public PersonService() &#123; &#125; public String getPersonName()&#123; return personServiceProperties.getName(); &#125; public int getPersonAge()&#123; return personServiceProperties.getAge(); &#125; public String getPersonSex()&#123; return personServiceProperties.getSex(); &#125;&#125; 3-3.自动配置类(核心)1234567891011121314151617181920212223242526272829303132package com.dony15.config;import com.dony15.service.PersonService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.autoconfigure.condition.ConditionalOnClass;import org.springframework.boot.autoconfigure.condition.ConditionalOnMissingBean;import org.springframework.boot.autoconfigure.condition.ConditionalOnProperty;import org.springframework.boot.context.properties.EnableConfigurationProperties;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;/** * @ClassMame: PersonServiceAutoConfiguration * @Description: TODO * @Author 宝全 * @Date 2018/9/18 10:55 * @Version 1.0 */@Configuration //声明配置类@EnableConfigurationProperties(PersonServiceProperties.class) //开启指定类的配置@ConditionalOnClass(PersonService.class) //当PersonService这个类在类路径中时，且当前容器中没有这个Bean的情况下，开始自动配置@ConditionalOnProperty(prefix = "person.proterties.set",value = "enabled",matchIfMissing = true) //指定的属性是否有指定的值public class PersonServiceAutoConfiguration &#123; @Autowired private PersonServiceProperties properties; @Bean @ConditionalOnMissingBean(PersonService.class) //当前容器中没有指定bean的情况下,自动配置PersonService类 public PersonService personService()&#123; return new PersonService(properties); &#125;&#125; 4.使用至此,一个简单的starter搭建完毕,如下可以引用 maven 12345&lt;dependency&gt;&lt;!-- 引入自己的starter --&gt; &lt;groupId&gt;com.dony15&lt;/groupId&gt; &lt;artifactId&gt;demo-starter&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; properties 1234person.proterties.set.age=18person.proterties.set.name=常贵person.proterties.set.height=189... 然后直接Autowired自动注入即可正常使用]]></content>
      <categories>
        <category>Spring全家桶</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Apollo基础(一)]]></title>
    <url>%2F2018%2F10%2F09%2FApollo%E5%9F%BA%E7%A1%80(%E4%B8%80)%2F</url>
    <content type="text"><![CDATA[Apollo基础(一)[TOC] 1.概念配置中心,实时监听最新配置列表,动态添加配置 实时生效/灰度发布/分环境/分集群管理配置/完善权限/本地离线等 本地离线 Mac/Linux: /opt/data/{appId}/config-cache Windows: C:\opt\data{appId}\config-cache 本地配置文件会以下面的文件名格式放置于本地缓存路径下： {appId}+{cluster}+{namespace}.properties 支持四个维度管理的kv配置: application(应用) env(环境) cluster(集群) namespace(命名空间) 1-2.配置的基本概念独立于程序的只读变量配置伴随应用的整个生命周期配置可以有多种加载方式: hard code 配置文件 环境变量 启动参数 基于数据库等 配置治理: 权限控制 不同的环境/集群配置管理 框架类组件配置管理 2.组成四个核心模块(功能相关),三个辅助模块(辅助服务发现的模块) ———————————-[核心功能模块]———————————— 2-1.ConfigService提供配置获取接口 提供配置推送接口 服务于Apollo客户端 2-2.AdminService提供配置管理接口 提供配置修改发布接口 服务于管理界面Portal 2-3.Client为应用获取配置,支持实时更新 通过MetaServer获取ConfigService的服务列表 使用客户端软负载SLB方式调用ConfigService 2-4.Portal配置管理界面 通过MetServer获取AdminService列表 使用客户端软辅在SLB方式调用AdminSerivce ———————————–[辅助服务发现模块]———————————— 2-5.Eureka用于服务注册和发现,ConfigService/AdminService注册实例并定期报心跳 和ConfigService在一起部署 2-6.MetaServerPortal通过域名访问MetaServer获取AdminService服务列表 Client通过域名访问MetaServer获取ConfigService服务地址 相当于Eureka Proxy 2-7.NginxLB和域名系统配合,协助Portal访问MetaServer,获取AdminService列表 和域名系统配合,协助client访问MetaServer,获取ConfigService列表 架构图 3.Apollo使用指南https://github.com/ctripcorp/apollo/wiki/Apollo%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97 4.API接入管理(Protal)https://github.com/ctripcorp/apollo/wiki/Apollo%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83%E4%BB%8B%E7%BB%8D 5.接入使用(Client)5-1.常用方案:引入依赖 12345678910maven &lt;dependency&gt; &lt;groupId&gt;com.ctrip.framework.apollo&lt;/groupId&gt; &lt;artifactId&gt;apollo-client&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt; &lt;/dependency&gt;orgradle compile 'com.ctrip.framework.apollo:apollo-client:1.0.0' 在properties中配置命名空间等即可使用(当做在线properties即可) 123456app.id=apollo-idapollo.meta=http://localhost:8080env=DEV# will inject &apos;application&apos; namespace in bootstrap phaseapollo.bootstrap.enabled = trueapollo.bootstrap.namespaces =redis 5-2.方案二Bean的形式注入到Spring中(该场景使用不多)(支持注解/XML等形式) 配置类 123456789101112public class RedissonSingleConfig &#123; @Value("$&#123;serverConfig:Single&#125;") private String serverConfig; @Value("$&#123;singleServerConfig.address:127.0.0.1&#125;") private String address; @Value("$&#123;singleServerConfig.connectionPoolSize:100&#125;") private Integer connectionPoolSize; @Value("$&#123;keepAlive:true&#125;") private Boolean keepAlive; @Value("$&#123;database:0&#125;") private Integer database;//get set 略 Bean注入类 123456789@Configuration@EnableApolloConfig(value = &#123;"namespace"&#125;) //可省略指定命名空间,默认为application私有空间//@EnableApolloConfig(&#123;"FX.apollo", "FX.soa"&#125;) //指定多个命名空间public class ApolloConfig &#123; @Bean public RedissonSingleConfig getRedissonSingleConfig()&#123; return new RedissonSingleConfig(); &#125;&#125; 通过上面的拉取和注入即可将Apollo的配置注入到Spring中使用,更多内容可参考官网java接入指南 https://github.com/ctripcorp/apollo/wiki/Java%E5%AE%A2%E6%88%B7%E7%AB%AF%E4%BD%BF%E7%94%A8%E6%8C%87%E5%8D%97#31-api%E4%BD%BF%E7%94%A8%E6%96%B9%E5%BC%8F 5-3.方案三动态切换数据库 https://github.com/ctripcorp/apollo/wiki/Apollo%E9%85%8D%E7%BD%AE%E4%B8%AD%E5%BF%83%E4%BB%8B%E7%BB%8D Hikaricp官网(动态切换jar包) http://brettwooldridge.github.io/HikariCP/ 6.Apollo使用 创建项目 创建配置空间(private/public) 私有空间是本项目使用, 公共空间是通用空间,其他项目都可以使用 注意: 公共空间使用时建议关联一个新副本,该副本改动的配置属性为覆盖效果,可覆盖公共空间的部分配置 优秀分析传送门: https://mp.weixin.qq.com/s/-hUaQPzfsl9Lm3IqQW3VDQ]]></content>
      <categories>
        <category>框架</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[WebSocket入门]]></title>
    <url>%2F2018%2F10%2F01%2FWebSocket%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[WebSocket入门[TOC] 1.概念ws协议,基于TCP连接,随着H5的发展而诞生 允许浏览器和服务器建立持久连接 服务器可以主动给客户端发送信息,双向互通 2.基础组成基础的组件由/open/close/send/message/error组成并延伸 当然,实际使用时需要有服务器来作为通信支撑,此处以nodejs为例 服务器首先需要安装nodjs环境 然后使用脚本拉取github的开源服务器model npm install nodejs-websocket 使用一下方式建立服务器脚本即可(需要与model同层,配置才生效) wsServer.js 1234567891011121314151617181920var ws = require("nodejs-websocket")var port=8000; //监听端口// Scream server example: "hi" -&gt; "HI!!!"//服务连接事件,连接后才会有内部的事件执行var server = ws.createServer(function (conn) &#123; console.log("New connection") //消息的收发中转 conn.on("text", function (str) &#123; console.log("Received "+str) conn.sendText(str.toUpperCase()+"!!!") &#125;) //关闭连接时的事件 conn.on("close", function (code, reason) &#123; console.log("Connection closed") &#125;) //错误时的事件,如果没有该函数,服务器会因消息错误而宕机,相当于java中的异常捕获 conn.on("error",function(err)&#123; console.log(err) &#125;)&#125;).listen(port) 启动方式:node wsServer.js 客户端以js为例(java/nodejs等语法稍微有区别,但原理相同) 12//首先需要创建ws协议,才能使用var websocket=new WebSocket("ws://echo.websocket.org/"); APIonopen/onclose/onmessage/onerror等,如下 2-1.open建立连接,比如发送按钮事件,可以嵌套在open中,如果websocket没有连接,name发送按钮本身也没有意义 123websocket.onopen=function()&#123; consolet.log(&quot;websocket open&quot;)&#125; 2-2.close关闭连接 123websocket.onclose=function()&#123; consolet.log(&quot;websocket close&quot;)&#125; 2-3.send发送消息 1websocket.send(&quot;这是发送的消息&quot;) 2-4.message接收消息 123websocket.onmessage=function(e)&#123; consolet.log(e.data)&#125; 对于message来说,e.data只是普通的字符串消息接收 但是因为实际的需求,如:用户离开/进入/统计等等 需要将消息分离,那么我们可以用对象的方式来操作信息 2-5.error错误情况 123websocket.onerror=function(err)&#123; consolet.log(err)&#125; 3.格式化消息改造通过以上的基础组件,我们可以实现简单的webSocket通信,但是稍微复杂一些的信息格式却难以完成,比如用户离开/进入/统计等 我们可以对消息进行JSON格式化来完成这样的基础实现 3-1.服务器改造123456789101112131415161718192021222324252627282930313233343536373839404142var ws = require("nodejs-websocket")var port = 8000;var clientCount = 0;var server = ws.createServer(function (conn) &#123; console.log("New connection"); clientCount++; //临时区分用户使用 conn.nickname = '用户' + clientCount; var mes = &#123;&#125;; //封装消息 mes.type = "enter"; //消息类型 mes.data = conn.nickname + "进入房间"; //消息内容 broadcast(JSON.stringify(mes)); //封装消息发送函数 conn.on("text", function (str) &#123; var mes = &#123;&#125;; mes.type = "message"; mes.data = conn.nickname + "说:" + str; broadcast(JSON.stringify(mes)) &#125;); conn.on("close", function (code, reason) &#123; var mes = &#123;&#125;; mes.type = "leave"; mes.data = conn.nickname + "离开房间"; broadcast(JSON.stringify(mes)); &#125;); conn.on("error", function (err) &#123; console.log(err) &#125;)&#125;).listen(port);console.log("WebSocket Start Success:" + port);function broadcast(msg) &#123; server.connections.forEach(function (connection) &#123; connection.sendText(msg); &#125;)&#125; 如上,将消息封装为一个mes对象,通过定义其属性来完成分类消息的发送 type=&quot;enter&quot; 表示进入 type=&quot;leave&quot;表示离开 data表示封装的消息 发送时将消息格式化为JSON字符串发送到前段即可 3-2.客户端改造通过类型的判断,来实现想要的显示方式 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;Websocket&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;WebSocket&lt;/h1&gt;&lt;input type="text" id="sendText" /&gt;&lt;button id="sendBtn"&gt;发送&lt;/button&gt;&lt;script&gt; var webSocket=new WebSocket("ws://localhost:8000/"); var sendBtn = document.getElementById("sendBtn"); function showMessage(data,type)&#123; var div= document.createElement(div); div.innerHTML="&lt;br/&gt;"+data; if (type=="enter")&#123; div.style.color="blue"; &#125; if (type=="leave")&#123; div.style.color="red"; &#125; document.body.appendChild(div); &#125; webSocket.onopen=function () &#123; sendBtn.onclick=function () &#123; var sendText = document.getElementById("sendText").value; if (sendText)&#123; webSocket.send(sendText); &#125; &#125; &#125;; webSocket.onclose=function () &#123; &#125;; webSocket.onmessage=function (e) &#123; var mes=JSON.parse(e.data); showMessage(mes.data,mes.type); &#125;&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 以上是原生的WebSocket,如果需要更为丰富的通信,可以使用Socket.IO框架来实现 4.Socket.IO框架支持包括java/python/c++等多语言框架(底部连接) NodeJs案例 通过以下指令安装socket.io模块 (需要nodejs环境和c编译器环境) 4-1.服务端12345678910111213141516171819202122var server = require('http').createServer();var io = require('socket.io')(server);io.on('connection', function (socket) &#123; //socket 与客户端的连接 /** * emit发送指定格式消息,on接收指定格式消息 * 当emit为io.emit时,表示广播形式 * 自定义KV,可以发送对象,简化了消息格式化的过程 * 自定义on的K,简化了自定义消息分类的过程 */ socket.on('Dony15',function (data) &#123; console.log(data) socket.emit('Dony15',data); &#125;)&#125;);/** * 监听3000端口,此处演示为监听时可执行函数功能,也可不执行 * server.listen(3000) */server.listen(3000, function () &#123; console.log('listen on *：3000');&#125;); 注意emit当其为io中的函数socket.emit时,代表的是发送 当io.emit时,代表的是广播 4-2.客户端1234567891011121314151617&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;WebSocketIO&lt;/title&gt; &lt;script src="https://cdnjs.cloudflare.com/ajax/libs/socket.io/2.0.3/socket.io.js"&gt;&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;script&gt; var socket=io('ws://localhost:3000'); socket.on('Dony15',function (data) &#123; console.log(data); &#125;) socket.emit('Dony15',&#123;name:'长贵',age:30&#125;);&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 4-3.Socket.IO服务端改造1234567891011121314151617181920var server = require('http').createServer(); //创建http服务var io=require('socket.io')(server); //将服务包装为io的形式var PORT = 3000;var clientCount = 0;io.on('connection',function (socket) &#123; //通过io建立连接 clientCount++; socket.nickname = '用户' + clientCount; io.emit('enter',socket.nickname+'进入'); //广播 socket.on('message',function (str) &#123; //以message类型发消息 io.emit('message',socket.nickname+'说:'+str) &#125;); socket.on('disconnect',function () &#123; //特殊:disconnect类型表示断开 io.emit('leave',socket.nickname+'离开'); &#125;);&#125;);server.listen(PORT); 4-4.Socket.IO客户端改造123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;WebSocketIO&lt;/title&gt; &lt;script src="https://cdnjs.cloudflare.com/ajax/libs/socket.io/2.0.3/socket.io.js"&gt;&lt;/script&gt;//引入在线Socket.IO.js,开发建立离线使用&lt;/head&gt;&lt;body&gt;&lt;h1&gt;WebSocket&lt;/h1&gt;&lt;input type="text" id="sendText"/&gt;&lt;button id="sendBtn"&gt;发送&lt;/button&gt;&lt;script&gt; var socket = io("ws://localhost:3000/"); var sendBtn = document.getElementById("sendBtn"); //判断输出样式 function showMessage(data, type) &#123; var div = document.createElement(div); div.innerHTML = "&lt;br/&gt;" + data; if (type == "enter") &#123; div.style.color = "blue"; &#125; if (type == "leave") &#123; div.style.color = "red"; &#125; document.body.appendChild(div); &#125; //点击发送消息 sendBtn.onclick = function () &#123; var sendText = document.getElementById("sendText").value; if (sendText) &#123; socket.emit('message', sendText); &#125; &#125;; //Socket.IO监听消息 socket.on('enter',function (data) &#123; //进入房间 showMessage(data,'enter'); &#125;); socket.on('leave',function (data) &#123; //离开房间 showMessage(data,'leave'); &#125;); socket.on('message',function (data) &#123; //发送消息 showMessage(data,'message'); &#125;)&lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 4-5.示例截图 5.传送门慕课网WebSocket入门教程 https://www.imooc.com/learn/861 Socket.IO官网文档 https://socket.io/get-started/chat/ 多语言GitHub服务器示例社区维护 Java：https：//github.com/socketio/socket.io-client-java C ++：https：//github.com/socketio/socket.io-client-cpp Swift：https：//github.com/socketio/socket.io-client-swift Dart：https：//github.com/rikulo/socket.io-client-dart Python：https：//github.com/invisibleroads/socketIO-client .Net：https：//github.com/Quobject/SocketIoClientDotNet]]></content>
      <categories>
        <category>网络编程</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[微服务入门]]></title>
    <url>%2F2018%2F09%2F10%2F%E5%BE%AE%E6%9C%8D%E5%8A%A1%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[微服务入门1.概念在单体应用架构开发模式时期经常会在合作开发和测试上线等环节出现问题,主要是开发人员较多,代码合并/打包/依赖等等的更新和疏忽导致. 服务化架构可以比较好的处理这个问题,小团队负责各自小型的单体应用服务,全自动方式部署,服务间调用通过HTTP API通讯等,服务可以使用不同语言和数据库等,一定程度的解耦 微服务架构与服务化架构相比: 服务拆分粒度更细 服务独立部署 服务独立维护 服务治理能力要求高 微服务架构的选择需要根据实际需求和开发团队能力的情况,否则容易挖坑自己跳,影响业务的稳定性]]></content>
      <categories>
        <category>微服务</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Docker容器基础]]></title>
    <url>%2F2018%2F09%2F05%2FDocker%E5%AE%B9%E5%99%A8%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[Docker容器基础[TOC] 1.概念先进的软件管理容器引擎,统一文件系统 基本概念 镜像 Image 容器 Container 仓库 Repository 数据卷 2.结构镜像:相当于java中的类 容器:相当于java中的对象 仓库:相当于属于镜像的maven仓库 数据卷: 容器间及本地共享资源等,可以快速引用 镜像可以增删,配置环境/资源/等等所有静态内容,但是不能运行 容器则相当于镜像的实例,可以创建/使用/停止/删除/暂停等,一个镜像可以实例化无数的容器,容器间相互独立隔绝 容器最好保持无状态,存储数据要独立于容器的数据卷等方式,这样容器消亡后,数据不会丢失. 仓库:存储镜像,每个镜像的每个版本都有自己的标签,可以通过标签来使用,和maven仓库同一概念 3.操作原理CLI :命令窗口 RestAPI :Rest指令 DockerServer :Docker守护线程,核心程序 在CLI中使用Rest指令,即可轻松操纵Docker,简单方便 4.基本操作[创建/运行/停止/暂停/删除] docker create 创建Container docker start 运行Container docker run 创建并运行Container docker stop 停止Container docker kill 不友好的停止Container docker pause 暂停Container docker rm 删除Container(需要停止Container) docker rmi 删除Image镜像 [创建镜像] docker commit 容器提交为镜像 docker build 构建镜像 [查看] docker ps 查看所有运行中的Container docker ps –a 查看所有Container(包含未运行) docker images 查看所有顶级镜像(top-leve) docker images –a 查看所有镜像 [移植复制] docker save 只对镜像生效,每一个层都保存了元数据,可以看到镜像历史版本 docker export 排除元数据,创建一个tar文件,多层合一,没有历史版本 docker history 查看镜像历史版本 [???骚操作] docker exec 在运行中的容器执行一个新进程 docker inspect or 提取镜像或容器最顶级的元数据 5.使用链接详细基础指令操作连接,配图 http://dockone.io/article/783 详细Docker指令文档,配每个指令详情 http://www.runoob.com/docker/docker-command-manual.html]]></content>
      <categories>
        <category>框架</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Kafka基础]]></title>
    <url>%2F2018%2F09%2F05%2Fkafka%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[Kafka基础[TOC] 1.概念基于发布/订阅的消息系统(类似JMS特性,但设计实现却不同) 分布式/可分区/可复制/日志服务 官方文档↓ http://kafka.apache.org/documentation.html 2.场景1.Messaging 常规消息对于一些常规的消息系统,kafka是个不错的选择;partitons/replication和容错,可以使kafka具有良好的扩展性和性能优势.不过到目前为止,我们应该很清楚认识到,kafka并没有提供JMS中的”事务性””消息传输担保(消息确认机制)””消息分组”等企业级特性;kafka只能使用作为”常规”的消息系统,在一定程度上,尚未确保消息的发送与接收绝对可靠(比如,消息重发,消息发送丢失等) 2.Websit activity tracking 网站活动追踪的最佳工具可以将网页/用户操作等信息发送到kafka中.并实时监控,或者离线统计分析等 3.Log Aggregation 日志收集中心 kafka的特性决定它非常适合作为”日志收集中心”;application可以将操作日志”批量””异步”的发送到kafka集群中,而不是保存在本地或者DB中;kafka可以批量提交消息/压缩消息等,这对producer端而言,几乎感觉不到性能的开支.此时consumer端可以使hadoop等其他系统化的存储和分析系统. 3.结构producer:提供者将消息发布到Topic中,同时将决定该消息属于哪个Partition,比如基于”round-robin”方式或者通过其他的一些算法等. consumer:消费者每个Consumer都属于一个Consumer Group; Consumer Group中可以存在多个Consumer; Topic中的一个消息,只会被Group中的一个Consumer订阅; 即: 如果只有一个Consumer Group且组内有多个Consumer,那么相当于queue模式,消息会在group内负载均衡 如果有多个Consumer Group且组内只有一个Consumer,那么相当于topic模式,消息将会发布给所有Consumer 注意,一个partition内部不允许并发,组内如果有多于partition的consumer存在,将会有接受不到消息的consumer 建议partition数量为Consumer的倍数,这样可以提高性能和合理负载 topic:主题逻辑上的概念,消息类别,物理上存在的是partition partition:区一个topic可以有多个partition区,每个partition都有存储xxx.log文件, 任何发布到此partition的消息都会append到log文件中,如 00000000000.log 00000000001.log 00000000002.log 每次的Record消息都拥有offset偏移量(下标) 0 ,1, 2, 3, 4…相对于partition内的有序队列 offset: 偏移量每个partition中消息的偏移量,partition间互不影响,kafka通过offset来使用,时间复杂度为O(1),效率飞铲高 Record:消息每一条消息都由Key/value和时间戳构成 broker: Serverkafka和JMS不同的是,即使消息被消费,也不会立马消失,会根据broker中的日志配置,如配置了两天后删除,那么无论消息是否被消费,两天后都会被清除 Distribution:分布一个Topic可以有多个partition,每个partition都可以分配到集群的broker(负责partition读写操作)中, broker中可以配置partition备份个数(Replicated),来完成负载均衡/高可用 Replicated:备份基于partition的备份,可以备份在多个Server中 Guarantees:担保1.发送到partition中的消息,将会按照他接受的消息追加到日志中 2.对于消费者而言,消息的接受顺序和日志的追加顺序保持一致 3.如果Topic中的 replicationfactor(复制因子) 为N ,那么允许N-1个实例失效(待深入) 精华传送门,入门+原理+配置说明 https://www.cnblogs.com/likehua/p/3999538.html 4.Java/服务器中的使用详细使用代码地址 https://www.2cto.com/kf/201804/739331.html JAVA4-1.Maven依赖4.2.Producer Producer发布消息 producer拦截器 Producer自定义路由规则 4-3.Consumer 自动提交 手动提交 自定义Consumer拦截器 定义offset,提交回调方法 服务器 开启zookeeper（在安装目录下使用命令） 启动kafka（安装目录下使用命令） 创建topic 删除topic 查看topic名称列表 查看topic详情 创建Consumer 创建Producer 查询topic所有分区的offset值 查询kafka集群当前topic所有分区中的消息数目]]></content>
      <categories>
        <category>框架</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot整合篇]]></title>
    <url>%2F2018%2F08%2F24%2FSpring%20boot%E6%95%B4%E5%90%88%E7%AF%87%2F</url>
    <content type="text"><![CDATA[Spring boot整合篇[TOC] 1.优秀传送门1-1.第一章送给GitHub仓库,多种框架整合实战案例https://github.com/JeffLi1993/springboot-learning-example 公告该套框架整合尽量以一个工程进行叠加演示,一般情况下后面的整合都包含前面的基础整合 (上面 1 仓库实战是各个框架分离,可以参考学习) 2.基础整合搭建ZK/DubboDubbo Spring Boot Starter 致力于简化 Dubbo 应用在 Spring Boot 环境中的开发，主要包括自动装配（Auto-Configure）、外部化配置（Externalized-Configuration）以及生产准备（Actuator） 思路 在Spring boot中整合ZK/Dubbo,可以将ZK抽出来放在parent中,这样子模块只需要考虑dubbo的服务配置即可 利用强大的注解功能,运用Dubbo的@Service做服务端注解,@Reference做消费端注解,快速整合Springboot+ZK+Dubbo 2-1.基础搭建传送门https://www.bysocket.com/?p=1681 2-2.优秀开源项目https://github.com/dubbo/dubbo-spring-boot-project Springboot 多模块项目，整合了freemark,jsp,logback,mail,多数据源,mybatis,redis,docker,SSL等(待验证) https://github.com/dony15/springboot-dubbox 2-3.配置详解application.properties 简单基础配置 123456## Dubbo 服务提供者配置spring.dubbo.application.name=provider/consumerspring.dubbo.registry.address=zookeeper://127.0.0.1:2181spring.dubbo.protocol.name=dubbospring.dubbo.protocol.port=20880spring.dubbo.scan=org.spring.springboot. spring.dubbo.application.name 应用名称 spring.dubbo.registry.address 注册中心地址 spring.dubbo.protocol.name 协议名称 spring.dubbo.protocol.port 协议端口 spring.dubbo.scan dubbo 服务类包目录 详细配置清单 #根据 starter 工程源码，可以看出 application.properties 对应的 Dubbo 配置类 DubboProperties 。 12345678910111213@ConfigurationProperties(prefix = &quot;spring.dubbo&quot;)public class DubboProperties &#123;private String scan;private ApplicationConfig application;private RegistryConfig registry;private ProtocolConfig protocol;&#125; 包括了扫描路径、应用配置类、注册中心配置类和服务协议类 所以具体常用配置下扫描包路径：指的是 Dubbo 服务注解的服务包路径 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231## Dubbo 配置# 扫描包路径spring.dubbo.scan=org.spring.springboot.dubbo应用配置类：关于 Dubbo 应用级别的配置## Dubbo 应用配置# 应用名称spring.dubbo.application.name=xxx# 模块版本spring.dubbo.application.version=xxx# 应用负责人spring.dubbo.application.owner=xxx# 组织名(BU或部门)spring.dubbo.application.organization=xxx# 分层spring.dubbo.application.architecture=xxx# 环境，如：dev/test/runspring.dubbo.application.environment=xxx# Java代码编译器spring.dubbo.application.compiler=xxx# 日志输出方式spring.dubbo.application.logger=xxx# 注册中心 0spring.dubbo.application.registries[0].address=zookeeper:#127.0.0.1:2181=xxx# 注册中心 1spring.dubbo.application.registries[1].address=zookeeper:#127.0.0.1:2181=xxx# 服务监控spring.dubbo.application.monitor.address=xxx这里注意多个注册中心的配置方式。下面介绍单个注册中心的配置方式。 注册中心配置类：常用 ZooKeeper 作为注册中心进行服务注册。## Dubbo 注册中心配置类# 注册中心地址spring.dubbo.application.registries.address=xxx# 注册中心登录用户名spring.dubbo.application.registries.username=xxx# 注册中心登录密码spring.dubbo.application.registries.password=xxx# 注册中心缺省端口spring.dubbo.application.registries.port=xxx# 注册中心协议spring.dubbo.application.registries.protocol=xxx# 客户端实现spring.dubbo.application.registries.transporter=xxxspring.dubbo.application.registries.server=xxxspring.dubbo.application.registries.client=xxxspring.dubbo.application.registries.cluster=xxxspring.dubbo.application.registries.group=xxxspring.dubbo.application.registries.version=xxx# 注册中心请求超时时间(毫秒)spring.dubbo.application.registries.timeout=xxx# 注册中心会话超时时间(毫秒)spring.dubbo.application.registries.session=xxx# 动态注册中心列表存储文件spring.dubbo.application.registries.file=xxx# 停止时等候完成通知时间spring.dubbo.application.registries.wait=xxx# 启动时检查注册中心是否存在spring.dubbo.application.registries.check=xxx# 在该注册中心上注册是动态的还是静态的服务spring.dubbo.application.registries.dynamic=xxx# 在该注册中心上服务是否暴露spring.dubbo.application.registries.register=xxx# 在该注册中心上服务是否引用spring.dubbo.application.registries.subscribe=xxx服务协议配置类：## Dubbo 服务协议配置# 服务协议spring.dubbo.application.protocol.name=xxx# 服务IP地址(多网卡时使用)spring.dubbo.application.protocol.host=xxx# 服务端口spring.dubbo.application.protocol.port=xxx# 上下文路径spring.dubbo.application.protocol.contextpath=xxx# 线程池类型spring.dubbo.application.protocol.threadpool=xxx# 线程池大小(固定大小)spring.dubbo.application.protocol.threads=xxx# IO线程池大小(固定大小)spring.dubbo.application.protocol.iothreads=xxx# 线程池队列大小spring.dubbo.application.protocol.queues=xxx# 最大接收连接数spring.dubbo.application.protocol.accepts=xxx# 协议编码spring.dubbo.application.protocol.codec=xxx# 序列化方式spring.dubbo.application.protocol.serialization=xxx# 字符集spring.dubbo.application.protocol.charset=xxx# 最大请求数据长度spring.dubbo.application.protocol.payload=xxx# 缓存区大小spring.dubbo.application.protocol.buffer=xxx# 心跳间隔spring.dubbo.application.protocol.heartbeat=xxx# 访问日志spring.dubbo.application.protocol.accesslog=xxx# 网络传输方式spring.dubbo.application.protocol.transporter=xxx# 信息交换方式spring.dubbo.application.protocol.exchanger=xxx# 信息线程模型派发方式spring.dubbo.application.protocol.dispatcher=xxx# 对称网络组网方式spring.dubbo.application.protocol.networker=xxx# 服务器端实现spring.dubbo.application.protocol.server=xxx# 客户端实现spring.dubbo.application.protocol.client=xxx# 支持的telnet命令，多个命令用逗号分隔spring.dubbo.application.protocol.telnet=xxx# 命令行提示符spring.dubbo.application.protocol.prompt=xxx# status检查spring.dubbo.application.protocol.status=xxx# 是否注册spring.dubbo.application.protocol.status=xxx 2-4.@Service 服务提供者常用配置常用 @Service 配置的如下 version 版本 group 分组 provider 提供者 protocol 服务协议 monitor 服务监控 registry 服务注册 … 2-5.@Reference 服务消费者常用配置常用 @Reference 配置的如下 version 版本 group 分组 timeout 消费者调用提供者的超时时间 consumer 服务消费者 monitor 服务监控 registry 服务注册 2-6.总结A) 依赖问题目前测试的是Spring boot整合的dubbo依赖 12345&lt;dependency&gt; &lt;groupId&gt;io.dubbo.springboot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-dubbo&lt;/artifactId&gt; &lt;version&gt;1.0.0&lt;/version&gt;&lt;/dependency&gt; 注意该依赖中存在了dubbo和zk所有依赖包,不需要额外的配置zk,否则会引起jar包冲突,选择时可以通过插件查看 注意提供者如果使用事务,那么需要导入AOP依赖 1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-aop&lt;/artifactId&gt; &lt;/dependency&gt; B)配置问题注意ZK的注册地址 12#ZK地址spring.dubbo.registry.address=zookeeper://www.dony15.com:2181 注意服务包目录 1spring.dubbo.scan=com.dony15.service 该目录的提供者和消费者并不需要一致,扫描的是本工程内对应的注解位置 12345#服务包目录-提供者spring.dubbo.scan=com.dony15.service#服务包目录-消费者spring.dubbo.scan=com.dony15.dubbo C)注解问题@Service(version = “1.0.0”)和@Reference(version = “1.0.0”) 版本号可以写也可以不写,但是这两个注解注意是dubbo包下,并非spring包 D)解耦可以将通用的接口和实体类抽离出来打成jar进行依赖,优点 提高复用性 避免springboot的按需依赖原则造成的过多引用问题 如果不这样做,注解方式的引用需要在提供者和消费者都建立服务接口,降低dubbo的实用性(每次调用服务都需要将服务内容复制一遍) E)注解篇代码奉上Spring boot+Dubbo+ZK+JDBC+AOP+Mybatis+Restfulhttps://github.com/dony15/my_springboot_code ### 3.整合Thymeleaf/Freemarker3-1.代码注解篇代码奉上Thymeleaf+Freemarker+Spring boot+Dubbo+ZK+JDBC+AOP+Mybatis+Restfulhttps://github.com/dony15/my_springboot_code/tree/master/springboot-dubbo-mybatis-freemarker-thymeleaf 3-2.配置文件1234567891011121314151617181920212223...#Themleaf配置spring.thymeleaf.content-type=text/html spring.thymeleaf.mode =LEGACYHTML5#开发时关闭缓存,不然没法看到实时页面spring.thymeleaf.cache=false#配置静态资源路径spring.mvc.static-path-pattern=/static/**#DispatcherServlet 映射后缀(效果暂时没发现,并非伪静态技术)server.sevlet-path=*.html#freemarker模板spring.freemarker.allow-request-override=falsespring.freemarker.cache=falsespring.freemarker.check-template-location=truespring.freemarker.charset=UTF-8spring.freemarker.content-type=text/htmlspring.freemarker.expose-request-attributes=falsespring.freemarker.expose-session-attributes=falsespring.freemarker.expose-spring-macro-helpers=false 3-3.总结Thymeleaf和Freemarker可以共存,当然语法有区别,根据实际业务选择吧,整合基本没有难点,有时间可以了解一下他们的配置文件都是啥意思,百度很多,不留了 A)严谨问题Thymeleaf对标签格式要求比较严谨,如果需要可以通过依赖jar进行自动补充(前段不一定写的很完整哦) 123456&lt;!--ThymeLeaf代码补全--&gt; &lt;dependency&gt; &lt;groupId&gt;net.sourceforge.nekohtml&lt;/groupId&gt; &lt;artifactId&gt;nekohtml&lt;/artifactId&gt; &lt;version&gt;1.9.22&lt;/version&gt; &lt;/dependency&gt; B)伪静态思路通过过滤器实现伪静态化,优化SEO,项目在不值得做大量静态页面时,可以使用 一时半会没整合好,就注释掉了,大概这个思路( • ̀ω•́ )✧ 123456&lt;!--伪静态化优化方案,未实现--&gt; &lt;dependency&gt; &lt;groupId&gt;org.tuckey&lt;/groupId&gt; &lt;artifactId&gt;urlrewritefilter&lt;/artifactId&gt; &lt;version&gt;4.0.4&lt;/version&gt; &lt;/dependency&gt; C)依赖问题Thymeleaf的依赖中已经存在spring-boot-starter-web的依赖 因此spring-boot-starter-web可以无情的去掉了 D)FreemarkerUtil使用问题注意目录,如果写错了很尴尬哦.中间环节取不到值会提示异常,表达式值为null E)前后端分离如果你能参与项目的设计,那么通过/{page}进行较大程度的前后端分离,是个不错的点子哦,项目中有示例 4.整合 FastDFS+Nginx本次整合会增加数据库字段,当然包括代码层的更新咯.url存图片来演示FastDFS功能 新增字段city_image存储url,演示是1张图,实际上在实体类中已经为多图扩展做了准备(数组切割) 4-1.代码Thymeleaf+Freemarker+Spring boot+Dubbo+ZK+JDBC+AOP+Mybatis+Restful+FastDFS+Nginx https://github.com/dony15/my_springboot_code/tree/master/3springboot-fastDFS-Nginx 4-2.配置文件1tracker_server=www.dony15.com:22122 不足 Nginx地址没有提出来,开发时应该提出来通用的,方案有很多,放在配置文件或者指定类或接口都可以 都没有做太多限制,比如图片类型,大小等等.可以进行各种判断过滤,这里只演示基础的功能实现 FastDFS只演示了增加,还缺少删和改哦,可以自行百度 4-3.总结A)前段问题这次演示没有使用富文本,可以更直接的去尝试细节(脑壳疼), 注意文件上传的类型,使用ajax的时候很容易前后不兼容,400或者406等 该方案是不依赖于form表单的ajax 详细见源码 1234567891011121314151617181920212223242526272829&lt;input type="file" alt="插入图片" id="uploadFile"name="uploadFile" /&gt;-----------------------------------------------------/** 图片上传* 注意如果不加processData:false和contentType:false会报错*/$("#uploadFile").change(function () &#123; var imageForm = new FormData(); imageForm.append("uploadFile", $("#uploadFile").get(0).files[0]); $.ajax(&#123; type: 'POST', url: "/insertImage", data: imageForm, processData: false, // 告诉jQuery不要去处理发送的数据 contentType: false, // 告诉jQuery不要去设置Content-Type请求头 success: function (data) &#123; var result = JSON.parse(data); if (result.error==1) &#123; alert(result.message) &#125;else&#123; $("#image_echo").attr("src", result.url); $("#cityImage").attr("value", result.url); &#125; &#125;, error: function () &#123; alert("上传失败") &#125; &#125;);&#125;) B)基础逻辑基础的逻辑,文件上传到FastDFS,通过回调获取URI 再和Nginx的地址拼接成完整的URL响应给前段 前段拿到响应的URL和其他数据一起存进数据库 5.整合Redis5-1.代码Thymeleaf+Freemarker+Spring boot+Dubbo+ZK+JDBC+AOP+Mybatis+Restful+FastDFS+Nginx+Redis https://github.com/dony15/my_springboot_code/tree/master/springboot4-redis 总结A)依赖问题注意redis需要和jackson一起,否则异常 1org.springframework.beans.factory.BeanCreationException: Error creating bean with name &apos;functionDomainRedisTemplate&apos; defined in class path resource [com/dony15/config/RedisConfig.class]: Bean instantiation via factory method failed; nested exception is org.springframework.beans.BeanInstantiationException: Failed to instantiate [org.springframework.data.redis.core.RedisTemplate]: Factory method &apos;functionDomainRedisTemplate&apos; threw exception; nested exception is java.lang.NoClassDefFoundError: com/fasterxml/jackson/databind/ObjectMapper 我们可以看到这里的提示,缺少jacksion中的ObjectMapper 1nested exception is java.lang.NoClassDefFoundError: com/fasterxml/jackson/databind/ObjectMapper 因此依赖应该这样配套使用 12345678910&lt;!-- 整合redis --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- jackson --&gt; &lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;/dependency&gt; 当然,FastJSON也是需要的,主要用在处理业务的时候,选择怎么存的策略转换,比如List,Map,数组等的处理选择上 B)配置-单机版Springboot整合redis,需要注意RedisTemplate的注入,通过配置类来实现 将RedisUtil注入封装RedisTemplate 调用RedisUtil通过自动装配或者@Resource注入即可 12345678910111213141516171819202122232425262728#Redis#Matser的ip地址redis.host=www.dony15.com#端口号redis.port=6379#如果有密码redis.password=#客户端超时时间单位是毫秒 默认是2000redis.timeout=20000 #最大空闲数redis.maxIdle=300 #连接池的最大数据库连接数。设为0表示无限制,如果是jedis 2.4以后用redis.maxTotal#redis.maxActive=600#控制一个pool可分配多少个jedis实例,用来替换上面的redis.maxActive,如果是jedis 2.4以后用该属性redis.maxTotal=1000 #最大建立连接等待时间。如果超过此时间将接到异常。设为-1表示无限制。redis.maxWaitMillis=10000 #连接的最小空闲时间 默认1800000毫秒(30分钟)redis.minEvictableIdleTimeMillis=300000 #每次释放连接的最大数目,默认3redis.numTestsPerEvictionRun=1024 #逐出扫描的时间间隔(毫秒) 如果为负数,则不运行逐出线程, 默认-1redis.timeBetweenEvictionRunsMillis=30000 #是否在从池中取出连接前进行检验,如果检验失败,则从池中去除连接并尝试取出另一个redis.testOnBorrow=true #在空闲时检查有效性, 默认falseredis.testWhileIdle=true 6.整合Logback全局异常处理个人理解目前Logback仍为主流的异常处理工具,但是配置细粒度较为麻烦,并且难以分析,对于中小项目比较实用; 对于长期的中大型soa项目,建议添加Cat检测,更加细粒度控制大部分细节,使用也相对简单方便,如: 分布式细粒度实时监控 故障快速发现 系统问题分析 Cat报表展示消息类型 Transaction Event Heartbeat Metric Trace 各种埋点 丰富的模块警告通知/多种通知方式 … Cat待更新,在新篇章介绍 6-1.代码Thymeleaf+Freemarker+Spring boot+Dubbo+ZK+JDBC+AOP+Mybatis+Restful+FastDFS+Nginx+Redis+Logback https://github.com/dony15/my_springboot_code/tree/master/springboot5-logback 6-2.配置A)、Logger、appender及layout Logger作为日志的记录器，把它关联到应用的对应的context上后，主要用于存放日志对象，也可以定义日志类型、级别。 Appender主要用于指定日志输出的目的地，目的地可以是控制台、文件、远程套接字服务器、 MySQL、 PostreSQL、 Oracle和其他数据库、 JMS和远程UNIX Syslog守护进程等。 Layout 负责把事件转换成字符串，格式化的日志信息的输出。 B)、logger context 各个logger 都被关联到一个 LoggerContext，LoggerContext负责制造logger，也负责以树结构排列各 logger。其他所有logger也通过org.slf4j.LoggerFactory 类的静态方法getLogger取得。 getLogger方法以 logger 名称为参数。用同一名字调用LoggerFactory.getLogger 方法所得到的永远都是同一个logger对象的引用。 C)、有效级别及级别的继承 Logger 可以被分配级别。级别包括：TRACE、DEBUG、INFO、WARN 和 ERROR，定义于 ch.qos.logback.classic.Level类。如果 logger没有被分配级别，那么它将从有被分配级别的最近的祖先那里继承级别。root logger 默认级别是 DEBUG。 D)、打印方法与基本的选择规则 打印方法决定记录请求的级别。例如，如果 L 是一个 logger 实例，那么，语句 L.info(“..”)是一条级别为 INFO 的记录语句。记录请求的级别在高于或等于其 logger 的有效级别时被称为被启用，否则，称为被禁用。记录请求级别为 p，其logger的有效级别为 q，只有则当 p&gt;=q时，该请求才会被执行。 该规则是 logback 的核心。级别排序为： TRACE &lt; DEBUG &lt; INFO &lt; WARN &lt; ERROR。 Logback默认配置的步骤 (1). 尝试在 classpath 下查找文件 logback-test.xml； (2). 如果文件不存在，则查找文件 logback.xml； (3). 如果两个文件都不存在，logback 用 Bas icConfigurator 自动对自己进行配置，这会导致记录输出到控制台。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;configuration debug="false"&gt; &lt;!--定义日志文件的存储地址 勿在 LogBack 的配置中使用相对路径--&gt; &lt;property name="LOG_HOME" value="D:/temp/log" /&gt; &lt;!-- 控制台输出 --&gt; &lt;appender name="STDOUT" class="ch.qos.logback.core.ConsoleAppender"&gt; &lt;encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder"&gt; &lt;!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符--&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- 按照每天生成日志文件 --&gt; &lt;appender name="FILE" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;!--日志文件输出的文件名--&gt; &lt;FileNamePattern&gt;$&#123;LOG_HOME&#125;/TestWeb.log.%d&#123;yyyy-MM-dd&#125;.log&lt;/FileNamePattern&gt; &lt;!--日志文件保留天数--&gt; &lt;MaxHistory&gt;30&lt;/MaxHistory&gt; &lt;/rollingPolicy&gt; &lt;encoder class="ch.qos.logback.classic.encoder.PatternLayoutEncoder"&gt; &lt;!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度%msg：日志消息，%n是换行符--&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;!--日志文件最大的大小--&gt; &lt;triggeringPolicy class="ch.qos.logback.core.rolling.SizeBasedTriggeringPolicy"&gt; &lt;MaxFileSize&gt;10MB&lt;/MaxFileSize&gt; &lt;/triggeringPolicy&gt; &lt;/appender&gt; &lt;!-- show parameters for hibernate sql 专为 Hibernate 定制 --&gt; &lt;logger name="org.hibernate.type.descriptor.sql.BasicBinder" level="TRACE" /&gt; &lt;logger name="org.hibernate.type.descriptor.sql.BasicExtractor" level="DEBUG" /&gt; &lt;logger name="org.hibernate.SQL" level="DEBUG" /&gt; &lt;logger name="org.hibernate.engine.QueryParameters" level="DEBUG" /&gt; &lt;logger name="org.hibernate.engine.query.HQLQueryPlan" level="DEBUG" /&gt; &lt;!--myibatis log configure--&gt; &lt;logger name="com.apache.ibatis" level="TRACE"/&gt; &lt;logger name="java.sql.Connection" level="DEBUG"/&gt; &lt;logger name="java.sql.Statement" level="DEBUG"/&gt; &lt;logger name="java.sql.PreparedStatement" level="DEBUG"/&gt; &lt;!-- 日志输出级别 --&gt; &lt;root level="INFO"&gt; &lt;appender-ref ref="STDOUT" /&gt; &lt;appender-ref ref="FILE" /&gt; &lt;/root&gt; &lt;!--日志异步到数据库 --&gt; &lt;appender name="DB" class="ch.qos.logback.classic.db.DBAppender"&gt; &lt;!--日志异步到数据库 --&gt; &lt;!-- DriverManagerConnectionSource不支持DataSource --&gt; &lt;connectionSource class="ch.qos.logback.core.db.DriverManagerConnectionSource"&gt; &lt;!-- DataSourceConnectionSource支持DataSource,但是没整合上,这里有区别,使用时需要注意 --&gt; &lt;!--&lt;connectionSource class="ch.qos.logback.core.db.DataSourceConnectionSource"&gt;--&gt; &lt;!--连接池 --&gt; &lt;!--&lt;dataSource class="com.mchange.v2.c3p0.ComboPooledDataSource"&gt;--&gt; &lt;!--&lt;dataSource class="com.alibaba.druid.pool.DruidDataSource"&gt;--&gt; &lt;driverClass&gt;com.mysql.jdbc.Driver&lt;/driverClass&gt; &lt;url&gt;jdbc:mysql://localhost:3306/test01?useUnicode=true&amp;amp;characterEncoding=utf-8&amp;amp;useSSL=false&lt;/url&gt; &lt;user&gt;root&lt;/user&gt; &lt;password&gt;68835230&lt;/password&gt; &lt;!--&lt;/dataSource&gt;--&gt; &lt;/connectionSource&gt; &lt;/appender&gt; &lt;!-- 数据库日志输出级别 --&gt; &lt;root level="INFO"&gt; &lt;!--&lt;appender-ref ref="STDOUT" /&gt;--&gt; &lt;appender-ref ref="DB" /&gt; &lt;/root&gt;&lt;/configuration&gt; 6-3.建表语句如果输出到数据库,那么需要先建表 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950BEGIN;DROP TABLE IF EXISTS logging_event_property;DROP TABLE IF EXISTS logging_event_exception;DROP TABLE IF EXISTS logging_event;COMMIT; BEGIN;CREATE TABLE logging_event ( timestmp BIGINT NOT NULL, formatted_message TEXT NOT NULL, logger_name VARCHAR(254) NOT NULL, level_string VARCHAR(254) NOT NULL, thread_name VARCHAR(254), reference_flag SMALLINT, arg0 VARCHAR(254), arg1 VARCHAR(254), arg2 VARCHAR(254), arg3 VARCHAR(254), caller_filename VARCHAR(254) NOT NULL, caller_class VARCHAR(254) NOT NULL, caller_method VARCHAR(254) NOT NULL, caller_line CHAR(4) NOT NULL, event_id BIGINT NOT NULL AUTO_INCREMENT PRIMARY KEY );COMMIT; BEGIN;CREATE TABLE logging_event_property ( event_id BIGINT NOT NULL, mapped_key VARCHAR(254) NOT NULL, mapped_value TEXT, PRIMARY KEY(event_id, mapped_key), FOREIGN KEY (event_id) REFERENCES logging_event(event_id) );COMMIT; BEGIN;CREATE TABLE logging_event_exception ( event_id BIGINT NOT NULL, i SMALLINT NOT NULL, trace_line VARCHAR(254) NOT NULL, PRIMARY KEY(event_id, i), FOREIGN KEY (event_id) REFERENCES logging_event(event_id) );COMMIT; 6-5.加入全局异常处理器即可使用这里整合了ajax请求(需要ajax请求工具类) 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970package com.dony15.exception;import com.alibaba.fastjson.JSON;import com.dony15.utils.AjaxResponse;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.web.servlet.HandlerExceptionResolver;import org.springframework.web.servlet.ModelAndView;import javax.servlet.http.Cookie;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.io.IOException;import java.io.PrintWriter;/** * 统一的错误处理页面 */public class ExceptionHandler implements HandlerExceptionResolver &#123; private Logger logger = LoggerFactory.getLogger(this.getClass()); @Override public ModelAndView resolveException(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) &#123; logger.error(ex.getMessage(),ex); //ajax 请求 if (request.getHeader("x-requested-with") != null &amp;&amp; request.getHeader("x-requested-with").equalsIgnoreCase("XMLHttpRequest")) &#123; //如果是ajax请求响应头会有x-requested-with AjaxResponse ajaxResponse = new AjaxResponse(); ajaxResponse.setThrowable(ex); response.reset(); response.setContentType("application/json;charset=UTF-8"); PrintWriter out = null; try &#123; out = response.getWriter(); &#125; catch (IOException e) &#123; logger.error(e.getMessage(),e); &#125; out.print(JSON.toJSONString(ajaxResponse)); out.flush(); return null; &#125;else &#123;//非ajax请求跳转登陆页 ModelAndView mv = new ModelAndView(); Cookie[] cookies = request.getCookies(); if (cookies != null) &#123; for (int i = 0; i &lt; cookies.length; i++) &#123; if ("debug".equals(cookies[i].getName())) &#123; StackTraceElement[] stackTraces = ex.getStackTrace(); StringBuilder stackTraceStr = new StringBuilder(); stackTraceStr.append(ex.toString()) .append("&lt;br&gt;"); for (int j = 0; j &lt; stackTraces.length; j++) &#123; stackTraceStr.append(stackTraces[j].toString()) .append("&lt;br&gt;"); &#125; mv.getModel().put("stackTraces", stackTraceStr); &#125; &#125; &#125; mv.setViewName("error.html"); return mv; &#125; &#125; &#125; 6-6.总结A)依赖依赖没有问题,spring-boot默认首先支持logback,不需要引入,详细关系可以查看关系图 B)配置配置中需要注意的是,如果输出到数据库,那么除了配置文件外,需要在数据库中建好表哦 测试logback-test.xml 生产logback.xml 7.整合Quartz7-1.配置组成以下为Spring boot 方式的配置,不依赖于任何配置文件 JobFactory 配置类:Job注入到Spring中管理,否则无法与Spring中的Bean交互 QuartzConfig 配置类:Schedulder注入到Spring中管理 QuartzManager 工具管理类:封装调用Quartz的方法,如添加/修改/删除/查看 SelectCityJob Job类:任务类,处理业务逻辑的地方 注意此处配置的注入,实际上是将Job和Schedulder的工厂交给Spring管理,因为Quartz本身具有自己的容器,而自身的容器和Spring的容器互相没有关联,导致Bean无法沟通 可参考该文章: https://blog.csdn.net/xiaobuding007/article/details/80455187 ①个人仓库中代码集成演示:https://github.com/dony15/my_springboot_code/tree/master/springboot6-quartz%20X该演示是单独Quartz的集成,特意打穿MVC架构使用,问题和理解↓↓↓ 7-2.原理假设: 我们需要通过CMS界面来定时执行某个任务 ①中的集成实际上存在问题,首先我们知道Quartz底层调用Object.wait()方法来阻塞实现 那么使用Quartz就必须异步实现,否则将会影响程序的正常运行 该演示中的集成恰好没有实现异步,我们一起来看后果是什么: 首先:如果我们在Controller调用Job的方法,那么会抛出TimeOut超时,其实很容易理解, Object.wait()阻塞下是拿不到返回值的,该方法执行一段时间后,因为Controller中的请求本身有设定超时时间, 时间到了自然超时(防止死锁和同步的问题,spring本身的优化方案) 超时情况下,我们的Quartz实际上是生效了的,而且会生效两次,这是SpringMVC本身的机制,超时时仍然会刷新该方法 这个时候的Quartz会被再次执行,导致一个无关紧要的异常提示:该job已经存在 12345678910//错误示范public String getCityByName(String cityName) &#123; Map&lt;String, Object&gt; params = new HashMap&lt;&gt;(); params.put("cityName", cityName); //try..catch省略 quartzManager.addJob("getCityN", "cityJ", "getCityT", "cityT", SelectCityJob.class, "0/3 * * * * ?", params); return "SUCCESS"; &#125; 解决这两个问题我进行了如下尝试 不调用需要返回值 提前进行任务判断 (Job中设置@DisallowConcurrentExecution 禁止并发) 123456789101112131415//初次解决方案public void getCityByName(String cityName) &#123; Boolean exists = quartzManager.notExists("getCityT", "cityT"); Map&lt;String, Object&gt; params = new HashMap&lt;&gt;(); params.put("cityName", cityName); if (!exists)&#123; //如果存在该任务,那么不操作 System.out.println("存在该任务哦,可以尝试移除"); &#125;else&#123; //如果不存在,那么创建该任务 quartzManager.addJob("getCityN", "cityJ", "getCityT", "cityT", SelectCityJob.class, "0/3 * * * * ?", params); &#125; &#125; 实际上该方案只能解决第二个异常提示:该job已存在 对于SpringMVC超时问题仍然无法解决,那么问题的根源又回到了一开始,为什么Quartz要使用异步来处理 我们知道SpringMVC本身有一套完善的请求流程(13步),但是我们在handler中的业务操作同步阻塞, 导致后续的流程需要超时后才能执行 虽然以上两个异常提示都不会终止程序,也不会终止业务的实现,但是等待超时的时间和毫无意义的异常仍然不利于我们的开发 同理,在此代码中,Quartz和dubbo也会发生同步超时的状态 因此,我们可以重新屡一下 我们需要定时做些事情–&gt;选择定时框架Quartz(扔进大后方)–&gt;Controller难以做到异步通知(X)–&gt;选择MQ消息队列通知(√)–&gt;完美ヾ(ﾟ∀ﾟゞ) 7-3.正确代码使用修改后的完整代码 Thymeleaf+Freemarker+Spring boot+Dubbo+ZK+JDBC+AOP+Mybatis+Restful+FastDFS+Nginx+Redis+Logback+Quartz+ActiveMQ https://github.com/dony15/my_springboot_code/tree/master/springboot7-quartz%20%E2%88%9A-ActiveMQ 加入MQ ActiveMQ 注意:序列化的对象不可以直接用来做ActiveMQ的消息,需要添加配置允许 1234spring.activemq.packages.trust-all=true //允许所有 此处百度 //允许指定序列化类 详细可参考ActiveMQ文章 核心: ActiveMQ配置文件 ActiveProvider ActiveConsumer 7-4.结合数据库本次数据库结合并非持久化MQ消息,只是持久化Quartz的任务 假装结合一下,剩下的就是普通的业务逻辑了,说明书代替就好 7-5.ActiveMQ消息持久化到数据库http://topmanopensource.iteye.com/blog/1066383 7-6.RocketMQ资源传送门 https://blog.csdn.net/zhangll_2008/article/details/78657177 在MQ文章中记录个人总结 https://dony15.github.io/2018/08/24/MQ%E5%9F%BA%E7%A1%80%E4%B8%8E%E8%BF%90%E7%94%A8/ 7-7.整合Quartz总结A)结构问题注意其本身需要异步实现,否则基本上会出现超时问题 本身具有自己的容器,该容器与Spring容器无关,需要配置注入到Spring管理,才能使用Spring中的bean B)位置建议放在大后方,还是异步处理的问题,最好不要与其他框架同步]]></content>
      <categories>
        <category>Spring全家桶</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[MQ基础与运用]]></title>
    <url>%2F2018%2F08%2F24%2FMQ%E5%9F%BA%E7%A1%80%E4%B8%8E%E8%BF%90%E7%94%A8%2F</url>
    <content type="text"><![CDATA[MQ基础与运用[TOC] 一.MQ原理待整理 二.ActiveMQ部分1.概念消息队列:即时消息通信和延时消息通信 MQ 是一个消息中间件,常见的消息中间件有 ActiveMQ | RabbitMQ | kafka ActiveMQ底层基于java的JMS实现,在没有JMS之前的系统存在很多缺陷: 前后端同步问题,如果后台没有响应,则前段会一直阻塞等待 前后端生命周期耦合性太强,一方崩了则另一方也会崩 点对点通信,前段一次只能发送给某一个单独的服务对象,无法群发 JMS: (Java Message Service ) 通过消息中间件(MOM：Message Oriented Middleware ) 将消息发送给单独的消息服务器中,消息服务器会将消息存放在若干的队列/主题中,在合适的时候将消息发送给接收者.发送和接收是异步的,无需阻塞等待 在pub/sub的模式下,可以将消息发送给多个接收者 JMS类中定义了java访问中间件的接口,除此之外都是异常定义 Provider/MessageProvider：生产者 Consumer/MessageConsumer：消费者 PTP：Point To Point，点对点通信消息模型 Pub/Sub：Publish/Subscribe，发布订阅消息模型 Queue：队列，目标类型之一，和PTP结合 Topic：主题，目标类型之一，和Pub/Sub结合 ConnectionFactory：连接工厂，JMS用它创建连接 Connnection：JMS Client到JMS Provider的连接 Destination：消息目的地，由Session创建 Session：会话，由Connection创建，实质上就是发送、接受消息的一个线程，因此生产者、消费者都是Session创建的 2.应用| 异步处理 | 应用解耦 | 流量削锋 | 消息通讯 | 详情参考:https://blog.csdn.net/kingcat666/article/details/78660535 3.消息模式 P2P模式(点对点) Queue Pub/Sub模式(发布订阅) Topic Push模式(推拉模式,消息更新C/S中) Topic根据业务需求,也可以持久化 客户端启动时设置一个ClientID作为编号在服务器注册 可以将消息一致保存在服务器(可以持久化) 环境搭建文件中存放该操作方法 4.五种不同的消息正文格式JMS定义了五种不同的消息正文格式，以及调用的消息类型，允许你发送并接收以一些不同形式的数据，提供现有消息格式的一些级别的兼容性。 StreamMessage – Java原始值的数据流 MapMessage–一套名称-值对 TextMessage–一个字符串对象(常用) ObjectMessage–一个序列化的 Java对象 BytesMessage–一个字节的数据流 5.java中与Solr结合搭建..(省略) 注意：如果ActiveMQ整合spring使用不要使用activemq-all-5.12.0.jar包。 (5.12.0中许多包和spring相同,而且少方法,坑) 建议使用5.11.2 进入管理后台： http://www.fzs.com:8161/admin/ 用户名：admin 密码：admin 5-1.JMS规范下使用套路 基础原理导包 12345&lt;dependency&gt; &lt;groupId&gt;org.apache.activemq&lt;/groupId&gt; &lt;artifactId&gt;activemq-all&lt;/artifactId&gt; &lt;version&gt;5.11.2&lt;/version&gt;&lt;/dependency&gt; 提供方 123456789101112131415161718192021//1.创建工厂对象ConnectionFactory,需要指定IP和端口 ConnectionFactory connectionFactory= new ActiveMQConnectionFactory("tcp://www.fzs.com:61616"); //2.使用工厂对象创建Connection连接对象 Connection connection=connectionFactory.createConnection(); //3.开启连接,调用Connection对象的start方法 connection.start(); //4.创建Session对象 //(两个参数,|1.是否开启分布式事务(少,一般不开),如果开启,第二个参数无意义 | 2.应答模式(自动/手动)一般自动) Session session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE); //5.使用Session创建目的模式Destination (queue(点对点)|topic(广播一对多)) Queue queue = session.createQueue("DonY15_ActiveMQ_Message"); //6.使用Session创建生产者Producer MessageProducer producer = session.createProducer(queue); //7.创建Message对象(一般textMessage) TextMessage textMessage = session.createTextMessage("发出命令:全军粗鸡!✧*｡٩(ˊᗜˋ*)و✧*｡"); //8.发送消息(Message放到Producer) producer.send(textMessage); //9.关闭资源(Producer|Session|Connection) producer.close(); session.close(); connection.close(); 接收方 123456789101112131415161718192021222324252627282930313233//1.创建工厂对象ConnectionFactory连接MQ服务器ConnectionFactory connectionFactory=new ActiveMQConnectionFactory("tcp://www.fzs.com:61616");//2.使用工厂对象创建Connection连接对象Connection connection=connectionFactory.createConnection();//3.开启连接connection.start();//4.创建SessionSession session = connection.createSession(false, Session.AUTO_ACKNOWLEDGE);//5.使用Session创建目的模式Destination (queue(点对点)|topic(广播一对多))Queue queue = session.createQueue("DonY15_ActiveMQ_Message");//6.使用Session创建消费者对象MessageConsumer consumer = session.createConsumer(queue);//7.接收消息(监听)consumer.setMessageListener(new MessageListener() &#123; @Override public void onMessage(Message message) &#123;//8.打印结果 TextMessage textMessage= (TextMessage) message; try &#123; String text = textMessage.getText(); System.out.println(text); &#125; catch (JMSException e) &#123; e.printStackTrace(); &#125; &#125;&#125;);//9.等待接收消息System.in.read();//9.关闭连接consumer.close();session.close();connection.close();]]></content>
      <categories>
        <category>框架</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Cat监控基础使用]]></title>
    <url>%2F2018%2F08%2F23%2FCat%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[Cat监控基础使用[TOC] 1.概念基于Java开发的实时应用监控平台，提供了全面的监控服务和业务决策支持。 1-1.作用故障快速发现:主要面向运维，让运维直观到生产环境出现的问题；系统问题分析：面向开发，让开发能了解自己系统实时运行状态、发现问题。分布式追踪 1-2.CAT报表展示消息类型Transaction 适合记录跨越系统边界的程序访问行为,比如远程调用，数据库调用，也适合执行时间较长的业务逻辑监控，Transaction用来记录一段代码的执行时间和次数。 Event 用来记录一件事发生的次数，比如记录系统异常，它和transaction相比缺少了时间的统计，开销比transaction要小。 Heartbeat 表示程序内定期产生的统计信息, 如CPU%, MEM%, 连接池状态, 系统负载等。 Metric 用于记录业务指标、指标可能包含对一个指标记录次数、记录平均值、记录总和，业务指标最低统计粒度为1分钟。 Trace 用于记录基本的trace信息，类似于log4j的info信息，这些信息仅用于查看一些相关信息。 1-3.CAT架构图 追求简单、去中心化、分工协作，两层结构，除了依赖外部存储如HDFS和MySQL外，不依赖其他系统，CAT内部全面采用组件化设计和实现。CAT每天消息量巨大，一台机器是不能处理全部流量，必须分片处理，均衡负载。业务应用目前使用CAT API进行埋点，后台异步线程采用TCP长连接方式，将消息源源不断地传输到后台服务器；CAT具有fail-over(故障切换)机制，在后台服务器不可用时会自动切换到另一台可用服务器。CAT目前使用native协议做序列化和反序列化，将来会考虑支持更多协议，比如thrift。 1-4.消息处理消息处理分五个阶段：收集、传输、分析、存储和展示。 2.配置GitHub–&gt;Cat master 安装代码/mvnrepo 依赖jar包(Copy到maven库中)https://github.com/dianping/cat搭建教程有很多,如https://my.oschina.net/fuxingCoder/blog/750639注意下载master中也有搭建教程,较为详细 3.AOP埋点master中整合了框架埋点方案如dubbo/logback/mybatis/aop/url等等,说明书相当完善,自行参考 CAT以上完整分析https://blog.csdn.net/tankun940507994/article/details/56672385/ 4.使用4-1.设置Cat配置文件主要是对client.xml/server.xml/datasources.xml进行配置,如果使用公司现成的则该步已经搭建完成,无需配置 4-2.引入master打包生成的jar包客户端和核心jar 1234567891011&lt;!--cat实时监控--&gt;&lt;dependency&gt; &lt;groupId&gt;com.dianping.cat&lt;/groupId&gt; &lt;artifactId&gt;cat-client&lt;/artifactId&gt; &lt;version&gt;2.0.0&lt;/version&gt;&lt;!--根据自己打包的版本号进行修改--&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.dianping.cat&lt;/groupId&gt; &lt;artifactId&gt;cat-core&lt;/artifactId&gt; &lt;version&gt;2.0.0&lt;/version&gt;&lt;/dependency&gt; 4-3.配置Cat过滤器这是整合Springboot的配置方案,如果是普通整合,只需要web.xml中添加servlet过滤器即可 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354package com.dony15.controller;import com.dianping.cat.servlet.CatFilter;import com.dony15.exception.ExceptionHandler;import org.springframework.boot.web.servlet.FilterRegistrationBean;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.core.Ordered;import org.springframework.http.HttpStatus;import org.springframework.web.servlet.HandlerExceptionResolver;import org.springframework.web.servlet.config.annotation.ViewControllerRegistry;import org.springframework.web.servlet.config.annotation.WebMvcConfigurerAdapter;import javax.servlet.DispatcherType;import java.util.List;/** * Created by ying on 2017/1/16. */@Configurationpublic class WebMvcConfigurer extends WebMvcConfigurerAdapter &#123; @Override public void configureHandlerExceptionResolvers(List&lt;HandlerExceptionResolver&gt; exceptionResolvers) &#123; exceptionResolvers.add(new ExceptionHandler()); &#125; /** * cat 过滤器 * @return */ @Bean public FilterRegistrationBean catFilterRegistrationBeanConfig()&#123; FilterRegistrationBean registrationBean = new FilterRegistrationBean(); registrationBean.setFilter(new CatFilter()); registrationBean.addUrlPatterns(&quot;/*&quot;); registrationBean.setDispatcherTypes(DispatcherType.FORWARD, DispatcherType.REQUEST); registrationBean.setName(&quot;catFilter&quot;); return registrationBean; &#125; /** * 一种增加心跳的方式 也可以用controller来做 * @param registry */ @Override public void addViewControllers( ViewControllerRegistry registry ) &#123; registry.addViewController( &quot;/heartBeat&quot; ).setStatusCode(HttpStatus.OK); registry.setOrder( Ordered.HIGHEST_PRECEDENCE ); super.addViewControllers( registry ); &#125;&#125; 4-5.resources中添加配置新建META-INF/app.properties文件 1app.name=demo01 配好的cat,使用相当简单,引入jar包,添加过滤,添加一行app.name配置即可完成基础操作 注意需要将script配置文件放入/data/appdatas/cat中 也可以使用脚本中的一键安装script中(未测)]]></content>
      <categories>
        <category>框架</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[IDE基础-Eclipse]]></title>
    <url>%2F2018%2F08%2F08%2FIDE%E5%9F%BA%E7%A1%80-Eclipse%2F</url>
    <content type="text"><![CDATA[IDE基础[TOC] 1.一楼送给自己用习惯IDEA,很长时间没有使用Eclipse了,马上换工作可能又要用回Eclipse,写一篇回归文档,重新巩固一下Eclipse的基础使用,简单粗暴,新手不宜观看 ಠ_ಠ我有一个特异功能！！(Maven+基础快捷键篇) 2.Maven搭建注意开始选择简单maven,否则建出来的项目包可能不完整,主要是jre可能不会自动识别,导致message问题不显示 本次maven搭建是简单的粗粒度模块切分,主要是熟悉parent继承和聚合项目在Eclipse中的搭建方式和BUG坑 2-1.从首选项导入Maven 2-2.Maven配置 2-3.搭建Server服务器软件 服务器软件可以这样搭↑↑↑,但是实际中我们建议使用maven的tomcat插件↓↓↓来使用(模块较多时效果更好) 12345678910111213&lt;!-- 在聚合pom工程配置tomcat插件统一启动即可(减少其他模块频繁打包) --&gt; &lt;build&gt; &lt;plugins&gt; &lt;plugin&gt; &lt;groupId&gt;org.apache.tomcat.maven&lt;/groupId&gt; &lt;artifactId&gt;tomcat7-maven-plugin&lt;/artifactId&gt; &lt;configuration&gt; &lt;path&gt;/&lt;/path&gt; &lt;port&gt;8080&lt;/port&gt; &lt;/configuration&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 2-4.新建Maven工程(parent)(pom) 2-4.parent配置 (pom) 2-5.common配置 (jar) 2-6.mvc聚合配置 (pom) 此处三层架构没有拆解,统一扔到聚合里了,正常可以将模块拆分 注意聚合中的模块大多数会用到common中的工具类或者实体类,这里的pom文件需要依赖common,后面不在提示依赖关系(根据业务逻辑进行依赖jar和模块即可) 2-7.聚合模块pojo(jar) 2-8.聚合模块dao(省略)/service(jar) 2-9.聚合模块controller(war) 注意问题:此时webapp为空(因为选择的基本maven) 右键war模块,选择JavaEE工具重新部署(点一下就行了),webapp将会注入内容(web-inf等) 2-10.聚合结构完成 2-end.总结Eclipse的maven搭建并不是很复杂,主要是用习惯了IDEA后,经常会忘记Eclipse搭建的坑,比如 建立的模块少包(没有选简单maven模板,jre没有注入) 建立的模块少webapp资源(还是bug,解决方案很多) 合理的选择打包方式(打pom,src中存在的是site(别紧张,没啥用)) 建议全部项目都以简单Maven模板的方式搭建,区别在于打包方式的不同pom/jar/war 3.基础快捷键1234567891011121314151617181920212223242526272829303132333435363738394041424344[核心快捷键]Alt+/ 代码助手/单词补全Ctrl+1 快速修正Shift+F2 打开外部Java文档Ctrl+Shift+O 快速导包/清理无效包------------(**查看**)----------------Ctrl+H 搜索对话框Ctrl+O 快速Outline结构显示全局 查找并替换 Ctrl+F Ctrl+e 快速切换编辑页面------------(**Alt修改代码**)----------------Ctrl+D 删除行Alt+Up/Down 上下移动选中行Ctrl+Alt+↑/↓ 复制当前行到上/下一行(复制增加)Alt+← 前一个编辑的页面Alt+→ 下一个编辑的页面(当然是针对上面那条来说了)----------------------------Ctrl+Shift+F 格式化当前代码Alt+Shift+M 抽取方法 (这是重构里面最常用的方法之一了,尤其是对一大堆泥团代码有用)----------------------------Ctrl+Shift+S 保存所有-------------------------[辅助使用]-----------------------------------Ctrl+Shift+X/Y 改变大小写Alt+Shift+T 显示重构菜单Ctrl+P 全局打印-------------------------[Debug辅助]-----------------------------------F5：Step Into（debug）F6：Step over（debug）F7：Step return（debug）F8：Resume（debug）F11：debug上一个应用（debug）]]></content>
      <categories>
        <category>IDE</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Linux基础操作文档]]></title>
    <url>%2F2018%2F08%2F08%2FLinux%E5%9F%BA%E7%A1%80%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[Linux基础操作文档[TOC] 1.User操作1234sudo(Superuser do) 超级用户操作passwd 修改密码chgrp(Change group) 改变用户组ps(Process Status)进程状态 2.文件/端口系统的增删改查12345678910111213141516171819202122232425262728293031323334353637383940//增mkdir/mkdirs 创建文件夹/指定路径文件夹vim 创建/打开指定文件tar(解压) -zxvf(每个字母都有意义) 压缩包名字.tar.gz结尾//删rm umount(Unmount) 卸载rm -f file1 删除一个叫做 &apos;file1&apos; 的文件&apos; rmdir dir1 删除一个叫做 &apos;dir1&apos; 的目录&apos; rm -rf dir1 删除一个叫做 &apos;dir1&apos; 的目录并同时删除其内容 rm -rf dir1 dir2 同时删除两个目录及它们的内容 //改cp 拷贝粘贴mv xxx xxx 移动/重命名//****查****----------------------------------------------------------[普通查看]cd 查看各种目录ls(list) 查看当前文件夹cat 查看文件内容pwd 当前文件夹全路径----------------------------------------------------------[动态查看文本]tail -2 file1 查看一个文件的最后两行 tail -f /var/log/messages 实时查看被添加到一个文件中的内容 ----------------------------------------------------------[查看内存]cat /proc/meminfo 查看详细内存使用情况 free -h 快速查询内存使用(单位自动换算)----------------------------------------------------------[核心组成]/etc 存放配置文件的地方.配置文件目录/dev(DEVices) 设备/usr = Unix Shared Resources 共享资源 3.文本操作123456789i 进入insert状态esc 进入文本操作:0 光标回到第一行:$光标回到最后一行/dsf 搜索dsf这个字符串:u 撤销,相当于ctrl+Z:q 退出:wq 保存并退出注意:断电时需要删除临时文件.xxx.swp 4.网络操作12ping 测试ping值ifconfig 查看网关地址等 5.端口及PID查询12345678910------------------------------------------------------------------[查看进程]# ps -aux|grep java //显示所有进程名中包含java字符串的进程------------------------------------------------------------------[查看端口]netstat -t 显示TCP协议的连接情况。netstat -u 显示UDP协议的连接情况。netstat -tln 查看linux的端口使用情况netstat -aln|grep 8080 查看8080端口占用情况 6.软件管理123456789101112131415161718192021222324252627282930311.源码安装：tar -zxvf filename.tar.gz 解压make 编译make install 安装make clean 清除1make distclean 清除22.rpm(二进制包)安装：(安装本地自己下载的rpm软件包，自己解决软件之间的依赖。) rpm -ivh xxx.rpm 安装 rpm -Uvh xxx.rpm 升级/** 一般用不到 rpm -e xxx.rpm 反安装 rpm -qpi xxx.rpm 查询软件包的详细信息 rpm -qf xxx.rpm 查询某个文件是属于那个rpm包 rpm -qpl xxx.rpm 查该软件包会向系统里面写入哪些文件**/3.yum安装：(在线安装，可以解决依赖问题。) 通过yum安装的php，是不需要手动配置环境变量的。配置文件目录在/etc/php.ini 通过yum安装的apache2，配置文件目录在/etc/httpd/conf/ rm -f /etc/httpd/conf.d/welcome.conf /var/www/error/noindex.html #删除默认测试页------------------------------------------------------------------[关闭]kill 进程号 正常关闭 (正常建议使用此命令)kill -9 进程号 强制关闭 (暴力关闭) 7.开发软件操作12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152/etc/init.d/sshd start 启动sshd服务器ps -ef|grep (服务名)如redis 服务查询(通用)tomcat service tomcat stop 停止 service tomcat start 启动 tail -f logs/catalina.out 卡特琳娜日志查询 在tomcat根目录下查看http://www.dony15.com:8080/dubbo-admin-2.8.4/governance/services 查看dubbo服务管理mysql service mysql stop 停止 service mysql start 启动zookeeper(目录)./zkServer.sh start 启动./zkServer.sh status 查看状态./zkServer.sh stop 停止redis(目录) ./redis-server redis.conf 启动 ./redis-cli -p 6379 连接 ./bin/redis-cli -p 7001 shutdown 停止redis集群(目录) ./start-cluster.sh 启动 ./stop-cluster.sh 停止 ./redis-cli -h 127.0.0.1 -p 7001 -c -a 123456 远程连接(密码可删) ./redis-trib.rb add-node 127.0.0.1:7007 127.0.0.1:7001 追加节点(需要注意步骤较多) ./redis-trib.rb del-node 127.0.0.1:7001 a06a54ab354327cd9920fa8b14a7b8b71a4d445a 删除redis哨兵 ???tracker /usr/local/software/fastdfs-master/init.d/fdfs_trackerd start 启动 ps -ef | grep fdfs_trackerd 查看状态storage /usr/local/software/fastdfs-master/init.d/fdfs_storaged start 启动 ps -ef | grep fdfs_storaged 查看状态nginx nginx 启动 nginx -s stop 停止 nginx -s reload 重新启动activeMQ ./activemq start 启动(bin目录下) ./activemq stop 停止 ./activemq status 查看状态 访问服务器的8161端口 http://www.vm.com:8161/admin/ 用户名密码都是admin 8.redis集群内部指令123查看info replication 查看节点信息quit 退出 9.防火墙设置(端口)123456使用iptables开放如下端口/sbin/iptables -I INPUT -p tcp --dport 22 -j ACCEPT保存/etc/rc.d/init.d/iptables save重启服务service iptables restart 10.服务器备用url12345678[solor]http://www.fzs.com:8080/solr/admin.html[dubbo]http://www.fzs.com:8080/dubbo-admin/ u:root p:root[activeMQ]http://www.fzs.com:8161/admin/index.jsp u:admin p:admin 11.Linux连接问题解决1234567891011Xshell问题*/etc/init.d/sshd start 启动sshd服务器/etc/init.d/iptables stop 关闭防火墙配置hostsvim /etc/hostsmysql远程连接失败问题*use mysql; UPDATE user SET Password=PASSWORD(&apos;123456&apos;) where USER=&apos;root&apos;;flush privileges; End.各种软件/框架连接问题1.MySQL连接问题123456789101112131415161718192021222324252627282930313233343536373839MySQL远程访问问题(搭配上面):授权法。例如，你想myuser使用mypassword从任何主机连接到mysql服务器的话。GRANT ALL PRIVILEGES ON *.* TO &apos;myuser&apos;@&apos;%&apos; IDENTIFIED BY &apos;mypassword&apos; WITH GRANT OPTION;FLUSH PRIVILEGES;如果你想允许用户myuser从ip为192.168.1.6的主机连接到mysql服务器，并使用mypassword作为密码GRANT ALL PRIVILEGES ON *.* TO &apos;myuser&apos;@&apos;192.168.1.3&apos; IDENTIFIED BY &apos;mypassword&apos; WITH GRANT OPTION;FLUSH PRIVILEGES;如果你想允许用户myuser从ip为192.168.1.6的主机连接到mysql服务器的dk数据库，并使用mypassword作为密码GRANT ALL PRIVILEGES ON dk.* TO &apos;myuser&apos;@&apos;192.168.1.3&apos; IDENTIFIED BY &apos;mypassword&apos; WITH GRANT OPTION;FLUSH PRIVILEGES; 我用的第一个方法,最后执行一个语句 mysql&gt;FLUSH RIVILEGES 使修改生效.就可以了另外一种方法,不过我没有亲自试过的,在csdn.net上找的,可以看一下.在安装mysql的机器上运行：1、d:/mysql/bin/&gt;mysql -h localhost -u root //这样应该可以进入MySQL服务器2、mysql&gt;GRANT ALL PRIVILEGES ON *.* TO &apos;root&apos;@&apos;%&apos; WITH GRANT OPTION //赋予任何主机访问数据的权限3、mysql&gt;FLUSH PRIVILEGES //修改生效4、mysql&gt;EXIT //退出MySQL服务器这样就可以在其它任何的主机上以root身份登录啦！来源： https://blog.csdn.net/zyj405569395/article/details/53614356]]></content>
      <categories>
        <category>Linux基础</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[volatile基础]]></title>
    <url>%2F2018%2F08%2F05%2Fvolatile%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[volatile基础[TOC] 1.概念A.轻量级同步机制,与synchronized重量级锁不同,不会引起线程的上下文切换,但是需要注意两个问题: 复合类操作无法同步 如 count++ 在其他变量的不变式中包含则无法同步 如常量和条件(后续再深入理解不变式) B.阻止指令重排 2.内存可见性volatile是轻量级的同步机制,相比于synchronized重量级锁来说 ,能够节省更大的消耗,虽然在总体能力上不如synchronized安全,但是在一定场合也具有自己的优势,合理的利用volatile能够让程序更高效的运行 volatile修饰的属性对整个内存来说是可见的,即:每个线程获取到的该数据都是最新的(此处内存分配属逻辑模拟) A线程(工作内存)→} 主内存空间 B线程(工作内存)→ 对线程来说,正常的共享资源会从主内存中copy到自己的工作内存中,这里如同内存和硬盘的区别,可以更加快速的使用copy的资源,但是此时的工作内存对于其他线程是不可见的,因此很容易因为并发产生数据异常 当使用volatile时,该共享资源每次更新都会被同步到主内存空间中,对于其他线程来说,该数据始终是最新的,因此可以一定程度的解决并发的问题,但是有一些情况volatile无法直接实现,如非复合类操作 3.解决count++原子性问题count++之类的非符合类操作,volatile无法保证他的原子性问题,使共享资源无法实时同步,进而引发并发问题 复合类操作过程: 读取 运算 赋值 因为volatile本身只是轻量级的同步机制,并非锁机制,当复合类操作的过程中可能有其他线程继续操作该资源,从而导致并发问题 解决:循环CAS 方案(待研究) 4.阻止指令重排指令重排是java优化程序性能的一种手段(提供并行度),但是重排也有一定的规则: 指令重排不会对存在依赖关系的数据进行操作 ​ 如a=1;b=a 指令重排不会对单线程下的结果进行操作 ​ 如a=1;b=2;c=a+b; 被volatile修饰的变量,在编译时,会插入内存屏障来阻止处理器等对数据的指令重排,阻止指令重排规则: 第一个是volatile读操作时,无论第二个是什么操作,都会阻止指令重排 第二个是volatile写操作时,无论第一个是什么操作,都会阻止指令重排 第一个是volatile写操作,得个是volatile读操作时,都会阻止指令重排]]></content>
      <categories>
        <category>SE基础</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Spring Cloud基础使用]]></title>
    <url>%2F2018%2F07%2F20%2FSpring%20Cloud%E5%9F%BA%E7%A1%80%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[Spring Cloud基础使用[TOC] 1.概念1-1.什么是微服务?微服务英文名称Micro service，Micro service架构模式就是将整个Web应用组织为一系列小的Web服务。 这些小的Web服务可以独立地编译及部署，并通过各自暴露的API接口相互通讯。 它们彼此相互协作，作为一个整体为用户提供功能，却可以独立地进行扩展。 1-2.微服务架构需要的功能或使用场景 将整个系统根据业务逻辑拆分为多个子系统 每个子服务器可以部署多个应用,应用之间使用负载均衡 需要一个服务注册中心,所有的应用都在注册中心注册,负载均衡也在注册中心通过策略实现 所有的客户端都通过同一个网关地址访问后台的服务，通过路由配置，网关来判断一个URL请求由哪个服务处理。请求转发到服务上的时候也使用负载均衡。 服务之间有时候也需要相互访问。例如有一个用户模块，其他服务在处理一些业务的时候，要获取用户服务的用户数据。 需要一个断路器，及时处理服务调用时的超时和错误，防止由于其中一个服务的问题而导致整体系统的瘫痪。 还需要一个监控功能，监控每个服务调用花费的时间等。 目前主流的微服务框架：Dubbo、 SpringCloud、thrift、Hessian等，目前国内的中小企业用的大多数都是Dubbo，SpringCloud 1-3.Spring Colud概念 springCloud是基于SpringBoot的一整套实现微服务的框架。 他提供了微服务开发所需的 配置管理、服务发现、断路器、智能路由、微代理、控制总线、全局锁、决策竞选、分布式会话和集群状态管理等组件。 最重要的是， 跟spring boot框架一起使用的话，会让你开发微服务架构的云服务非常好的方便。 2.组成 2-1.Spring cloud子项目包括 Spring Cloud Config：配置管理开发工具包，可以让你把配置放到远程服务器，目前支持本地存储、Git以及Subversion。 Spring Cloud Bus：事件、消息总线，用于在集群（例如，配置变化事件）中传播状态变化，可与Spring Cloud Config联合实现热部署。 Spring Cloud Netflix：针对多种Netflix组件提供的开发工具包，其中包括Eureka、Hystrix、Zuul、Archaius等。 Netflix Eureka：云端负载均衡，一个基于 REST 的服务，用于定位服务，以实现云端的负载均衡和中间层服务器的故障转移。 Netflix Hystrix：容错管理工具，旨在通过控制服务和第三方库的节点,从而对延迟和故障提供更强大的容错能力。 Netflix Zuul：边缘服务工具，是提供动态路由，监控，弹性，安全等的边缘服务。 Netflix Archaius：配置管理API，包含一系列配置管理API，提供动态类型化属性、线程安全配置操作、轮询框架、回调机制等功能。 Spring Cloud for Cloud Foundry：通过Oauth2协议绑定服务到CloudFoundry，CloudFoundry是VMware推出的开源PaaS云平台。 Spring Cloud Sleuth：日志收集工具包，封装了Dapper,Zipkin和HTrace操作。 Spring Cloud Data Flow：大数据操作工具，通过命令行方式操作数据流。 Spring Cloud Security：安全工具包，为你的应用程序添加安全控制，主要是指OAuth2。 Spring Cloud Consul：封装了Consul操作，consul是一个服务发现与配置工具，与Docker容器可以无缝集成。 Spring Cloud Zookeeper：操作Zookeeper的工具包，用于使用zookeeper方式的服务注册和发现。 Spring Cloud Stream：数据流操作开发包，封装了与Redis,Rabbit、Kafka等发送接收消息。 Spring Cloud CLI：基于 Spring Boot CLI，可以让你以命令行方式快速建立云组件。 3.特点 约定优于配置 开箱即用、快速启动 适用于各种环境 轻量级的组件 组件支持丰富，功能齐全 4.Dubbo和Spring Cloud对比**传送门:https://www.hellojava.com/a/1040.html]]></content>
      <categories>
        <category>Spring全家桶</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[SQL银行模拟语句整合]]></title>
    <url>%2F2018%2F07%2F15%2FSQL%E9%93%B6%E8%A1%8C%E6%A8%A1%E6%8B%9F%E8%AF%AD%E5%8F%A5%E6%95%B4%E5%90%88%2F</url>
    <content type="text"><![CDATA[SQL银行模拟语句整合123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644645646647648649650651652653654655656657658659660661662663664665666667668669670671672673674675676677678679680681682683684685686687688689690691692693694695696697698699700701702703704705706707708709710711712713714715716717718719720721722723724725726727--创建表空间create tablespace bankspace datafile &apos;E:\bank\bank.dbf&apos; size 10m autoextend on;--创建用户bankusercreate user bankuser identified by bankuser default tablespace bankspace;--drop table tradeinfo;drop table userInfo;drop table cardInfo;drop table Deposit;--为用户授权grant connect,resource to bankuser;--创建用户信息表create table userInfo --用户信息表(customerID number not null,customerName varchar2(8),PID varchar2(18) not null,telephone varchar2(20) not null,address varchar(50));--创建银行卡信息表create table cardinfo(cardid char(19) NOT NULL,curid varchar(10)NOT NULL,--币种savingid number NOT NULL,openDate date NOT NULL,openMoney number NOT NULL,balance number NOT NULL,pass char(6)NOT NULL,isreportloss number(1)NOT NULL,--判断卡是否挂失customerID number NOT NULL);select * from userInfo;--创建交易信息表create table tradeInfo (tradeDate DATE NOT NULL,tradeType Char(4) NOT NULL,cardID CHAR(19) NOT NULL,tradeMoney NUMBER NOT NULL,remark LONG);select * from tradeInfo;--创建存款类型表create table deposit (savingID NUMBER NOT NULL,savingName varchar(20)NOT NULL,descrip varchar(50));/*为deposit表添加约束*/alter table deposit add constraint pa_savingIDprimary key(savingid);/*为userInfo添加约束*/--主键alter table userinfo add constraint pk_customerIDprimary key(customerID);--check约束，身份证号长度alter table userinfo add constraint ck_pidcheck(length(pid)=18 or length(pid)=15);--unique唯一约束，身份证号唯一alter table userinfo add constraint uq_pid unique(pid);--check约束，电话号码alter table userinfo add constraint ck_telephonecheck(regexp_like(telephone,&apos;(^\d&#123;3,4&#125;-\d&#123;7,8&#125;$)|(^\d&#123;11&#125;$)&apos;));--查看创建的约束select * from user_constraints where table_name=&apos;DEPOSIT&apos;;select * from user_constraints where table_name=&apos;USERINFO&apos;;/*为cardInfo添加约束*/--主键alter table cardinfo add constraint pk_cardidprimary key(cardid);--check约束，卡号alter table cardinfo add constraint ck_cardIDcheck(regexp_like(cardid,&apos;1010 3576 \d&#123;4&#125; \d&#123;4&#125;&apos;));--修改表中字段alter table cardInfo modify (curid varchar(10) default &apos;RMB&apos;);alter table cardInfo modify (opendate varchar(10) default sysdate);--预存金额大于等于1alter table cardinfo add constraint ck_openmoneycheck(openmoney&gt;=1);--check 约束 ，预存金额大于等于1alter table cardinfo add constraint ck_balancecheck(balance&gt;=1);--密码检查约束，密码必须是六位数字alter table cardinfo add constraint ck_passcheck(regexp_like(pass,&apos;^[0-9]&#123;6&#125;$&apos;));--密码默认6个8alter table cardinfo modify (pass char(6) default &apos;888888&apos;);--是否挂失默认值0alter table cardinfo modify (isreportloss number(1) default 0);--外键约束alter table cardinfo add constraint fk_customeridforeign key(customerid)references userInfo(customerid);--外键约束alter table cardinfo add constraint fk_savingidforeign key(savingid)references deposit(savingid);/*为tradeinfo 表添加约束*/--交易类型(存入、支取)alter table tradeinfo add constraint ck_tradetypecheck(tradetype in (&apos;存入&apos;,&apos;支取&apos;));--外键alter table tradeinfo add constraint fk_cardIDforeign key(cardid)references cardInfo(cardId);--交易金额大于0alter table tradeinfo add constraint ck_tradeMoneycheck(tradeMoney&gt;0);--交易时间alter table tradeinfo modify (tradeDate date default sysdate);/***************************************************************************************************//* 插入测试数据 *//***************************************************************************************************//* ========================== 测试数据 ========================== */--存款类型INSERT INTO deposit (savingID,savingName,descrip) VALUES (1,&apos;活期&apos;,&apos;按存款日结算利息&apos;);INSERT INTO deposit (savingID,savingName,descrip) VALUES (2,&apos;定期一年&apos;,&apos;存款期是1年&apos;);INSERT INTO deposit (savingID,savingName,descrip) VALUES (3,&apos;定期二年&apos;,&apos;存款期是2年&apos;);INSERT INTO deposit (savingID,savingName,descrip) VALUES (4,&apos;定期三年&apos;,&apos;存款期是3年&apos;);INSERT INTO deposit (savingID,savingName) VALUES (5,&apos;定活两便&apos;);INSERT INTO deposit (savingID,savingName) VALUES (6,&apos;通知&apos;);INSERT INTO deposit (savingID,savingName,descrip) VALUES (7,&apos;零存整取一年&apos;,&apos;存款期是1年&apos;);INSERT INTO deposit (savingID,savingName,descrip) VALUES (8,&apos;零存整取二年&apos;,&apos;存款期是2年&apos;);INSERT INTO deposit (savingID,savingName,descrip) VALUES (9,&apos;零存整取三年&apos;,&apos;存款期是3年&apos;);INSERT INTO deposit (savingID,savingName,descrip) VALUES (10,&apos;存本取息五年&apos;,&apos;按月支取利息&apos;);SELECT * FROM DEPOSIT;SELECT * FROM userinfo;SELECT * FROM cardinfo;SELECT * FROM tradeinfo;INSERT INTO userInfo(customerID,customerName,PID,telephone,address ) VALUES(1,&apos;张三&apos;,&apos;123456789012345&apos;,&apos;010-67898978&apos;,&apos;北京海淀&apos;);INSERT INTO cardInfo(cardID,savingID,openMoney,balance,customerID) VALUES(&apos;1010 3576 1234 5678&apos;,1,1000,1000,1);INSERT INTO userInfo(customerID,customerName,PID,telephone) VALUES(2,&apos;李四&apos;,&apos;321245678912345678&apos;,&apos;0478-44443333&apos;);INSERT INTO cardInfo(cardID,savingID,openMoney,balance,customerID) VALUES(&apos;1010 3576 1212 1134&apos;,2,1,1,2);INSERT INTO userInfo(customerID,customerName,PID,telephone) VALUES(3,&apos;王五&apos;,&apos;567891234532124670&apos;,&apos;010-44443333&apos;);INSERT INTO cardInfo(cardID,savingID,openMoney,balance,customerID) VALUES(&apos;1010 3576 1212 1130&apos;,2,1601,1601,3);INSERT INTO userInfo(customerID,customerName,PID,telephone) VALUES(4,&apos;丁六&apos;,&apos;567891321242345618&apos;,&apos;0752-43345543&apos;);INSERT INTO cardInfo(cardID,savingID,openMoney,balance,customerID) VALUES(&apos;1010 3576 1212 1004&apos;,2,1,1,4);/*张三的卡号（1010 3576 1234 5678）取款900元，李四的卡号（1010 3576 1212 1134）存款5000元，要求保存交易记录，以便客户查询和银行业务统计。说明：当存钱或取钱（如300元）时候，会往交易信息表（tradeInfo）中添加一条交易记录， 同时应更新银行卡信息表（cardInfo）中的现有余额（如增加或减少500元）*//*--------------交易信息表插入交易记录--------------------------*/INSERT INTO tradeInfo(tradeType,cardID,tradeMoney) VALUES(&apos;支取&apos;,&apos;1010 3576 1234 5678&apos;,900) ;/*-------------更新银行卡信息表中的现有余额-------------------*/UPDATE cardInfo SET balance=balance-900 WHERE cardID=&apos;1010 3576 1234 5678&apos;;/*--------------交易信息表插入交易记录--------------------------*/INSERT INTO tradeInfo(tradeType,cardID,tradeMoney) VALUES(&apos;存入&apos;,&apos;1010 3576 1212 1130&apos;,300) ;/*-------------更新银行卡信息表中的现有余额-------------------*/UPDATE cardInfo SET balance=balance+300 WHERE cardID=&apos;1010 3576 1212 1130&apos;;/*--------------交易信息表插入交易记录--------------------------*/INSERT INTO tradeInfo(tradeType,cardID,tradeMoney) VALUES(&apos;存入&apos;,&apos;1010 3576 1212 1004&apos;,1000) ;/*-------------更新银行卡信息表中的现有余额-------------------*/UPDATE cardInfo SET balance=balance+1000 WHERE cardID=&apos;1010 3576 1212 1004&apos;;/*--------------交易信息表插入交易记录--------------------------*/INSERT INTO tradeInfo(tradeType,cardID,tradeMoney) VALUES(&apos;支取&apos;,&apos;1010 3576 1212 1130&apos;,1900) ;/*-------------更新银行卡信息表中的现有余额--报错-----------------*/UPDATE cardInfo SET balance=balance-1900 WHERE cardID=&apos;1010 3576 1212 1130&apos;;/*--------------交易信息表插入交易记录--------------------------*/INSERT INTO tradeInfo(tradeType,cardID,tradeMoney) VALUES(&apos;存入&apos;,&apos;1010 3576 1212 1134&apos;,5000) ; --INSERT INTO tradeInfo(tradeType,cardID,tradeMoney,Tradedate) --VALUES(&apos;存入&apos;,&apos;1010 3576 1212 1134&apos;,5000,to_date(&apos;2014-06-01&apos;,&apos;yyyy-mm-dd&apos;)) ;/*-------------更新银行卡信息表中的现有余额-------------------*/UPDATE cardInfo SET balance=balance+5000 WHERE cardID=&apos;1010 3576 1212 1134&apos;;commit;/*--------检查测试数据是否正确---------*/SELECT * FROM cardInfo;SELECT * FROM tradeInfo;SELECT * FROM userInfo;--删除数据delete from tradeInfo;delete from cardInfo;delete from userInfo;delete from DEPOSIT;/*取本周第一天select trunc (sysdate,&apos;DAY&apos;) from dual;*//*---------修改密码-----*/--1.张三（卡号为1010 3576 1234 5678）修改银行卡密码为123456--2.李四（卡号为1010 3576 1212 1134）修改银行卡密码为123123update cardInfo set pass=&apos;123456&apos; WHERE cardID=&apos;1010 3576 1234 5678&apos; ;update cardInfo set pass=&apos;123123&apos; WHERE cardID=&apos;1010 3576 1212 1134&apos; ;--查询账户信息SELECT * FROM cardInfo;/*---------挂失帐号---------*/--李四（卡号为1010 3576 1212 1134）因银行卡丢失，申请挂失update cardInfo set IsReportLoss=1 WHERE cardID=&apos;1010 3576 1212 1134&apos; ;SELECT * FROM cardInfo;--查看修改密码和挂失结果SELECT cardid 卡号,curID 货币,savingName 储蓄种类,opendate 开户日期,openmoney 开户金额,balance 余额,pass 密码, case IsReportLoss WHEN 1 THEN &apos;挂失&apos; WHEN 0 THEN &apos;未挂失&apos; ELSE NULL end 是否挂失, customerName 客户姓名FROM CardInfo, Deposit, UserInfoWHERE CardInfo.savingID=Deposit.savingID and CardInfo.customerID = UserInfo.customerID;/*--------统计银行的资金流通余额和盈利结算------------------------------*/--统计说明:存款代表资金流入,取款代表资金.假定存款利率为千分之3,贷款利率为千分之8/*--单一货币RMB--*/DECLARE v_inMoney number; v_outMoney number; v_profit number;begin --SELECT * FROM tradeInfo SELECT sum(tradeMoney) into v_inMoney FROM tradeInfo WHERE (tradeType=&apos;存入&apos;); SELECT sum(tradeMoney) into v_outMoney FROM tradeInfo WHERE (tradeType=&apos;支取&apos;); dbms_output.put_line(&apos;银行流通余额总计为:&apos;||to_char(v_inMoney-v_outMoney)||&apos;RMB&apos;); v_profit:=v_outMoney*0.008-v_inMoney*0.003; dbms_output.put_line(&apos;盈利结算为:&apos;||to_char(v_profit)||&apos;RMB&apos;);end;/*--------查询本周开户的卡号,显示该卡相关信息-----------------*/SELECT c.cardID 卡号,u.customerName 姓名,c.curID 货币,d.savingName 存款类型,c.openDate 开户日期,c.openMoney 开户金额,c.balance 存款余额, CASE c.IsReportLoss WHEN 0 THEN &apos;正常账户&apos; WHEN 1 THEN &apos;挂失账户&apos; ELSE NULL END 账户状态FROM cardInfo c INNER JOIN userInfo u ON (c.customerID = u.customerID)INNER JOIN Deposit d ON (c.savingID = d.savingID )WHERE openDate between trunc(sysdate,&apos;DAY&apos;) and trunc(sysdate,&apos;DAY&apos;)+6/*---------查询本月交易金额最高的卡号----------------------*/SELECT * FROM tradeInfo;SELECT DISTINCT cardID FROM tradeInfo WHERE tradeMoney= (SELECT Max(tradeMoney) FROM tradeInfo WHERE to_char(tradeDate,&apos;yyyy-mm&apos;)=to_char(sysdate,&apos;yyyy-mm&apos;)); /*---------查询挂失帐号的客户信息---------------------*/SELECT customerName as 客户姓名,telephone as 联系电话 FROM userInfo WHERE customerID IN (SELECT customerID FROM cardInfo WHERE IsReportLoss=1); /*------催款提醒：例如某种业务的需要，每个月末，如果发现用户帐上余额少于200元，将致电催款。---*/SELECT customerName as 客户姓名,telephone as 联系电话,balance as 存款余额 FROM userInfo INNER JOIN cardInfo ON userInfo.customerID=cardInfo.customerID WHERE balance&lt;200;/*视图查询*/--1.创建视图：为了向客户显示信息友好,查询各表要求字段全为中文字段名。create or replace VIEW vw_userInfo --客户信息表视图 AS select customerID as 客户编号,customerName as 开户名, PID as 身份证号, telephone as 电话号码,address as 居住地址 from userInfo;--使用视图SELECT * FROM vw_userInfo;--2.创建视图：查询银行卡信息create or replace VIEW vw_cardInfo --银行卡信息表视图 AS select c.cardID as 卡号,u.customerName as 客户,c.curID as 货币种类, d.savingName as 存款类型,c.openDate as 开户日期, c.balance as 余额,c.pass 密码, case c.IsReportLoss when 0 then &apos;正常&apos; when 1 then &apos;挂失&apos; end as 是否挂失 from cardInfo c, deposit d,userinfo u where c.savingID=d.savingID and c.customerID=u.customerID;--使用视图SELECT * FROM vw_cardInfo;SELECT 客户,余额 FROM vw_cardInfo where 客户=&apos;张三&apos;;--3.创建视图：查看交易信息create VIEW vw_tradeInfo --交易信息表视图 AS select tradeDate as 交易日期,tradeType as 交易类型, cardID as 卡号,tradeMoney as 交易金额, remark as 备注 from tradeInfo ;--使用视图SELECT * FROM vw_tradeInfo;--4.根据客户登录名（采用实名制访问银行系统）查询该客户帐户信息的视图/*trim去掉前后空格*/create or replace VIEW vw_oneUserInfo AS select customerID as 客户编号,customerName as 开户名, PID as 身份证号, telephone as 电话号码,address as 居住地址 from userInfo where UPPER(TRIM(customerName)) in (select UPPER(TRIM(username)) from user_users);select * from user_users;--使用视图select * from vw_oneUserInfo;/*存储过程*/select * from tradeinfo;select * from cardinfo;/*--1.取钱或存钱的存储过程*/create or replace procedure usp_takeMoney (v_card char, --卡号 v_m number, --存取金额 v_type char, --存取类型 v_inputPass char default NULL) --密码as v1 number(1); --临时变量 v_mybalance number; --余额begin dbms_output.put_line(&apos;交易正进行,请稍后......&apos;); if (v_type=&apos;支取&apos;) then SELECT 1 into v1 FROM cardInfo WHERE cardID=v_card and pass=v_inputPass; end if; SELECT balance into v_mybalance FROM cardInfo WHERE cardID=v_card; if (v_type=&apos;支取&apos;) then if (v_mybalance&gt;=v_m+1) then update cardInfo set balance=balance-v_m WHERE cardID=v_Card; else dbms_output.put_line(&apos;卡号&apos;||v_card||&apos; 余额：&apos;||to_char(v_mybalance)); raise_application_error(-20000,&apos;交易失败！余额不足！&apos;); end if; else update cardInfo set balance=balance+v_m WHERE cardID=v_card; end if; dbms_output.put_line(&apos;交易成功！交易金额：&apos;||to_char(v_m)); SELECT balance into v_mybalance FROM cardInfo WHERE cardID=v_card; dbms_output.put_line(&apos;卡号&apos;||v_card||&apos; 余额：&apos;||to_char(v_mybalance)); INSERT INTO tradeInfo(tradeType,cardID,tradeMoney) VALUES(v_type,v_card,v_m); commit;exception when no_data_found then raise_application_error(-20001,&apos;卡号或密码错误!&apos;);end;--调用存储过程取钱或存钱 张三取300， --现实中的取款机依靠读卡器读出张三的卡号,这里根据张三的名字查出考号来模拟 DECLARE emp_20000 EXCEPTION; PRAGMA EXCEPTION_INIT(emp_20000, -20000); emp_20001 EXCEPTION; PRAGMA EXCEPTION_INIT(emp_20001, -20001); v_card char(19);BEGIN select cardID into v_card from cardInfo Inner Join userInfo ON cardInfo.customerID=userInfo.customerID where customerName=&apos;张三&apos;; usp_takeMoney(v_card,300 ,&apos;支取&apos;,&apos;123456&apos;);EXCEPTION WHEN emp_20000 THEN DBMS_OUTPUT.PUT_LINE(&apos;交易失败！余额不足！&apos;); rollback; WHEN emp_20001 THEN DBMS_OUTPUT.PUT_LINE(&apos;密码错误!&apos;); rollback; WHEN no_data_found THEN DBMS_OUTPUT.PUT_LINE(&apos;用户名不存在!&apos;); rollback; WHEN OTHERS THEN DBMS_OUTPUT.PUT_LINE(&apos;出现了其他异常错误&apos;); rollback;END;--调用存储过程，李四存500 DECLARE emp_20000 EXCEPTION; PRAGMA EXCEPTION_INIT(emp_20000, -20000); emp_20001 EXCEPTION; PRAGMA EXCEPTION_INIT(emp_20001, -20001); v_card char(19);BEGIN select cardID into v_card from cardInfo Inner Join userInfo ON cardInfo.customerID=userInfo.customerID where customerName=&apos;李四&apos;; usp_takeMoney(v_card,500 ,&apos;存入&apos;);EXCEPTION WHEN emp_20000 THEN DBMS_OUTPUT.PUT_LINE(&apos;交易失败！余额不足！&apos;); rollback; WHEN emp_20001 THEN DBMS_OUTPUT.PUT_LINE(&apos;密码错误!&apos;); rollback; WHEN OTHERS THEN DBMS_OUTPUT.PUT_LINE(&apos;出现了其他异常错误&apos;); rollback;END;select * from vw_cardInfo;select * from vw_tradeInfo;/*--2.产生随机卡号的存储过程(dbms_random包来实现) --*/create or replace procedure usp_randCardID(v_randCardID OUT char)AS v_r number(8);BEGIN v_r:=round(dbms_random.value(10000000,99999999));--产生这个范围(10000000,99999999)的随机数 v_randCardID:=&apos;1010 3576 &apos;||substr(v_r,1,4)||&apos; &apos;||substr(v_r,5,8);--四位一空格end;--测试产生随机卡号DECLARE v_mycardID char(19) ;BEGIN usp_randCardID(v_mycardID); dbms_output.put_line(&apos;产生的随机卡号为：&apos;||v_mycardID);END;/*--3.开户的存储过程--*/select * from userInfo;CREATE SEQUENCE seq_customerID START WITH 10 INCREMENT BY 1 NOMAXVALUE NOCYCLE CACHE 30;create or replace procedure usp_openAccount( v_customerName char, v_PID char, v_telephone char, v_openMoney number, v_savingName char, v_address varchar default &apos;&apos; )AS v_mycardID char(19); v_cur_customerID int; v_savingID int ; v1 int; begin --调用产生随机卡号的存储过程获得随机卡号 usp_randCardID (v_mycardID); SELECT count(*) into v1 FROM cardInfo WHERE cardID=v_mycardID; while (v1&lt;&gt;0) loop usp_randCardID (v_mycardID); SELECT count(*) into v1 FROM cardInfo WHERE cardID=v_mycardID; end loop; dbms_output.put_line(&apos;尊敬的客户,开户成功!系统为您产生的随机卡号为:&apos;||v_mycardID); dbms_output.put_line(&apos;开户日期&apos;||to_char(sysdate,&apos;yyyy-mm-dd&apos;)||&apos; 开户金额:&apos;||to_char(v_openMoney)); select count(*) into v1 from userInfo where PID=v_PID; if v1=0 then INSERT INTO userInfo(customerID,customerName,PID,telephone,address ) VALUES(seq_customerID.nextval,v_customerName,v_PID,v_telephone,v_address) ; end if; SELECT savingID into v_savingID FROM deposit WHERE savingName =v_savingName; select customerID into v_cur_customerID from userInfo where PID=v_PID; INSERT INTO cardInfo(cardID,savingID,openMoney,balance,customerID) VALUES(v_mycardID,v_savingID,v_openMoney,v_openMoney,v_cur_customerID);exception when no_data_found then raise_application_error(-20000,&apos;存款类型不正确,请重新输入!&apos;); when others then raise_application_error(-20001,&apos;其他错误,请重新输入!&apos;);end;--调用存储过程重新开户begin usp_openAccount (&apos;王老五&apos;,&apos;334456889012678&apos;,&apos;2222-63598978&apos;,1000,&apos;活期&apos;,&apos;河南新乡&apos;); commit;end;--EXEC usp_openAccount(&apos;赵小二&apos;,&apos;213445678912342222&apos;,&apos;0760-44446666&apos;,1,&apos;定期&apos;);select * from vw_userInfo;select * from vw_cardInfo;select * from vw_tradeInfo;GO/*--4.输入页数和每页显示的记录数，实现分页显示*/--DROP PROCEDURE usp_pagingDisplaySELECT tradeDate 交易日期,tradeType 交易类型,cardID 卡号,trademoney 交易金额 FROM (SELECT t.*,rownum rn FROM (SELECT * FROM tradeInfo ) t)WHERE rn&gt;=4 and rn&lt;=6;CREATE OR REPLACE PROCEDURE usp_pagingDisplay( v_page number:= 1, v_records number:= 10)AS v_rec1 number; v_rec2 number; v_statement varchar2(200); TYPE cursor_type IS REF CURSOR; --声明一个游标变量 c1 CURSOR_TYPE; v_trade tradeinfo%rowtype;begin v_rec1:= (v_page-1)*v_records+1; v_rec2:= v_page*v_records; v_statement:=&apos;SELECT tradeDate,tradeType,cardID,trademoney,REMARK &apos;; --SQL语句拼接 v_statement:=v_statement||&apos;FROM (SELECT t.*,rownum rn FROM (SELECT * FROM tradeInfo ) t) &apos;; v_statement:=v_statement||&apos;WHERE rn&gt;=&apos;||v_rec1||&apos; and rn&lt;=&apos;||v_rec2; --dbms_output.put_line(v_statement); dbms_output.put_line(&apos;交易日期 交易类型 卡号 交易金额 &apos;); dbms_output.put_line(&apos;---------------------------------------------------------&apos;); open c1 for v_statement; LOOP FETCH c1 INTO v_trade ; EXIT WHEN c1%NOTFOUND; DBMS_OUTPUT.PUT_LINE(to_char(v_trade.tradeDate,&apos;yyyy-mm-dd&apos;)||&apos; &apos;||v_trade.tradeType||&apos; &apos;||v_trade.cardID||&apos; &apos;||v_trade.trademoney); END LOOP; CLOSE c1;END;BEGIN usp_pagingDisplay(2,2);END;/*---- 5.打印对账单 ----*/--drop proc usp_CheckSheetCREATE OR REPLACE PROCEDURE usp_CheckSheet( v_cardID varchar2, v_date1 date:=NULL, v_date2 date:=NULL)AS v_custName varchar2(20); v_curName varchar2(20); v_savingName varchar2(20); v_openDate date; TYPE cursor_type IS REF CURSOR; --声明一个游标变量 c1 CURSOR_TYPE; v_trade tradeinfo%rowtype; v_sqlStr varchar2(2000);BEGIN SELECT c.curID, u.customerName,d.savingName ,c.openDate INTO v_curName,v_custName,v_savingName, v_openDate FROM cardInfo c inner join userInfo u on c.customerID=u.customerID inner join deposit d on c.savingID = d.savingID WHERE cardID = v_cardID; --and u.customerName = user_name() dbms_output.put_line(&apos;卡号：&apos; || v_cardID); dbms_output.put_line(&apos;姓名:&apos; || v_custName); dbms_output.put_line(&apos;货币:&apos; || v_curName); dbms_output.put_line(&apos;存款类型：&apos; || v_savingName); dbms_output.put_line(&apos;开户日期：&apos; || to_char(v_openDate,&apos;yyyy&quot;年&quot;mm&quot;月&quot;dd&quot;日&quot;&apos;)); dbms_output.put_line(&apos; &apos;); dbms_output.put_line(&apos;--------------------------------------------------------------------&apos;); dbms_output.put_line(&apos;交易日 &apos;||&apos; 类型 &apos;||&apos; 交易金额 &apos;||&apos; 备注&apos;); v_sqlStr:=&apos;SELECT * FROM tradeInfo WHERE cardID=&apos;&apos;&apos;||v_cardID||&apos;&apos;&apos;&apos;; IF v_date2 IS NOT NULL THEN v_sqlStr:=v_sqlStr||&apos; AND tradeDate &lt;=to_date(&apos;&apos;&apos;||to_char(v_date2,&apos;yyyy-mm-dd&apos;)||&apos; 23:59:59&apos;||&apos;&apos;&apos;,&apos;&apos;yyyy-mm-dd hh24:mi:ss&apos;&apos;)&apos;; END IF; IF v_date1 IS NOT NULL THEN v_sqlStr:=v_sqlStr||&apos; AND tradeDate &gt;=to_date(&apos;&apos;&apos;||to_char(v_date1,&apos;yyyy-mm-dd&apos;)||&apos; 00:00:00&apos;||&apos;&apos;&apos;,&apos;&apos;yyyy-mm-dd hh24:mi:ss&apos;&apos;)&apos;; END IF; v_sqlStr:=v_sqlStr||&apos; ORDER BY tradeDate&apos;; --dbms_output.put_line(v_sqlStr); open c1 for v_sqlStr; LOOP FETCH c1 INTO v_trade ; EXIT WHEN c1%NOTFOUND; DBMS_OUTPUT.PUT_LINE(to_char(v_trade.tradeDate,&apos;yyyy-mm-dd&apos;)||&apos; &apos;||v_trade.tradeType||&apos; &apos;||v_trade.tradeMoney||&apos; &apos;||v_trade.remark); END LOOP; CLOSE c1;END;--调用begin -- Test statements here usp_CheckSheet(&apos;1010 3576 1212 1130&apos;,to_date(&apos;2012-12-01&apos;,&apos;yyyy-mm-dd&apos;),to_date(&apos;2013-11-01&apos;,&apos;yyyy-mm-dd&apos;));end;/*--6.查询、统计在指定时间段内没有发生交易的账户信息*/--drop proc usp_getWithoutTradecreate or replace procedure usp_getWithoutTrade( v_Num out number , v_Amount out number , v_date1 date := NULL, v_date2 date := NULL)AS v_sd date; v_ed date;TYPE cursor_type IS REF CURSOR;c1 CURSOR_TYPE;v_cur userInfo%rowtype;BEGIN IF v_date1 IS NULL THEN v_sd:=trunc(sysdate,&apos;month&apos;); END IF; IF v_date2 IS NULL THEN v_ed := sysdate; END IF; dbms_output.put_line(&apos;客户号 &apos;||&apos; 客户姓名&apos;||&apos; 身份证号&apos;||&apos; 电话&apos;||&apos; 地址&apos;); dbms_output.put_line(&apos;---------------------------------------------------------------&apos;); open c1 for SELECT distinct u.customerID,u.customerName,u.PID,u.telephone,address FROM userInfo u JOIN cardInfo c ON u.customerID = c.customerID WHERE c.cardID NOT IN (SELECT cardID FROM tradeInfo WHERE tradeDate Between v_sd and v_ed); LOOP FETCH c1 INTO v_cur ; EXIT WHEN c1%NOTFOUND; DBMS_OUTPUT.PUT_LINE(v_cur.customerID||&apos; &apos;||v_cur.customerName||&apos; &apos;||v_cur.PID||&apos; &apos;||v_cur.telephone||&apos; &apos;||v_cur.address); END LOOP; CLOSE c1; SELECT COUNT(customerID),SUM(balance) into v_Num,v_Amount FROM cardInfo WHERE cardID NOT IN (SELECT cardID FROM tradeInfo WHERE tradeDate Between v_sd and v_ed);end;--调用存储过程DECLARE v_NUM number; v_Amount number(18,2); v_date1 date; v_date2 date;begin v_date1:= to_date(&apos;2009-1-1&apos;,&apos;yyyy-mm-dd&apos;); v_date2:= sysdate; usp_getWithoutTrade(v_NUM, v_Amount);--, @date1, @date2 dbms_output.put_line(&apos;统计未发生交易的客户&apos;); dbms_output.put_line( &apos;---------------------------------------&apos;); dbms_output.put_line( &apos;客户人数：&apos; || v_NUM || &apos; 客户总余额：&apos; || v_Amount);end;/*--7.统计银行卡交易量和交易额*/--drop proc usp_getTradeInfocreate or replace procedure usp_getTradeInfo( v_Num1 out number, v_Amount1 out number, v_Num2 out number, v_Amount2 out number, v_date1 date:=trunc(sysdate,&apos;year&apos;), v_date2 date:=sysdate, v_address varchar:= NULL)ASBEGIN IF v_address IS NULL THEN SELECT COUNT(tradeMoney), SUM(tradeMoney) into v_num1,v_Amount1 FROM tradeInfo WHERE tradeDate BETWEEN v_date1 AND v_date2 AND tradeType=&apos;存入&apos;; SELECT COUNT(tradeMoney), SUM(tradeMoney) into v_num2,v_Amount2 FROM tradeInfo WHERE tradeDate BETWEEN v_date1 AND v_date2 AND tradeType=&apos;支取&apos;; ELSE SELECT COUNT(tradeMoney), SUM(tradeMoney) into v_num1,v_Amount1 FROM tradeInfo JOIN cardInfo ON tradeInfo.cardID = cardInfo.cardID JOIN userInfo ON cardInfo.customerID = userInfo.customerID WHERE tradeDate BETWEEN v_date1 AND v_date2 AND tradeType=&apos;存入&apos; AND address Like &apos;%&apos;||v_address||&apos;%&apos;; SELECT COUNT(tradeMoney), SUM(tradeMoney) into v_num2,v_Amount2 FROM tradeInfo JOIN cardInfo ON tradeInfo.cardID = cardInfo.cardID JOIN userInfo ON cardInfo.customerID = userInfo.customerID WHERE tradeDate BETWEEN v_date1 AND v_date2 AND tradeType=&apos;支取&apos; AND address Like &apos;%&apos;||v_address||&apos;%&apos;; END IF; v_num1:=nvl(v_num1,0); v_num2:=nvl(v_num2,0); v_Amount1:=nvl(v_Amount1,0); v_Amount2:=nvl(v_Amount2,0);end;--调用declare v_CNT1 number; v_Total1 number(18,2); v_CNT2 number; v_Total2 number(18,2); v_date1 date; v_date2 date;begin v_date1 := to_date(&apos;2009-1-1&apos;,&apos;yyyy-mm-dd&apos;); v_date2 := sysdate; usp_getTradeInfo (v_CNT1, v_Total1, v_CNT2, v_Total2, v_date1,v_date2,&apos;北京海淀&apos;);--, &apos;北京&apos;; dbms_output.put_line(&apos;统计银行卡交易量和交易额&apos;); dbms_output.put_line(&apos;&apos;); dbms_output.put_line(&apos;起始日期：&apos; || to_char(v_date1,&apos;yyyy-mm-dd&apos;) || &apos; 截止日期：&apos; || to_char(v_date2,&apos;yyyy-mm-dd&apos;)); dbms_output.put_line(&apos;-----------------------------------------------------------&apos;); dbms_output.put_line(&apos;存入笔数：&apos; || v_CNT1 || &apos; 存入金额：&apos; ||v_Total1); dbms_output.put_line( &apos;支取笔数：&apos; || v_CNT2|| &apos; 支取金额：&apos; ||v_Total2); dbms_output.put_line(&apos;-----------------------------------------------------------&apos;); dbms_output.put_line(&apos;发生笔数：&apos; || (v_CNT1+v_CNT2)|| &apos; 结余金额：&apos; || (v_Total1-v_Total2));end;/*复杂的业务逻辑*/--转帐的事务存储过程-- drop proc usp_tradefercreate or replace procedure usp_tradefer ( v_card1 varchar2, v_pwd varchar2, v_card2 varchar2, v_outmoney number)AS v_date1 date:= sysdate; v_date2 date:= sysdate; emp_20000 EXCEPTION; PRAGMA EXCEPTION_INIT(emp_20000, -20000); emp_20001 EXCEPTION; PRAGMA EXCEPTION_INIT(emp_20001, -20001);BEGIN commit; dbms_output.put_line(&apos;开始转账，请稍后......&apos;); usp_takeMoney(v_card1,v_outmoney ,&apos;支取&apos;,v_pwd); usp_takeMoney(v_card2,v_outmoney ,&apos;存入&apos;); commit; dbms_output.put_line(&apos;转账成功！&apos;); v_date2 := sysdate; dbms_output.put_line(&apos;打印转出账户对账单&apos;); dbms_output.put_line(&apos;-------------------&apos;); usp_CheckSheet(v_card1,v_date1,v_date2); dbms_output.put_line(&apos;打印转入账户对账单&apos;); dbms_output.put_line( &apos;-------------------&apos;); usp_CheckSheet(v_card2,v_date1,v_date2);EXCEPTION WHEN emp_20000 THEN DBMS_OUTPUT.PUT_LINE(&apos;交易失败！余额不足！转账失败！&apos;); rollback; WHEN emp_20001 THEN DBMS_OUTPUT.PUT_LINE(&apos;卡号或密码错误! 转账失败！&apos;); rollback; WHEN OTHERS THEN DBMS_OUTPUT.PUT_LINE(&apos;出现了其他异常错误,转账失败！&apos;); rollback;END;--测试上述事务存储过程--从李四的帐户转帐2000到张三的帐户--同上一样,现实中的取款机依靠读卡器读出张三/李四的卡号,这里根据张三/李四的名字查出考号来模拟DECLARE emp_20000 EXCEPTION; PRAGMA EXCEPTION_INIT(emp_20000, -20000); emp_20001 EXCEPTION; PRAGMA EXCEPTION_INIT(emp_20001, -20001); v_card1 char(19); v_card2 char(19);BEGIN select cardID into v_card1 from cardInfo Inner Join userInfo ON cardInfo.customerID=userInfo.customerID where customerName=&apos;李四&apos;; select cardID into v_card2 from cardInfo Inner Join userInfo ON cardInfo.customerID=userInfo.customerID where customerName=&apos;张三&apos;; usp_tradefer(v_card1,&apos;123123&apos;,v_card2,2000);EXCEPTION WHEN emp_20000 THEN DBMS_OUTPUT.PUT_LINE(&apos;交易失败！余额不足！转账失败！&apos;); WHEN emp_20001 THEN DBMS_OUTPUT.PUT_LINE(&apos;密码错误!转账失败！&apos;); WHEN no_data_found THEN DBMS_OUTPUT.PUT_LINE(&apos;用户名不存在!转账失败！&apos;); WHEN OTHERS THEN DBMS_OUTPUT.PUT_LINE(&apos;出现了其他异常错误！&apos;);END;select * from vw_userInfo;select * from vw_cardInfo;select * from vw_tradeInfo;]]></content>
      <categories>
        <category>SQL</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot基础使用]]></title>
    <url>%2F2018%2F07%2F13%2FSpring%20Boot%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[Spring boot基础[TOC] 1.Starter1-1.概念Spring boot的依赖项，所有spring boot整合的依赖都有此约定 核心依赖org.springframework.boot中的整合都以 spring-boot-starter-xxx的形式引入 第三方的依赖可能是以xxx-spring-boot-starter的形式引入 如spring-boot-starter 核心启动器，整合自动配置的支持以及日志记录和YAMLSpring-boot-starter-aop 支持spring 面向切面编程……更多参考官网列表https://docs.spring.io/spring-boot/docs/current/reference/htmlsingle/#using-boot-starter 1-2.spring boot根据starter生成主观配置Spring boot会根据配置的starter生成自己的主观配置，如导入spring-boot-starter-web时生成的观点 使用Tomcat作为嵌入web服务容器 使用Hibernation 对象关系映射(ORM) 使用Apache Jackson绑定Json 使用Spring MVC作为Rest风格框架 Spring boot会生成目前主流的web默认配置（¯(ツ)/¯），如果需要替换，可以自定义，方法下方传送门 2.可执行jar可以通过maven插件配置打包，在本地命令窗口即可启动项目（简单实用的功能，省略） 精选传送门，附带整合Rest风格的Demohttps://www.ibm.com/developerworks/cn/java/j-spring-boot-basics-perry/index.html 3.Spring快速搭建3-1.Demo01入门该博客有一套基础的Spring boot搭建文章https://www.cnblogs.com/ityouknow/p/5662753.html 4.常用注解整合4-1.Controller层常用注解@ControllerSpring中，表现层的控制器标识（servlet） @RestController在rest风格中常用的控制器标识，是组合注解，包括 @ResponseBody @Controller @Retention(value=RUNTIME) @DocumentedSpringMVC中，该类的所有handler都会以字符串渲染的形式返回给调用者 @RequestMapping扩展处理器映射器，被标注的方法即handler，可以标注对象，这也是springMVC的特点之一属性： value 地址/变量/正则表达式 method 方法格式，如 RequestMethod.GET consumes 如 consumes=”application/json” 处理Content-Type的类型为指定类型的请求 produces 如 produces=”application/json” 处理请求的Accept为指定类型的请求，并返回相同的内容类型 params 如 params = “username=DonY15” 处理带有username参数，且值为DonY15的指定请求 headers 如 headers=”Referer=http://www.ifeng.com/“ 处理header中带有Referer且值为http://www.ifeng.com/的请求 不同属性的映射注解 @PathVariable 如 @PathVariable String username 接收地址栏中变量/正则的注解 @RequestParams 接收约定传递的参数 @ResponseBody普通MVC中常用来返回json格式给前端，建议和json类型转换器搭配使用 @RequestBody很少使用，限制请求参数来自请求体中 4-2.配置注解@SpringBootApplication启动类注解，组合注解，内部封装了三种注解，都需要时可以使用该注解来简化代码 @ComponentScan 扫描需要的组件 @Configuration 配置类 @EnableAutoConfiguration 开启自动配置 @Component与Configuration类似，一般当组件配置不好分类时使用 @Autowired/@Resource自动装配/指定注入 @Inject等价于默认的@Autowired，只是没有required属性 @ImportResource用来加载xml配置文件。 如Spring-xxx.xml可以注入 (技巧,可以先将多个Spring-xxx.xml通过@Import注入到一个Spring-root.xml中,再将Spring-root.xml注入到代码) @Service一般用于修饰service层的组件（不同框架有不同的作用，如Dubbo） @Repository使用@Repository注解可以确保DAO或者repositories提供异常转译，这个注解修饰的DAO或者repositories类会被ComponetScan发现并配置，同时也不需要为它们提供XML配置项。 @Bean用@Bean标注方法等价于XML中配置的bean。 @Value注入Spring boot application.properties配置的属性的值。 —————「待深入注解」—————@JsonBackReference解决嵌套外链问题 @RepositoryRestResourcepublic配合spring-boot-starter-data-rest使用。 @Import用来导入其他配置类 @Qualifier当有多个同一类型的Bean时，可以用@Qualifier(“name”)来指定。与@Autowired配合使用。@Qualifier限定描述符除了能根据名字进行注入，但能进行更细粒度的控制如何选择候选者 4-3.全局异常注解@ControllerAdvice包含@Component。可以被扫描到。统一处理异常。 @ExceptionHandler（Exception.class）用在方法上面表示遇到这个异常就执行以下方法。 4-4.事务管理@EnableTransactionManagement开始事务支持 @TransactionalService中指定方法开启事物 多事务管理器传送门https://blog.csdn.net/catoop/article/details/50595702事务简单配置传送门https://blog.csdn.net/rickiyeat/article/details/62042685 4-5.整合Mybatismybatis-spring-boot-starter@MapperScan扫描Mapper包 整合Mybatis传送门http://www.ityouknow.com/springboot/2016/11/06/spring-boo-mybatis.html 4-6.JPA注解@Entity实体类注解 @Table实体类和数据库表映射，如果两者名字相同可以省略 @Column实体类属性和字段映射，如果两者名字相同可省略 @Id主键映射 @GeneratedValue(strategy = GenerationType.SEQUENCE,generator = “repair_seq”)表示主键生成策略是sequence（可以为Auto、IDENTITY、native等，Auto表示可在多个数据库间切换），指定sequence的名字是repair_seq。 @JsonIgnore作用是json序列化时将Java bean中的一些属性忽略掉,序列化和反序列化都受影响。 @JoinColumn（name=”loginId”）一对一：本表中指向另一个表的外键。一对多：另一个表指向本表的外键。 @OneToOne@OneToMany@ManyToOne对应hibernate配置文件中的一对一，一对多，多对一。 —————「待深入注解」—————@Transient：表示该属性并非一个到数据库表的字段的映射,ORM框架将忽略该属性。如果一个属性并非数据库表的字段映射,就务必将其标示为@Transient,否则,ORM框架默认其注解为@Basic。@Basic(fetch=FetchType.LAZY)：标记可以指定实体属性的加载方式 5.Thymeleaf 丁香叶SpringBoot官方不支持使用JSP,官方推荐 Thymeleaf 引擎代替JSP Thymeleaf支持动静结合 5-1. 语法 th: 前缀1234567891011121314151617181920212223242526&lt;p th:text=&quot;$&#123;text&#125;&quot;&gt;我是普通文本&lt;/p&gt; &lt;p th:utext=&quot;$&#123;htmlText&#125;&quot;&gt;我是转义文本(标签)&lt;/p&gt;&lt;p&gt;&lt;a th:href=&quot;@&#123;&#123;ahref&#125;?pa=&#123;text&#125;(ahref=$&#123;ahref&#125;,text=$&#123;text&#125;)&#125;&quot;&gt;我是a标签&lt;/a&gt;&lt;/p&gt;我是表格&lt;br/&gt;&lt;table border=&quot;1&quot;&gt; &lt;tr th:each=&quot;dept:$&#123;deptList&#125;&quot;&gt; &lt;td th:text=&quot;$&#123;dept.id&#125;&quot;&gt;id&lt;/td&gt; &lt;td th:text=&quot;$&#123;dept.name&#125;&quot;&gt;name&lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;我是下拉框 &lt;select &gt; &lt;option th:each=&quot;dept:$&#123;deptList&#125;&quot; th:value=&quot;$&#123;dept.id&#125;&quot; th:text=&quot;$&#123;dept.name&#125;&quot; th:selected=&quot;$&#123;dept.id&#125;==$&#123;param.id[0]&#125;&quot;&gt;&lt;/option&gt;&lt;/select&gt;&lt;br/&gt;&lt;input th:value=&quot;$&#123;text&#125;&quot;&gt; //value值 &lt;script th:src=&quot;@&#123;static/test.js&#125;&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;&lt;div th:if=&quot;$&#123;ahref == &apos;test&apos;&#125;&quot;&gt;条件判断是否显示这段话&lt;/div&gt; Thymeleaf基础手册 https://blog.csdn.net/zrk1000/article/details/72667478/ 后台可以使用Model 5-2.优秀传送门https://www.bysocket.com/?p=1973 6.PageInfo的使用传送门https://blog.csdn.net/csdn_huzeliang/article/details/79350425]]></content>
      <categories>
        <category>Spring全家桶</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[实用工具类集合]]></title>
    <url>%2F2018%2F07%2F12%2F%E5%AE%9E%E7%94%A8%E5%B7%A5%E5%85%B7%E7%B1%BB%E9%9B%86%E5%90%88%2F</url>
    <content type="text"><![CDATA[实用工具类集合[TOC] 简述 该工具类集合章会持续更新,具体工具类会集成到我的GitHub仓库中 传送门 https://github.com/dony15/mymodes 1.js-utils.js-前段小集合工具常用js的前段封装 XMLHttpRequest 原生ajax的获取 ,内置了Chrome和IE的兼容转换 图片上传功能前段,四个id解决 | 图片 | 表单 | 回显 | 的结合 验证码显示和输入框校验 两个id 一个url 即可解决 | 校验 | 提示 | 提交url |的结合 点击切换验证码 id和url 2.pattern.js-正则工具包含开发中各种验证常用的正则封装 2.CollectionsFactory-集合封装工具包含各种集合类型的构建,静态工具类,使代码看起来更加规范简洁 3.DownloadUtil-文件下载工具文件下载工具类,根据文件名或者文件路径获取文件进行下载(多场景的封装) 3.FileUtil-文件处理工具非常实用的文件处理工具,如获取文件名/去重/清空但不删除文件夹/磁盘遍历/xml生成等等… 4.FormatStyle-文件容量格式转换工具文件容量单位的格式转换,主要解决特殊情况下因为数字太大导致java直接写无法识别的 5.IDUtils-ID生成工具ID的多种生成策略 5.JsonUtils-Json转化工具使用jackson,多种类型和json的转化封装 对象 | List 6.ResourcesUtil-资源读取工具资源读取工具类,较为特殊,使用较少(主要是国际语言的匹配读取,现在前段控制即可) 7.UtilFuns-乱七八糟工具该工具类非常的丰富.各种SE的基础转换和时间/固定长度转换/编码解码等都有涉猎 8.QuartzUtil-时间调度工具该工具为时间调度工具类,包含增加工作,修改工作,移除工作,启动所有定时和关闭所有定时 9.CookieUtils-Cookie设置工具Cookie的设置与获取/删除/生命周期等操作集合 10.ResopnseResult-响应消息工具响应消息的一种规范工具类 status(Boolean)/msg(String)/data(Object) 11.ExcelUtils-Excel报表数据库报表工具包,将数据库数据生成Excel表格,发送到前端或保存到本地 (内置sheet分页功能/数据类型转换) 12.SmsUtils-短信验证短信API产品的DEMO程序,执行main函数即可体验短信产品API功能 (只需要将AK替换成开通了云通信-短信产品功能的AK即可)(国际短信发送请勿参照此DEMO) 13.generatorSqlmapCustom-逆向工程(贼稳当版)ssm逆向工程工具包 自动生成mybatis持久层数据以及pojo对象 自动搭建持久层和pojo等关系映射 生成几乎所有增删改和单表查功能 14.wxpay工具类-微信支付15.EncodeInterceptor-编码拦截工具16.策略模式redis工具类​ 接口+单机/集群+基础配置 17.MessageDigestUtils -md5/sha-1-加密工具18.FileUpLoadUtils-文件上传较原生的上传,本地可选水印版(很少用),可以修改为FastDFS使用 19.HttpClientUtilHttp请求url的工具类,需要导入jar包 httpclient | jsoup(该jar爬虫时导入即可) 20.java爬虫基础爬虫封装(豆瓣部分示例) 21.FreemarkerUtil该工具类简单实用的通过freemarker模板生成静态页面 其他中文命名工具类不再解释(简单明了) 狗厂&amp;飞机厂工具库推荐1.Google Guava官方教程（汉译）传送门：https://blog.csdn.net/axi295309066/article/details/70856889 中文指南传送门：https://blog.csdn.net/qq_35246620/article/details/77970421 2.apache commons官网：http://commons.apache.org/ 中文指南传送门：http://www.mamicode.com/info-detail-1828364.html]]></content>
      <categories>
        <category>工具类</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Zookeeper与Dubbo基础原理]]></title>
    <url>%2F2018%2F07%2F08%2FZookeeper%E4%B8%8EDubbo%E5%9F%BA%E7%A1%80%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[Zookeeper与Dubbo基础原理[TOC] 1.Zookeeper(RPC框架)高效的分布式分布式应用协调服务,提供注册和负载均衡等–&gt;服务中心 Zookeeper也是集群管理工具,用来管理各种需要的集群,如solorCloud zookeeper让调用者知道调用的哪台服务器地址,也是集群的管理者 Zookeeper具有心跳检测机制,当服务器挂掉时可以让调用者知道,从而切换请求服务器 Zookeeper具有高并发的横向扩展,在不改变代码的情况下对设备进行扩展 1.命名服务 2.配置管理 3.集群管理 4.分布式锁 5.队列管理 命名服务:在zookeeper的文件系统里创建一个目录，即有唯一的path。在我们使用tborg无法确定上游程序的部署机器时即可与下游程序约定好path，通过path即能互相探索发现。 配置管理:程序分散部署在多台机器上难以管理,可以将每台设备的信息存储在Zookeeper的目录节点中,然后相关程序对该目录进行监控,如果配置信息发生变化,则Zookeeper会发布新的配置 集群管理:(1)设备的加入(2)选举master(可以改变设备编号,编号第一位自动master(一种思路)) 分布式锁:zookeeper是一致性的文件系统,锁服务可以分为两类，(1)保持独占，(2)控制时序。 列队管理: 同步队列，当一个队列的成员都聚齐时，这个队列才可用，否则一直等待所有成员到达。在约定目录下创建临时目录节点，监听节点数目是否是我们要求的数目。 队列按照 FIFO 方式进行入队和出队操作。和分布式锁服务中的控制时序场景基本原理一致，入列有编号，出列按编号。 1-1.特性 最终一致性：client不论连接到哪个Server，展示给它都是同一个视图，这是zookeeper最重要的性能。 可靠性：具有简单、健壮、良好的性能，如果消息被到一台服务器接受，那么它将被所有的服务器接受。 实时性：Zookeeper保证客户端将在一个时间间隔范围内获得服务器的更新信息，或者服务器失效的信息。但由于网络延时等原因，Zookeeper不能保证两个客户端能同时得到刚更新的数据，如果需要最新数据，应该在读数据之前调用sync()接口。 等待无关（wait-free）：慢的或者失效的client不得干预快速的client的请求，使得每个client都能有效的等待。 原子性：更新只能成功或者失败，没有中间状态。 顺序性：包括全局有序和偏序两种：全局有序是指如果在一台服务器上消息a在消息b前发布，则在所有Server上消息a都将在消息b前被发布；偏序是指如果一个消息b在消息a后被同一个发送者发布，a必将排在b前面。 1-2.Zookeeper工作原理​ Zookeeper 的核心是原子广播，这个机制保证了各个Server之间的同步。实现这个机制的协议叫做Zab协议。Zab协议有两种模式，它们分别是恢复模式（选主）和广播模式（同步）。当服务启动或者在领导者崩溃后，Zab就进入了恢复模式，当领导者被选举出来，且大多数Server完成了和 leader的状态同步以后，恢复模式就结束了。状态同步保证了leader和Server具有相同的系统状态 ​ 为了保证事务的顺序一致性，zookeeper采用了递增的事务id号（zxid）来标识事务。所有的提议（proposal）都在被提出的时候加上了zxid。实现中zxid是一个64位的数字，它高32位是epoch用来标识leader关系是否改变，每次一个leader被选出来，它都会有一个新的epoch，标识当前属于那个leader的统治时期。低32位用于递增计数。 (部分整理) 原文:https://blog.csdn.net/xqb_756148978/article/details/52259381 2.Dubbo(SOA基础框架)管理中间层的框架,与注册中心搭配使用,如Zookeeper(最常用),使之具有Zookeeper负载均衡/资源同步等的特性 ​ 单一应用架构(ORM) –&gt;垂直应用架构(MVC) 传统架构,难以应对高并发/高可用问题 –&gt;分布式服务架构(RPC) 功能拆分,多台服务器做不同的功能,相当于节点,一个节点下可以有多态服务器做集群 –&gt;流动计算架构(SOA) 节点和节点通过SOA通信,将冗余的业务逻辑单独提取出来,分为表现层和业务层 缓存 数据库层… 2-1.核心部分 远程通讯 集群容错 自动发现 2-2.作用 透明化的远程方法调用，就像调用本地方法一样调用远程方法，只需简单配置，没有任何API侵入 软负载均衡及容错机制，可在内网替代F5等硬件负载均衡器，降低成本，减少单点. 服务自动注册与发现，不再需要写死服务提供方地址，注册中心基于接口名查询服务提供者的IP地址，并且能够平滑添加或删除服务提供者。 Dubbo采用全spring配置方式,透明化接入,应用,没有API入侵 2-3.架构 Provider: 暴露服务的服务提供方。 ​ Consumer: 调用远程服务的服务消费方。 ​ Registry: 服务注册与发现的注册中心。 ​ Monitor: 统计服务的调用次调和调用时间的监控中心. ​ Container: 服务运行器。 2-4.调用关系说明： 服务容器负责启动，加载，运行服务提供者。 服务提供者在启动时，向注册中心注册自己提供的服务。 服务消费者在启动时，向注册中心订阅自己所需的服务。 注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。 服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。 服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。 2-5.注意Dubbo内部版本冲突dubbo的jar包中存在spring 2.+版本以及netty过时版本,需要屏蔽使用,防止冲突 12345678910&lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;exclusion&gt; &lt;groupId&gt;org.jboss.netty&lt;/groupId&gt; &lt;artifactId&gt;netty&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt; 2.6注意Dubbo发布过程 初始化Spring容器 占用暴露服务的端口进行发布,此时本机的端口不可以冲突 收藏Dubbo架构详解http://shiyanjun.cn/archives/325.html]]></content>
      <categories>
        <category>框架</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[工具类集合分析--接口]]></title>
    <url>%2F2018%2F07%2F08%2F%E5%B7%A5%E5%85%B7%E7%B1%BB%E9%9B%86%E5%90%88%E5%88%86%E6%9E%90--%E6%8E%A5%E5%8F%A3%2F</url>
    <content type="text"><![CDATA[工具类集合分析–接口[TOC] 1.概述使用接口作为工具类,一般分两种情况 ​ (1)定义常量 ​ (2)定义动态工具类 2.分析1.定义常量可以在工具类中快捷明了的定义常量来使用,因为接口中默认属性便是常量,如: ​ int HOTEL_STATUS_INVALID=0;//酒店失效 ​ int HOTEL_STATUS_VALID=1;//酒店有效 当controller中往前端传递数据时,需要判断状态,而状态从controller中多次定义会导致观察不变,不利于交接和后期维护,此时便可以将状态抽出来存进接口工具类中,提高代码的可读性和开发效率 (RestFull开发风格中,提高代码可读性尤为突出) 2.定义动态工具类当程序运行在不同的环境中时,因为程序对环境的耦合性,频繁的修改代码会大大降低开发效率,可以使用工具类接口的方式,将耦合性降低,如动态工具类 场景 ​ redis 单机版和集群版 (可以根据需要选择具体的方案,减少代码的修改量) ​]]></content>
      <categories>
        <category>工具类</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Solr基础原理]]></title>
    <url>%2F2018%2F07%2F06%2FSolr%E5%9F%BA%E7%A1%80%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[Solr基础原理[TOC] 1.目录核心组成1.core ​ solr的索引库,可以理解为数据库,需要手动创建(文件夹),core可以根据需要建立多个索引库,索引库的内容可以在后台看到也可以在core中看到 2.solrhome ​ solr的配置目录,solr服务器所有的配置文件存放的目录(core创建在solrhome中) 3.collection一个完整的索引库,逻辑结构1.高并发,高可用 solr的逻辑索引(逻辑意义上的完整索引),由多个shard片的组成负载均衡 每个shard可以分成多份Core,每份相同,主(leadereplica)从(replica)同步,高可用 collection本质是可以跨越多个核的索引,包含冗余的索引. 2.海量存储 当存储空间不够时,只需要横向扩充shard片就可以 4.SolrCloud,物理结构一个SolrCloud集群,包含多个Solr服务器,每个Solr服务器包含多个Core(索引库) 参考https://blog.csdn.net/zhousenshan/article/details/51799567 2.配置详解1.配置中文分词 ​ &lt;!– default values for query parameters can be specified, these ​ will be overridden by parameters in the request ​ –&gt; ​ ​ explicit ​ item_keywords ​ 10 ​ ​ explicit ​ json ​ true ​ item_keywords ​ 2.配置Solr Dataimport ​ ​ data-config.xml ​ ​ ​ ​ ​ ​ ​ ​ ​ ​ ​ 3.Solr后台的使用第一次先Dataimport–&gt;Execute导入,然后Refresh刷新状态即可 Query:查询功能 ​ q ; –&gt;第一个 表示字段; 第二个 表示字段的内容; ​ 如 item_keywords:北京 分词中有”北京”关键字的内容 ​ item_price:[* TO 200] 价格是200以内的内容 ​ item_price:[100 TO 700] 价格是100-200的内容 3.java中的作用建立一个新的索引模块 index,接口层和实现发布层 写Solr更新和搜索两个方法dubbo发布即可在controller中使用 (一般与MQ一起使用,如activeMQ,见activeMQ基础与运用章节)]]></content>
      <categories>
        <category>框架</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2018%2F07%2F03%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment]]></content>
  </entry>
  <entry>
    <title><![CDATA[Shiro基础原理]]></title>
    <url>%2F2018%2F06%2F04%2FShiro%E5%9F%BA%E7%A1%80%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[Shiro基础原理[TOC] 1.简介shiro是apache的一个开源框架，实现 |认证|授权|为核心的一系列权限管理框架. Web 应用程序一般做法通过表单提交用户名及密码达到认证目的。 “授权”即是否允许已认证用户访问受保护资源。 2.对比Shiro与Spring Security 简单性:shiro更加简单,更容易理解 灵活性:shiro可以使用在 |Web|EJB|IoC| 等大部分的应用环境,而Spring Security必须和Spring一起集成使用 拔插性:shiro干净的API(工具类集合)和设计模式(单例+工厂)使它可以方便的和许多其他框架整合,Spring Security则只能与Spring一起集成 3.组成 1.三个核心组件 Subject: 令牌与项目的登录关系,Shiro保证了项目整体的安全性,是Shiro对外API的核心 Security Manager:负责安全认证预授权等 Shiro的核心 Realm:整个框架中必须由设计者自行实现的模块之一.并且Shiro支持多个Realm数据源,最为重要的一种实现方式—&gt;数据库查询,当需要多个数据库组合验证时,多个数据源的效果就体现出来 2.主要功能 Authentication: 身份认证 Authorization: 授权,权限验证 Session Manager: 会话管理 Cryptography:加密 Web Support: web支持 Caching:缓存 Concurrency:多线程验证 Testing:提供测试支持 Run As:允许一个用户假装另一个用户访问 Remember Me: 记住我 3.组件和内容流程分析1.subject外部API核心,存储用户数据和返回数据 1Subject currentUser = SecurityUtils.getSubject(); 获得Subject的方法,有了Subject才能和Shiro做深入的交互 2.SessionManager Shiro的Session提供了HttpSession常规的大部分功能,但是又有区别,即:Session不依赖于HTTP环境,可以在程序任何地方使用 Shiro的Session可以在任何的环境下使用相同的API,而且是自动启动SessionManager 如果希望在*当前与应用程序会话期间,为用户提供内容,则可以设置Session 12Session session = currentUser.getSession();session.setAttribute( &quot;someKey&quot;, &quot;aValue&quot; ); 3.登录认证AuthenticationShiro的认证功能,会根据Subject的信息进行判断,如果认证过,则直接进入/如果没认证,则需要先认证 12345678910if ( !currentUser.isAuthenticated() ) &#123; //collect user principals and credentials in a gui specific manner //such as username/password html form, X509 certificate, OpenID, etc. //We&apos;ll use the username/password example here since it is the most common. //(do you know what movie this is from? ;) UsernamePasswordToken token = new UsernamePasswordToken(&quot;lonestarr&quot;, &quot;vespa&quot;); //this is all you have to do to support &apos;remember me&apos; (no config - built in!): token.setRememberMe(true); currentUser.login(token);&#125; UsernamePasswordToken(username/password) 以特定的方式收集用户的主体和凭证 Remember Me no config - built in!(true/false) Shiro内置功能,记住用户(详情待更新) 登录尝试失败的反馈–异常 1234567891011121314try &#123; currentUser.login( token ); //if no exception, that&apos;s it, we&apos;re done!&#125; catch ( UnknownAccountException uae ) &#123; //username wasn&apos;t in the system, show them an error message?&#125; catch ( IncorrectCredentialsException ice ) &#123; //password didn&apos;t match, try again?&#125; catch ( LockedAccountException lae ) &#123; //account for that username is locked - can&apos;t login. Show them a message?&#125; ... more types exceptions to check if you want ...&#125; catch ( AuthenticationException ae ) &#123; //unexpected condition - error?&#125; Shiro中使用多种异常完善认证 将Subject的.login(token)进行捕获,从而的到许多种异常提醒,根据相应的异常判断用户登录的错误信息 注意:Shiro有丰富的认证异常设定并支持自定义异常,在Realm中通过判断条件,抛出异常的方式,可以在Controller中接收需要的异常数据来完善程序的开发 注意:Shiro不会自己维护用户|权限; 需要开发者去 设计|提供 ; 然后通过接口注入给Shiro即可 4.源码Token认证JdbcRealm Shiro –&gt;JdbcRealm封装的固定sql [1.封装根据用户名查询密码的SQL语句] 1234/** * The default query used to retrieve account data for the user. */ protected static final String DEFAULT_AUTHENTICATION_QUERY = "select password from users where username = ?"; [2.盐加密&amp;&amp;authenticationQuery验证查询(判断)] 1234567891011/** * Sets the salt style. See &#123;@link #saltStyle&#125;. * * @param saltStyle new SaltStyle to set. */ public void setSaltStyle(SaltStyle saltStyle) &#123; this.saltStyle = saltStyle; if (saltStyle == SaltStyle.COLUMN &amp;&amp; authenticationQuery.equals(DEFAULT_AUTHENTICATION_QUERY)) &#123; authenticationQuery = DEFAULT_SALTED_AUTHENTICATION_QUERY; &#125; &#125; [3.发现源代码中使用预编译的原生JDBC,并根据索引查找对比,所以要求自定义语句时不能乱写,根据规则走] 12345678910111213141516171819202122232425PreparedStatement ps = null; ResultSet rs = null; try &#123; ps = conn.prepareStatement(authenticationQuery); ps.setString(1, username); // Execute query rs = ps.executeQuery(); // Loop over results - although we are only expecting one result, since usernames should be unique boolean foundResult = false; while (rs.next()) &#123; // Check to ensure only one row is processed if (foundResult) &#123; throw new AuthenticationException(&quot;More than one user row found for user [&quot; + username + &quot;]. Usernames must be unique.&quot;); &#125; result[0] = rs.getString(1); //索引查询 if (returningSeparatedSalt) &#123; result[1] = rs.getString(2); &#125; foundResult = true; &#125; new SimpleAuthenticationInfo()(存放唯一认证) 源码分析 principal: 整个Shiro中唯一的标识符,可以存用户名,也可以存ID credentials: 唯一标识符的密码 realmName: 当前数据源的名字 1234public SimpleAuthenticationInfo(Object principal, Object credentials, String realmName) &#123; this.principals = new SimplePrincipalCollection(principal, realmName); this.credentials = credentials; &#125; 使用了工厂模式来对SecurityManager进行生成和配置 生成过程是使用单例+工厂 提供对外的工具类来使用，包含获取SecurityManager的方法和获取Subject的方法 (代码略) subject的使用是通过传入AuthenticationToken接口（注意是接口，其实扩展接口rememnverMeaut…和HostAutho…）， 该接口目前的实现类是UserPasswordToken，当然也可以自己扩展实现自定义的认证Token 测试加密算法盐值加密如果几个人密码一样，那么加密后的密码则一致。这样不安全，要解决这个问题，可以在密码上加盐。一般会选择不重复的值作为盐值，例如 用户名。(部分代码) 12345678//构造方法： //第一个参数：散列算法 //第二个参数：明文，原始密码 //第三个参数：盐，通过使用随机数 //第四个参数：散列的次数，比如散列两次，相当 于md5(md5('')) SimpleHash simpleHash = new SimpleHash("md5", source, salt, hashIterations); String md5 = simpleHash.toString(); System.out.println(md5); 12345678910111213141516shiro-realm-md5.ini---------------------[main]定义凭证匹配器credentialsMatcher=org.apache.shiro.authc.credential.HashedCredentialsMatcher散列算法credentialsMatcher.hashAlgorithmName=md5散列次数credentialsMatcher.hashIterations=1024开启加盐（无需设置，realm中使用的SimpleAuthenticationInfo 是 SaltedAuthenticationInfo 接口的实现类，默认开启的加盐功能）credentialsMatcher.hashSalted=true自定义 realmcustomRealm=com.qfedu.shirodemo.realm.CustomRealmMd5customRealm.credentialsMatcher=$credentialsMatcher将realm设置到securityManager，相当 于spring中注入securityManager.realms=$customRealm 授权流程原理授权 授权，也叫访问控制，即在应用中控制谁能访问哪些资源（如访问页面/编辑数据/页面操作等）。在授权中需了解的几个关键对象：主体（Subject）、资源（Resource）、权限（Permission）、角色（Role）。 主体（Subject） 主体，即访问应用的用户，在Shiro中使用Subject代表该用户。用户只有授权后才允许访问相应的资源。 资源 在应用中用户可以访问的任何东西，比如JSP 页面、某些数据、某个业务方法等等都是资源。用户只要授权后才能访问。 角色 角色代表了操作集合，可以理解为权限的集合，一般情况下我们会赋予用户角色而不是权限，即这样用户可以拥有一组权限，赋予权限时比较方便。 典型的如：项目经理、技术总监、CTO、开发工程师等都是角色，不同的角色拥有一组不同的权限。 权限 权限表示在应用中用户能不能访问某个资源， 如：访问用户列表页面查看/新增/修改/删除用户数据（即很多时候都是CRUD（增查改删）式权限控制）打印文档等等。。。 判断是否授权的方式Shiro 支持三种方式的授权判断： 编程式 通过写if/else 授权代码块完成： Subject subject = SecurityUtils.getSubject(); if(subject.hasRole(“admin”)) { ​ //有权限 } else { ​ //无权限 } 注解式 通过在执行的Java方法上放置相应的注解完成： @RequiresRoles(“admin”) public void hello() { //有权限 } 没有权限将抛出相应的异常； JSP 标签 在JSP 页面通过相应的标签完成： 12345&lt;shiro:hasRole name=&quot;admin&quot;&gt;&lt;!— 有权限—&gt;&lt; /shiro:hasRole &gt; 自定义realm授权从认证的realm拷贝，改变继承的抽象父类，添加新的方法 5.程序分析程序分析：从应用程序角度的来观察如何使用Shiro完成工作 应用代码通过Subject来进行认证和授权，而Subject又委托给SecurityManager； 我们需要给Shiro的SecurityManager注入Realm，从而让SecurityManager能得到合法的用户及其权限进行判断。 可以看到：应用代码直接交互的对象是Subject，也就是说Shiro的对外API核心就是Subject； Shiro内部结构 详细原理深入和运用:http://jinnianshilongnian.iteye.com/blog/2018398 6.Shiro认证技巧整理工具类接口的使用建立一个工具类接口Constants,以常量字符串的方式,专门存放Shiro中自定义的标识符 12345678910public interface Constants &#123; // md5(用户密码+PASSWORD_SALT_KEY)保存到数据库中。 String PASSWORD_SALT_KEY = &quot;Shiro.admin.2017&quot;; //Shiro的session中存放用户的key String SESSION_USER_KEY = &quot;SESSION_USER_KEY&quot;; //redis中存放的用户权限菜单的key String SESSION_USER_MANU = &quot;SESSION_USER_MANU&quot;; //Shiro存放的角色信息 String SESSION_USER_ROLE = &quot;SESSION_USER_ROLE&quot;;&#125; 接口工具类的思路不仅限于Shiro,灵活的定义接口,将冗余和容易混淆的部分抽离出来统一管理,可以极大的提高开发和维护的效率 认证优化技巧Controller层登录方法中,接收到用户名和密码后先进行 1234Subject currentUser = SecurityUtils.getSubject();if (!currentUser.isAuthenticated()) &#123; ...认证&#125; 直接获取subject,先进性判断该用户是否认证过,如果认证过则直接跳出即可 如果没有认证过,再进入认证环节 该逻辑可以减少服务器和数据库的压力,提高服务器的并发能力 ..shiro.xml 拦截器设置Shiro主过滤器本身功能十分强大,其强大之处就在于它支持任何基于URL路径表达式的、自定义的过滤器的执行 /login.html=anon 静态资源的方式屏蔽过滤器 /**=authc 该路径下需要认证才能访问 … 过滤器的完整参考： http://blog.csdn.net/jadyer/article/details/12172839 登录认证使用原理动态权限控制 RBAC（Role-Based Access Control ）基于角色的访问控制 配置好环境和工具类 自定义Realm和异常 service中添加通过用户名查找用户信息 在Controller层认证登录 UsernamePasswordToken token = new UsernamePasswordToken(name, password); Subject subject = SecurityUtils.getSubject(); ubject.login(token); 将真正的验证交给封装的底层–&gt;AuthenticationToken实现.(自定义Realm中) 通过此时token的username去数据库查询用户信息 用户信息存在,则存入SimpleAuthenticationInfo,否则 抛出用户对应的异常 Shiro的分布式认证结构(shiro认证将账号密码的比较环节封装到AuthenticationToken中) ​ Realm放在Controller中,在分布式中Controller使用Dubbo服务端接口,而dubbo接口通过service实现类来发布,这个角度看realm与dao隔层交互设计不太合理 ​ 验证成功则返回SimpleAuthenticationInfo(存放唯一标识(id或者username),密码,Realm名 7.Shiro授权技巧整理 通过用户登录的唯一标识principals 查找到用户有哪些菜单权限(ID) 将这些ID存到SimpleAuthorizationInfo中 在自定义ShiroFilterFactoryBean中获取所有菜单列表,并将id加入到section中 底层自动对比,哪些ID用户有,则允许访问,没有的话”authc”拦截 Controller中查询用户拥有的菜单数据返回前段即可,此时没有权限的数据已经被拦截 易错集合1.授权URL​ 注意使用Shiro权限设置后的url如果需要访问,逻辑路径需要放在 前端 拼接,(后台对逻辑路径没有识别,也没有必要识别,不能将逻辑路径放在后台和数据库中) 2.权限顺序​ 运行时先执行MyRealm中的权限,然后拼接MyShiroFilterFactoryBean中的权限 ​ 注意:限制范围较大的往后排,特别是全部拦截的/ 如果需要的话尽量放在MyShiroFilterFactoryBean**中 8.Remember me功能简述Shiro的Remember Me可以很轻松的实现自动登录的功能,方便快捷 实现过程123456UsernamePasswordToken token = new UsernamePasswordToken(username, password); Subject subject = SecurityUtils.getSubject(); if(loginForm.getRememberMe() != null &amp;&amp; &quot;Y&quot;.equals(loginForm.getRememberMe()))&#123; token.setRememberMe(true); &#125; subject.login(token); 1/** = user Remember Me只需要在登录时将token的RememberMe功能开启,本来的拦截级别为/ = authc 将拦截设置(降级)为user级别**即可使用 Remember Me功能开启使用后,Shiro会生成一个叫RememberMe的Cookie保存在浏览器中,当subject.loginout退出或者过期后失效,改参数是base64加密的字符串如下 12名称： rememberMe内容： 6gYvaCGZaDXt1c0xwriXj/Uvz6g8OMT3VSaAK4WL0Fvqvkcm0nf3CfTwkWWTT4EjeSS/EoQjRfCPv4WKUXezQDvoNwVgFMtsLIeYMAfTd17ey5BrZQMxW+xU1lBSDoEM1yOy/i11ENh6eXjmYeQFv0yGbhchGdJWzk5W3MxJjv2SljlW4dkGxOSsol3mucoShzmcQ4VqiDjTcbVfZ7mxSHF/0M1JnXRphi8meDaIm9IwM4Hilgjmai+yzdVHFVDDHv/vsU/fZmjb+2tJnBiZ+jrDhl2Elt4qBDKxUKT05cDtXaUZWYQmP1bet2EqTfE8eiofa1+FO3iSTJmEocRLDLPWKSJ26bUWA8wUl/QdpH07Ymq1W0ho8EIdFhOsELxM66oMcj7a/8LVzypJXAXZdMFaNe8cBSN2dXpv4PwiktCs3J9P9vP4XrmYees5x27UmXNqYFk86xQhRjFdJsw5A9ctDKXzPYvJmWFouo3qT5hugX0uxWALCfWg8MHJnG9w7QgVKM8oy3Xy4Ut8lSvYlA== Shiro的RememberMe设计时!=已经登录,因为该cookie被序列化后可以不同的浏览器之间访问,并且可能被黑客复制截取等,因此使用该功能的话尽量以非关键性资源为主,当牵扯到资金等关键资源时,选择再次登录即可 开发时如果使用Session域对象,则自动登录后Session中不会再有数据,如果需要用到,那么需要重写isAccessAllowed 方法 详细参考自:https://blog.csdn.net/nsrainbow/article/details/36945267/ (本次Remember Me尚未指定配置更改,待更新)]]></content>
      <categories>
        <category>框架</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Spring-MVC基础原理]]></title>
    <url>%2F2018%2F05%2F15%2FSpring-MVC%E5%9F%BA%E7%A1%80%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[1.Spring-MVC基础原理[TOC] 1.概念优秀的Web框架,具有松散耦合,拔插组件结构,注解驱动,REST风格支持等特性,比其他web框架更具有扩展性和灵活性 在数据绑定,视图解析,本地化处理,静态资源处理上有不俗的表现,远超Struts2,WebWork等MVC框架 2.MVC框架MVC全称 Model veiw Controller(模型视图控制器) 软件级的解耦分离 M:主要包含service(核心业务逻辑)和dao(数据库访问) V:静态资源,如HTML5,JS,CSS等 C:servlet(主要处理页面的转发和重定向,数据的接收,域对象的操作,)和jsp(本身也是servlet) MVC 分层有助于管理复杂的应用程序，因为您可以在一个时间内专门关注一个方面。例如，您可以在不依赖业务逻辑的情况下专注于视图设计。同时也让应用程序的测试更加容易。 MVC 分层同时也简化了分组开发。不同的开发人员可同时开发视图、控制器逻辑和业务逻辑。 (扩展)Spring MVC是基于 Model 2实现的技术框架,Model 2是经典的MVC(model,view,control)模型在WEB应用中的变体.这个改变主要源于HTTP协议的无状态性,Model 2 的目的和MVC一样,也是利用处理器分离模型,视图和控制,达到不同技术层级间松散层耦合的效果,提高系统灵活性,复用性和可维护性.大多情况下,可以将Model 2 与 MVC等同起来. (扩展)三层架构基础 物理三层架构:客户端(如浏览器)/Web服务器/数据库服务器 逻辑三层架构:表现层/业务逻辑层/数据库访问层 3.Spring MVC体系概述Spring-MVC围绕着DispatcherServlet(前段控制器)这个核心展开,所有的前端请求都会拦截经过这里分发到Spring MVC的各个处理器中处理,(扩展)如注解驱动控制器,请求及响应的信息处理,视图解析,本地化解析,上传文件解析,异常处理及表单标签绑定内容等… 4.Spring MVC核心组件 DispatcherServlet：作为前端控制器，整个流程控制的中心，控制其它组件执行，统一调度，降低组件之间的耦合性，提高每个组件的扩展性。 HandlerMapping：通过扩展处理器映射器实现不同的映射方式，例如：配置文件方式，实现接口方式，注解方式等。 HandlAdapter：通过扩展处理器适配器，支持更多类型的处理器,调用处理器传递参数等工作! ViewResolver：通过扩展视图解析器，支持更多类型的视图解析，例如：jsp、freemarker、pdf、excel等。 5.Spring MVC执行流程 5-1.Controller和Handler关系Controller指的是类 Handler指的是Controller中的方法,每次URL访问Handler都是访问的@RequestMapper所标注的方法 6.DispatcherServlet1.核心 DispatcherServlet 是Spring-MVC的核心构成,负责协调所有mvc的处理器, DispatcherServlet可以和Spring-IoC无缝集成,获得Spring的所有好处 使用时需要在web.xml中对DispatcherServlet进行配置 2.DispatcherServlet继承关系图 3.DispatcherServlet的责任主要负责调度Spring-mvc的工作,并控制MVC的流程 文件上传解析，如果请求类型是multipart将通过MultipartResolver进行文件上传解析； 通过HandlerMapping，将请求映射到处理器（返回一个HandlerExecutionChain，它包括一个处理器、多个HandlerInterceptor拦截器）； 通过HandlerAdapter支持多种类型的处理器(HandlerExecutionChain中的处理器)； 通过ViewResolver解析逻辑视图名到具体视图实现； 本地化解析； 渲染具体的视图等； 如果执行过程中遇到异常将交给HandlerExceptionResolver来解析。 4.DispatcherServlet核心代码5.DispatcherServlet辅助类传送门:https://xuzhongcn.github.io/#top7.常用注解(实用重点)1.@RequestMapping 请求方式写在类或者方法上,表示请求该类或方法的路径 1.value methodvalue: 请求路径 指定为普通具体值(如”/dologin”) 指定为某一变量 123456@RequestMapping(value=&quot;/user/&#123;username&#125;&quot;, method=RequestMethod.GET)public String findOwner(@PathVariable String username, Model model) &#123; User user=userService.selectUserByUsername(username); model.addAttribute(&quot;user&quot;, user); return &quot;user&quot;; &#125; 指定为含有正则表达式的变量(略) method: 请求类型 GET、POST、PUT、DELETE等 RestFull https://blog.csdn.net/gebitan505/article/details/70143901 2.consumes producesconsumes: 指定处理请求提交的内容类型（Content-Type），例如application/json, text/html; 123456@Controller@RequestMapping(value = &quot;/pets&quot;, method = RequestMethod.POST, consumes=&quot;application/json&quot;)public void addPet(@RequestBody Pet pet, Model model) &#123; // implementation omitted //方法仅处理request Content-Type为“application/json”类型的请求。&#125; produces: 指定返回的内容类型，仅当request请求头中的(Accept)类型中包含该指定类型才返回； 123456@Controller@RequestMapping(value = &quot;/pets/&#123;petId&#125;&quot;, method = RequestMethod.GET, produces=&quot;application/json&quot;)@ResponseBodypublic Pet getPet(@PathVariable String petId, Model model) &#123; // implementation omitted&#125; 仅处理request请求头header中包含了指定类型application/json的请求,同时暗示返回数据也是json 3.params headersparams: 指定request中必须包含某些参数才可以调用该方法 123456789@Controller@RequestMapping(&quot;/owners/&#123;ownerId&#125;&quot;)public class RelativePathUriTemplateController &#123; @RequestMapping(value = &quot;/pets/&#123;petId&#125;&quot;, method = RequestMethod.GET, params=&quot;myParam=myValue&quot;) public void findPet(@PathVariable String ownerId, @PathVariable String petId, Model model) &#123; // implementation omitted &#125;&#125; 仅处理请求中包含了名为“myParam”，值为“myValue”的请求； headers:指定的request中必须包含指定的header值才可以调用该方法 123456789@Controller@RequestMapping(&quot;/owners/&#123;ownerId&#125;&quot;)public class RelativePathUriTemplateController &#123;@RequestMapping(value = &quot;/pets&quot;, method = RequestMethod.GET, headers=&quot;Referer=http://www.ifeng.com/&quot;) public void findPet(@PathVariable String ownerId, @PathVariable String petId, Model model) &#123; // implementation omitted &#125;&#125; 仅处理request的header中包含了指定“Refer”请求头和对应值为“http://www.ifeng.com/”的请求； 2.@RequestParam 处理请求参数3.@PathVariable 路径传参4.@RequestBody 处理Json/xml请求requestBody 常用来处理不是默认类型application/x-www-form-urlcoded 的请求 如application/json或者是application/xml等(一般处理json) requestBody可以将请求体中的JSON字符串绑定到相应的bean上，也可以将其分别绑定到对应的字符串上 123456789 @requestMapping(&quot;/login&quot;) public void login(@requestBody String userName,@requestBody String pwd)&#123; System.out.println(userName+&quot; ：&quot;+pwd); &#125;--------------- @requestMapping(&quot;/login&quot;) public void login(@requestBody User user)&#123; System.out.println(user); &#125; 5.@ResponseBody 处理Json/xml 响应responseBody:用于将数据放到response的body体中响应到前端 注意:返回的数据不是html标签页面,而是json/xml数据 ​ 如果返回String,此方法原理相当于response.write(),都不走视图解析,直接响应给页面数据,如果使用对象,才会解析为json 6.@JsonFomat格式化时间123456789/**更新时间 用户可以点击更新，保存最新更新的时间。**/@JsonFormat(pattern=&quot;yyyy-MM-dd HH:mm:ss&quot;)private Date updateTime;或者getter上@JsonFormat(pattern=&quot;yyyy-MM-dd HH:mm:ss&quot;)public Date getUpdateTime() &#123; return updateTime;&#125; 格式化时间 对于请求类型的适配原理传送门:http://www.cnblogs.com/qq78292959/p/3760651.html 8.伪静态化SEO优化请求的后缀改为.html 可以实现伪静态化,欺骗SEO搜索(对动态不友好),此处拦截也可以改为*.html, 这样静态资源也不会被拦截(不需要配置静态资源映射了) 8-1.简单优化过程web.xml 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;web-app xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://java.sun.com/xml/ns/javaee" xsi:schemaLocation="http://java.sun.com/xml/ns/javaee http://java.sun.com/xml/ns/javaee/web-app_2_5.xsd" id="WebApp_ID" version="2.5"&gt; &lt;display-name&gt;e3-portal-web&lt;/display-name&gt; &lt;welcome-file-list&gt; &lt;welcome-file&gt;index.html&lt;/welcome-file&gt; &lt;/welcome-file-list&gt; &lt;!-- 解决post乱码 --&gt; &lt;filter&gt; &lt;filter-name&gt;CharacterEncodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;utf-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;CharacterEncodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;!-- springmvc的前端控制器 --&gt; &lt;servlet&gt; &lt;servlet-name&gt;e3-portal-web&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;!-- contextConfigLocation不是必须的， 如果不配置contextConfigLocation， springmvc的配置文件默认在：WEB-INF/servlet的name+"-servlet.xml" --&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:spring/springmvc.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;e3-portal-web&lt;/servlet-name&gt; &lt;!-- 拦截指定后缀所有请求 伪静态化 --&gt; &lt;url-pattern&gt;*.html&lt;/url-pattern&gt; &lt;/servlet-mapping&gt;&lt;/web-app&gt; Handler 1234@RequestMapping(&quot;/index.html&quot;) public String showIndex()&#123; return &quot;index&quot;; &#125; 欢迎页改为index.html 当静态页面中没有index.html时,请求会被Spring-mvc拦截器拦截到(后缀为.html) 拦截到index请求后发送到Controller中的对应Handler中,完成伪静态优化]]></content>
      <categories>
        <category>Spring全家桶</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[基础排序 组合]]></title>
    <url>%2F2018%2F05%2F08%2F%E5%9F%BA%E7%A1%80%E6%8E%92%E5%BA%8F%20%E7%BB%84%E5%90%88%2F</url>
    <content type="text"><![CDATA[规范:()中,先写下,在写上 [TOC] 1.排序转换为计算机写法A(n,m) n在下 m在上 ​ 即:n个数中取m个来排序 2.组合转换为计算机写法C(n,m) n在下 m在上 ​ 即: 分子:n的阶乘,阶乘的个数为m ​ 分母:m的阶乘]]></content>
      <categories>
        <category>初等数学</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Quartz基础原理]]></title>
    <url>%2F2018%2F05%2F07%2FQuartz%E5%9F%BA%E7%A1%80%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[Quartz基础原理1.概念Quartz是开源的任务调度框架,集合可以应用于任何java程序中,小到独立的小项目,大到规模庞大的电子商务系统. Quartz可以创建几条/几百条甚至十万条作业调度数 (Quartz的作业环境可以很复杂,精确到每个月最后一个工作日的22:50) 场景:每月自动还款/广告自动上下架/几个小时自动备份云盘等 2.核心组成Scheduler：调度器。所有的调度都是由它控制。包含两个重要组件 ​ JobStore:存储运行时的信息,包括Trigger,Schduler,JobDetail，业务锁等 ​ ThreadPool:Quartz自己的线程池实现,所有的任务都有线程池执行 Trigger:触发器.定义触发条件.常用SimpleTrigger/CronTirgger，每隔1秒中执行一次,五种类型 SimpleTrigger CronTirgger DateIntervalTrigger NthIncludedDayTrigger Calendar 类（ org.quartz.Calendar） 常用: SimpleTrigger：用来触发只需执行一次或者在给定时间触发并且重复N次且每次执行延迟一定时间的任务。 CronTrigger：按照日历触发，例如“每个周五”，每个月10日中午或者10：15分。 JobDetail &amp; Job：JobDetail 定义的是任务数据，而真正的执行逻辑是在Job中。 ​ 设计成JobDetail+Job是因为任务有可能并发执行的,如果Scheduler直接使用Job,则有可能在同一时刻多个线程同时访问一个Job实例,造成并发访问问题; ​ 而JobDetail&amp;Job的模式下,Scheduler每次使用Job前,JobDetail都会构建一个新的Job,以此来规避并发访问问题 JobDetail和Trigger都有name和group。 ​ name是Scheduler中的唯一标识,如果想更新JobDetail或Trigger,只需要重新定义相同的name覆盖即可 ​ group是组织单元,使Scheduler可以整组的调度作业 3.核心关系图 4.原理(精)传送门:https://xuzhongcn.github.io/5.使用5-1 Cron表达式的格式：秒 分 时 日 月 周 年(可选)。 字段名 允许的值 允许的特殊字符 秒 0-59 , - * / 分 0-59 , - * / 小时 0-23 , - * / 日 1-31 , - * ? / L W C 月 1-12 or JAN-DEC , - * / 周几 1-7 or SUN-SAT , - * ? / L C # SUN , MON , TUE , WED , THU , FRI and SAT 年 (可选字段) empty, 1970-2099 , - * / “?”字符：表示不确定的值 “,”字符：指定数个值 “-”字符：指定一个值的范围 “/”字符：指定一个值的增加幅度。 n/m表示从n开始，每次增加m “L”字符：用在日表示一个月中的最后一天，用在周表示该月最后一个星期X “W”字符：指定离给定日期最近的工作日(周一到周五) “#”字符：表示该月第几个周X。6#3表示该月第3个周五 Cron表达式示例 每隔5秒执行一次：/5 * ? 每隔1分钟执行一次：0 /1 ? 每天23点执行一次：0 0 23 ? 每天凌晨1点执行一次：0 0 1 ? 每月1号凌晨1点执行一次：0 0 1 1 * ? 每月最后一天23点执行一次：0 0 23 L * ? 每周星期六凌晨1点实行一次：0 0 1 ? * L 在26分、29分、33分执行一次：0 26,29,33 * ? 每天的0点、13点、18点、21点都执行一次：0 0 0,13,18,21 ?]]></content>
      <categories>
        <category>框架</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Redis基础原理]]></title>
    <url>%2F2018%2F05%2F04%2FRedis%E5%9F%BA%E7%A1%80%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[Redis基础原理[TOC] 1.概念NoSQL 非关系型数据库,Redis是非关系型数据库中的键值存储数据库 应用 处理高并发/海量数据的访问,内容缓存/内容持久化 同样具有分布式的内存对象缓存的系统还有MemCache (不能数据持久化) 简介传送门:https://blog.csdn.net/sinat_33994744/article/details/56514901 优点 快速查询,支持横向扩充(集群)和纵向扩充(加强设备) 丰富的数据类型String，list，set，sorted set，hash 一主多从,读写分离 哨兵机制,检测选举 集群机制,多主多从,数据高可用,分布式存储 保存在内存中,速度很快 读11W/s | 写8W/s 缺点 ​ 存储缺少结构化(难以构建关系型理数据库模型) 2.数据类型String最简单的KV存储,value可以是String也可以是数字等 场景 kv字符串结构等,非常普遍 指令 ​ SET key value 设置key=value ​ GET key 或者键key对应的值 ​ GETRANGE key start end 得到字符串的子字符串存放在一个键 ​ GETSET key value 设置键的字符串值，并返回旧值 ​ GETBIT key offset 返回存储在键位值的字符串值的偏移 ​ MGET key1 [key2..] 得到所有的给定键的值 ​ SETBIT key offset value 设置或清除该位在存储在键的字符串值偏移 ​ SETEX key seconds value 键到期时设置值 ​ SETNX key value 设置键的值，只有当该键不存在 ​ SETRANGE key offset value 覆盖字符串的一部分从指定键的偏移 ​ STRLEN key 得到存储在键的值的长度 ​ MSET key value [key value…] 设置多个键和多个值 ​ MSETNX key value [key value…] 设置多个键多个值，只有在当没有按键的存在时 ​ PSETEX key milliseconds value 设置键的毫秒值和到期时间 ​ INCR key 增加键的整数值一次 ​ incr key 让Redis统计网站访问量,速度快,减少并发问题,生成主键 ​ INCRBY key increment 由给定的数量递增键的整数值 ​ INCRBYFLOAT key increment 由给定的数量递增键的浮点值 ​ DECR key 递减键一次的整数值 ​ DECRBY key decrement 由给定数目递减键的整数值 ​ APPEND key value 追加值到一个键 ​ ——–操作管理———- KEYS * 查看所有的Key DEL key 如果存在删除键 DUMP key 返回存储在指定键的值的序列化版本 EXISTS key 此命令检查该键是否存在 EXPIRE key seconds 指定键的过期时间 常用 EXPIREAT key timestamp 指定的键过期时间。在这里，时间是在Unix时间戳格式 PEXPIRE key milliseconds 设置键以毫秒为单位到期 PEXPIREAT key milliseconds-timestamp 设置键在Unix时间戳指定为毫秒到期 KEYS pattern 查找与指定模式匹配的所有键 MOVE key db 移动键到另一个数据库 PERSIST key 移除过期的键 常用,让key持久化 PTTL key 以毫秒为单位获取剩余时间的到期键。 TTL key 获取键到期的剩余时间。 正数是有过期时间,-1是持久化,-2是不存在 RANDOMKEY 从Redis返回随机键 RENAME key newkey 更改键的名称 RENAMENX key newkey 重命名键，如果新的键不存在 TYPE key 返回存储在键的数据类型的值。 List(列表)字符串列表,非常重要的Redis类型,本质是双向链表,支持反向查询和遍历,更加方便,但是会额外增加内存开销(存储双向链表),redis内部的发送缓冲队列使用的就是List结构 一般用来做排队处理的工作(队列)一个一个左边加,一个一个右边取 场景 如twitter的关注列表和粉丝列表,实现轻量级的消息队列等 指令 BLPOPBLPOP key1 [key2 ] timeout 取出并获取列表中的第一个元素，或阻塞，直到有可用 BRPOPBRPOP key1 [key2 ] timeout 取出并获取列表中的最后一个元素，或阻塞，直到有可用 BRPOPLPUSHBRPOPLPUSH source destination timeout 从列表中弹出一个值，它推到另一个列表并返回它;或阻塞，直到有可用 LINDEXLINDEX key index 从一个列表其索引获取对应的元素 LINSERTLINSERT key BEFORE|AFTER pivot value 在列表中的其他元素之后或之前插入一个元素 LLENLLEN key 获取列表的长度 LPOPLPOP key 获取并取出列表中的第一个元素,并移除 LPUSHLPUSH key value1 value2 [value3] 在value3左边加上一个或多个值的列表 LPUSHXLPUSHX key value 在前面加上一个值列表，仅当列表中存在 LRANGELRANGE key 0 -1 (其中0和-1的集合代表查看全部)从一个列表获取各种元素 LREMLREM key count value 从列表中删除元素 LSETLSET key index value 在列表中的索引设置一个元素的值 LTRIMLTRIM key start stop 修剪列表到指定的范围内 RPOPRPOP key 取出并获取列表中的最后一个元素,并移除 RPOPLPUSHRPOPLPUSH source destination 删除最后一个元素的列表，将其附加到另一个列表并返回它 RPUSHRPUSH key value1 value2 [value3] 在value3右边添加一个或多个值到列表 RPUSHXRPUSHX key value 添加一个值列表，仅当列表中存在 HashRedis Hash对应Value内部实际就是一个HashMap，实际这里会有2种不同实现，这个Hash的成员比较少时Redis为了节省内存会采用类似一维数组的方式来紧凑存储，而不会采用真正的HashMap结构，对应的value redisObject的encoding为zipmap,当成员数量增大时会自动转成真正的HashMap,此时encoding为ht。 场景 可以方便的存储用户信息,用户ID为Key,用户信息序列化为value存储 注意 不能设定Hash的key中指定field的过期时间(只有key的过期时间) 指令 HDELHDEL key field[field…] 删除对象的一个或几个属性域，不存在的属性将被忽略 HEXISTSHEXISTS key field 查看对象是否存在该属性域 HGETHGET key field 获取对象中该field属性域的值 HGETALLHGETALL key 获取对象的所有属性域和值 HSETHSET key field value 设置对象指定字段的值 HMSETHMSET key field value [field value …] 同时设置对象中一个或多个字段的值 HSETNXHSETNX key field value 只在对象不存在指定的字段时才设置字段的值 HINCRBYHINCRBY key field value 将该对象中指定域的值增加给定的value，原子自增操作，只能是integer的属性值可以使用 HINCRBYFLOATHINCRBYFLOAT key field increment 将该对象中指定域的值增加给定的浮点数 HKEYSHKEYS key 获取对象的所有属性字段 HVALSHVALS key 获取对象的所有属性值 HLENHLEN key 获取对象的所有属性字段的总数 HMGETHMGET key field[field…] 获取对象的一个或多个指定字段的值 HSTRLENHSTRLEN key field 返回对象指定field的value的字符串长度，如果该对象或者field不存在，返回0. HSCANHSCAN key cursor [MATCH pattern][COUNT count] 类似SCAN命令 HKEYS HKeys key 查看key中所有的field HVALS Hvals key 查看key中所有field的对应的值 HGETALL HgetAll key 查看key中所有的field和value Set存储数据不重复,set 的内部实现是一个 value永远为null的HashMap，实际就是通过计算hash的方式来快速排重的，这也是set能提供判断一个成员是否在集合内的原因。 用来去重 场景 set和list的功能类似,但是set加载的列表自动排重,当你需要存储一个列表数据，又不希望出现重复数据时，set是一个很好的选择，并且set提供了判断某个成员是否在一个set集合内的重要接口，这个也是list所不能提供的。 在微博应用中，每个用户关注的人存在一个集合中，就很容易实现求两个人的共同好友功能。 指令 SADDSADD key member [member …] 添加一个或者多个元素到集合(set)里 SACRDSCARD key 获取集合里面的元素数量 SDIFFSDIFF key [key …] 获得队列不存在的元素 SDIFFSTORESDIFFSTORE destination key [key …] 获得队列不存在的元素，并存储在一个关键的结果集 SINTERSTORESINTERSTORE destination key [key …] 获得两个集合的交集，并存储在一个集合中 SISMEMBERSISMEMBER key member 确定一个给定的值是一个集合的成员 SMEMBERSSMEMBERS key 获取集合里面的所有key SMOVESMOVE source destination member 移动集合里面的一个key到另一个集合 SPOPSPOP key [count] 获取并删除一个集合里面的元素 SRANDMEMBERSRANDMEMBER key [count] 从集合里面随机获取一个元素 SREMSREM key member [member …] 从集合里删除一个或多个元素，不存在的元素会被忽略 SUNIONSTORESUNIONSTORE destination key [key …] 合并set元素，并将结果存入新的set里面 SSCANSSCAN key cursor [MATCH pattern][COUNT count] 迭代set里面的元素 Set中key的各种关系筛选,可以两个也可以多个 设置 Sadd seta a b c d e Sadd setb c d e f g SDIFF 差集 Sdiff seta setb 结果 a b Sdiff setb seta 结果 f g SINTER 交集SINTER seta [setb …] 获得两个集合的交集 结果 c d e SUNION 并集 Sunion seta setb 结果 a b c d e f g Sorted Setset的有序版,由HaspMap和跳跃表组成,兼顾list和set 有序去重,但是处理两方面sorted性能消耗大 场景 用户的积分排行榜需求就可以通过有序集合实现。还有上面介绍的使用List实现轻量级的消息队列，其实也可以通过Sorted Set实现有优先级或按权重的队列。 指令 ZADDZADD key score1 member1 [score2 member2] 添加一个或多个成员到有序集合，或者如果它已经存在更新其分数 ZCARDZCARD key 得到的有序集合成员的数量 ZCOUNTZCOUNT key min max 计算一个有序集合成员与给定值范围内的分数 ZINCRBYZINCRBY key increment member 在有序集合增加成员的分数 ZINTERSTOREZINTERSTORE destination numkeys key [key …] 多重交叉排序集合，并存储生成一个新的键有序集合。 ZLEXCOUNTZLEXCOUNT key min max 计算一个给定的字典范围之间的有序集合成员的数量 ZRANGEZRANGE key start stop [WITHSCORES] 由索引返回一个成员范围的有序集合（从低到高）0 -1 取全部 ZRANGEBYLEXZRANGEBYLEX key min max [LIMIT offset count]返回一个成员范围的有序集合（由字典范围） ZRANGEBYSCOREZRANGEBYSCORE key min max [WITHSCORES][LIMIT] 返回有序集key中，所有 score 值介于 min 和 max 之间(包括等于 min 或 max )的成员，有序集成员按 score 值递增(从小到大)次序排列 ZRANKZRANK key member 确定成员的索引中有序集合 ZREMZREM key member [member …] 从有序集合中删除一个或多个成员，不存在的成员将被忽略 ZREMRANGEBYLEXZREMRANGEBYLEX key min max 删除所有成员在给定的字典范围之间的有序集合 ZREMRANGEBYRANKZREMRANGEBYRANK key start stop 在给定的索引之内删除所有成员的有序集合 ZREMRANGEBYSCOREZREMRANGEBYSCORE key min max 在给定的分数之内删除所有成员的有序集合 ZREVRANGEZREVRANGE key start stop [WITHSCORES] 返回一个成员范围的有序集合，通过索引，以分数排序，从高分到低分 ZREVRANGEBYSCOREZREVRANGEBYSCORE key max min [WITHSCORES] 返回一个成员范围的有序集合，以socre排序从高到低 ZREVRANK ZrevrankZREVRANK key member 确定一个有序集合成员的索引，以分数排序，从高分到低分 ZSCOREZSCORE key member 获取给定成员相关联的分数在一个有序集合 ZUNIONSTOREZUNIONSTORE destination numkeys key [key …] 添加多个集排序，所得排序集合存储在一个新的键 ZSCANZSCAN key cursor [MATCH pattern] [COUNT count] 增量迭代排序元素集和相关的分数 **Redis过期策略:https://www.jb51.net/article/103236.htm 3.Redis运用Redis使用策略设计模式来开发(接口+实现类,方便切换单机和集群版) 文件夹格式 key中如果存在 : 那么该符号将被额外解析为文件夹层级 如 ITEM_INFO:TEST:BASE 被解析为ITEM_INFO文件夹下–&gt;TEST子文件夹下的key ITEM_INFO:TEST:BASE 实际开发中,经常会用到集合(list读取较快)来存储缓存数据,但是Redis只支持List,不能直接支持List,因此需要制作工具类来转换Json类型读写 导入POM 导入JsonUtils工具类(将Object/List &lt;Object &gt;转化为字符串) 导入Redis工具类接口/实现接口 导入配置文件spring-redis/redis.properties service中注入使用即可 注意spring的加载机制: 1Caused by: java.lang.IllegalArgumentException: Could not resolve placeholder &apos;USER_LIST&apos; in string value &quot;$&#123;USER_LIST&#125;&quot; Spring容器采用反射扫描的发现机制，在探测到Spring容器中有一个org.springframework.beans.factory.config.PropertyPlaceholderConfigurer的Bean就会停止对剩余PropertyPlaceholderConfigurer的扫描（Spring 3.1已经使用PropertySourcesPlaceholderConfigurer替代PropertyPlaceholderConfigurer了） 所以根据加载的顺序，配置的第二个property-placeholder就被没有被spring加载，我想引入的config-wxapp.properties就没有被引入，所以在使用@Value注入的时候占位符就解析不了…解决方法就是把2个property-placeholder注解配置合并在一起就好了 4.redis事务5.Redis持久化方案Redis 的所有数据都是保存在内存中 数据的完整性和速度要有取舍,如果追求完整性,用关系型数据库如MySQL.追求速度用Redis等. Rdb: 快照形式,定期把内存中当前的数据保存到磁盘中,Redis默认开启的持久化方案 在配置文件redis.config中存在,可以修改 123456####################SHAPSHOTTING#####################Save the DB on disk默认save 900 1 15分钟内1个key变化了,则15分钟保存一次save 300 10 5分钟内10个key变化了,则5分钟保存一次save 60 10000 1分钟10000个key变化了,则1分钟保存一次 aof: 123appendonly no 默认不开启,另一套持久化方案(频繁操作磁盘,会每秒钟保存一次,慢)如果觉得rdb丢数据可能性高,那么可以开启aof模式,将增删改命令保存到指定文件(恢复时运行一下就好)当前目录会生成一个appendonly.aof,运行它就可以恢复 Rdb和aof如果有必要可以同时开启 6.Redis集群Redis-cluster (最少三个) 集群所有节点相互通信,ping-pong,只要连接集群任意一个节点即可连接到集群 主从节点内容相同(同步缓存,高可用),主节点之间内容不同 增强Redis高可用–哨兵机制(投票)超过半数即生效 slot(槽)为了保证Redis负载均衡,使用slot来维护 将所有的物理节点映射到[0-16383]个槽上 根据算法,分配数据到不同的槽上(槽和数据数量没关系,只和服务器分配有关系) 7.缓存穿透/缓存雪崩/热点key方案8.假设redis只能缓存20W数据,如何保证2000W条数据的热点被使用MySQL里有2000w数据，redis中只存20w的数据，如何保证redis中的数据都是热点数据 相关知识：redis 内存数据集大小上升到一定大小的时候，就会施行数据淘汰策略。redis 提供 6种数据淘汰策略： voltile-lru：从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰 volatile-ttl：从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰 volatile-random：从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰 allkeys-lru：从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰 allkeys-random：从数据集（server.db[i].dict）中任意选择数据淘汰 no-enviction（驱逐）：禁止驱逐数据]]></content>
      <categories>
        <category>框架</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Spring基础原理]]></title>
    <url>%2F2018%2F04%2F15%2FSpring%E5%9F%BA%E7%A1%80%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[Spring基础原理[TOC] 1.Spring概念提供一个ioc容器来管理Bean,并通过AOP方式来增加Bean的功能 基于Spring-IoC和AOP来构建多层Java EE 项目,能构将项目内的组件进行解耦分离,大大提高了开发效率和维护效率 通过反射+XML实现的对象管理工厂(大容器) 目的: 解耦,简化开发 AOP编程的支持 声明事务的支持 方便程序测试 继承各种优秀框架 降低Java EE API的使用难度 2.核心概念 IoC: Inversion of Control 控制反转 (通过反射机制创建对象实例) DI: Dependency Injection 依赖注入(将bean之间的关系交给spring容器管理,我们可以在service注入dao层的实例,controller中注入service层实例) AOP: Aspect Oriented Programming 面向切面(通过JDK动态代理和CGlib动态代理实现) 3.Spring组成Spring框架的功能大概由20多个模块组成,这些模块按组可以分为以下几部分 | 核心容器 | 数据访问/集成 | WEB | AOP | 设备 | 消息 | 测试 | ​ 核心模块:Beans Core Context spEL对应项目初始化时需要的四个核心包 4.Spring说明 bean元素:需要spring管理的对象,是Spring中最基础的单位(包括数据源/SessionFactory/事务管理等) class属性: 需要spring管理对象的全类名 name属性:给被管理者起个引用名,根据该引用名就可以使用该对象(bean对象的标识) id属性:bean对象的唯一标识(和name的区别是整个spring中不可重复) lazy-init:是否延时加载,默认false(开启后只对单例有效) init-method:对象初始化方法 destory:对象销毁方法 scope:singleton(默认,适用实际开发的大部分情况)还是prototype 1.Spring管理对象原理1.Spring容器Spring要管理对象,就需要把对象加入到自己的容器中 Spring容器是Spring的核心,主要的责任便是管理Spring中java的组件 对象加入到Spring容器的三种方法(依赖注入) |无参构造+setter注入|有参构造方法注入|动静态工厂注入| 使用bean对象时,实例化容器的两种方法|ClassPathXml..xml实例化|FileSystem…绝对路径实例化| ApplicationContext容器实例化后,默认会实例化内部的所有bean,通过getBean即可获取bean对象的使用权 2.Spring容器与对象Bean通常情况下,Bean是被动的接收Spring容器创建的实例,具有使用权,即Bean不对Spring进行访问 如果想让Bean对Spring进行访问,则需要手动配置,让Bean实现BeanFactoryAware 接口… 该操作非常不推荐,污染代码,使Bean和Spring耦合在一起,若非特别需要,否则不要用 3.Spring容器中Bean的继承特性与Java中继承区别spring中可以使用抽象bean,即abstract 属性为true,抽象bean不能被实例化,作用是Spring中的继承 spring中的继承: 主要用于bean的数量越来越多,许多属性配置冗余,此时可以使用继承 spring的继承无法继承如下属性: depends-on,aotuwirwe,dependency-check,singleton,scope,lazy-iniyt这些属性总是子Bean定义，或采用默认值。 Bean继承与java中继承的区别： Spring中的子bean和父Bean可以是不同类型，但java中的继承则可保证子类是一种特殊的父类； Spring中的Bean的继承是实例之间的关系，因此只要表现在参数值的延续，而java中的继承是类之间的关系，主要表现为方法、属性之间的延续； Spring中的子Bean不可以作为父Bean使用，不具备多态性，java中的子类完全可以当成父类使用。 4.Spring容器中Bean模式的生命周期singleton： Spring容器能够准确的追踪其创建/使用/销毁 prototype：Spring容器仅负责其创建,无法追踪其使用和销毁,每次创建后都会委托给客户端,不再对其追踪 5.强制初始化Bean(使用较少)Spring有一个默认的规则，总是先初始化主调Bean，然后在初始化依赖Bean。为了指定Bean在目标Bean之前初始化，可以使用depends-on属性 6.自动装配 Spring能自动装配Bean与Bean之间的依赖关系，即使无需使用ref显式指定依赖Bean。 自动装配可以减少配置文件的工作量，但是降低了依赖关系的透明性和依赖性。 可以根据指定属性值类型来缩小自动装配的范围(很少指定) | no | byName | byType | constructor | autodetect | 7.依赖检察(使用较少)Spring提供一种依赖检查的功能，可以防止出现配置手误，或者其他情况的错误。dependency-check=”all” 该属性值可以为| none | simple | objects | all | 2.Spring核心机制:IoC/DI无论是IoC(控制反转) 还是DI(依赖注入),其含以上是互相包容的,在控制反转时便实现依赖注入 传统方法:当一个java实例(A)需要调用另一个java实例(B)时,需要在A中new一个B来构建 Spring管理中:B对象的创建交给了Spring来管理(控制反转) | 将B对象注入给A对象的过程称为(依赖注入) 4.Spring AOP1.概念 AOP（Aspect Oriented Programming），即面向切面编程，基于面向过程 是OOP（Object Oriented Programming，面向对象编程）的补充和完善。 (OOP无法关注到程序的切入点,AOP具有更强大的切面控制力) 例如: 面向对象的流程是用户注册信息,然后插入到数据库中 面向切面的流程是用户注册信息,在插入数据库前进行控 制,在插入数据库后进行控制 AOP使用横切技术,把软件系统分成两部分核心关注点,特点:纵向关系为主,建立对象层次结构横切关注点,特点:横向关系为主,分布在核心关注点的周围,能够切开封装对象,对内部重复的部分进行重新封装,降低耦合性,如权限认证、日志、事务,AOP可以分离系统中的关注点,达到更高效的开发和运行 2.五种横切方案 前置通知 后置正常通知 后置异常通知 后置始终通知 环绕通知 3.八大核心概念 Joinpoint 连接点 AOP执行程序的特定位置 PointCut 切点 AOP通过切点来确定特定的连接点位置 Advice 增强 织入目标类连接点上的一段代码,可以描述程序,也可以确定方位, 只有通过切点信息和方位信息,才能确定特定连接点并执行增强逻辑 Target 目标对象 增强逻辑的织入目标类 Introduction 引介 特殊增强,给指定类添加属性和方法,也可以动态的添加接口的实现业务逻辑 weaving 织入 增强 添加到 目标类 的 连接点 的过程,将目标,增强和引介很好的结合在了一起,AOP常用的三种织入技术 编译期织入,这要求使用特殊的Java编译器. ​ 类装载期织入,这要求使用特殊的类装载器. ​ 动态代理织入,在运行期为目标类添加增强生成子类的方式. Spring采用动态代理织入,而AspectJ采用编译期织入和类装载器织入. Proxy 代理 目标被增强织入后生成一个新的代理类,该代理类可能和原类是一个接口,也可能是原类的子类,可以采用和原类相同的方法调用 Aspect 切面 由增强和切点组成, [既包含横切逻辑的定义,也包括连接点的定义] ,能够把这两种定义织入到指定连接点中 4.AOP底层调用的两种代理机制 JDK动态代理:针对接口类产生代理 CGlib动态代理:针对没有实现接口的类产生代理,应用的是底层字节码增强技术,生成当前类的子类对象 5.Spring父子容器Spring父容器(ContextLoaderListener)一般配置的是Dao层和Service层，而Spring子容器(DispatcherServlet)一般配置的是Controller层父子容器的访问关系是: 子容器可以访问父容器中的对象，但是父容器无法访问子容器中的对象。比如controller可以把Dao和Service注入进来，但是Dao和Service无法把Controller注进来。 我们在service配置扫描包的时候配置的扫描范围是”com.taotao.service”，如果我们配置成com.taotao，那么就会把com.taotao.controller也扫描到父容器中，这样父子容器中就都有controller层了，但是在父容器中扫进来controller是没有用的，我们在表现层访问的时候，访问的还是子容器的controller。同理，如果把子容器的扫描范围扩大，变为com.taotao，那么它便会把Dao和Service也扫描到子容器当中，这样当我们访问表现层的时候，访问的便是子容器中的Dao和Service，子容器中的Dao和Service是没有事务的，但是父容器中的Dao和Service是有事务的，这样就会导致虽然我们在父容器中配置了事务，但由于子容器扫描范围太大，而导致访问子容器中的Dao和Service没有事务的问题。 6.Spring深入拓展1.利用后处理器扩展Spring容器…2.Spring的“零配置”支持(注解)**| Component | Controller | Service | Repository | Scope | Resource | Autowired | Qualifier | JsonIgnore |** 3.资源访问…深入拓展传送门:https://www.cnblogs.com/shijiaoyun/p/7458341.html]]></content>
      <categories>
        <category>Spring全家桶</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[javaSE-集合]]></title>
    <url>%2F2018%2F03%2F23%2FjavaSE-%E9%9B%86%E5%90%88%2F</url>
    <content type="text"><![CDATA[JavaSE-集合基础[TOC] 1.集合的并发问题 Java快速失败与安全失败迭代器 : java迭代器提供了遍历集合对象的功能，集合返回的迭代器有快速失败型的也有安全失败型的，快速失败迭代器在迭代时如果集合类被修改，立即抛出ConcurrentModificationException异常，而安全失败迭代器不会抛出异常，因为它是在集合类的克隆对象上操作的。 java快速失败迭代器 : 大多数集合类返回的快速失败迭代器在遍历时不允许结构性修改（结构性修改指添加，删除和更新一个元素）当遍历的同时被结构性修改，会改变modCount的值, 就会抛出ConcurrentModificationException异常，而当集合是被迭代器自带的方法（如remove()）修改时，不会抛出异常。 java安全失败迭代器 : 安全失败迭代器在迭代中被修改，不会抛出任何异常，因为它是在集合的克隆对象迭代的，所以任何对原集合对象的结构性修改都会被迭代器忽略，但是这类迭代器有一些缺点，其一是它不能保证你迭代时获取的是最新数据，因为迭代器创建之后对集合的任何修改都不会在该迭代器中更新，还有一个缺点就是创建克隆对象在时间和内存上都会增加一些负担。 集合对并发问题集成了一个并发包ConcurrentModificationException 2.java中的同步容器在java中,同步容器主要包括2类 Vector | Stack | HashTable Collections类中提供的静态工厂方法创建的类 Vector实现了List接口,Vector实际上是一个数组,和ArrayList类似,但是Vector中的方法都是synchronized线程同步,即进行了同步措施. Stack继承了Vector,也是一个同步容器,它的方法也是synchronized线程同步 HashTable实现Map接口,他和HashMap很相似,但是HashTable中使用synchronized线程同步,而HashMap是不安全的 Collections类是一个工具提供类，注意，它和Collection不同， Collection是一个顶层的接口。 在Collections类中提供了大量的方法，比如对集合或者容器进行排序、查找等操作。最重要的是，在它里面提供了几个静态工厂方法来创建同步容器类 3.单项链表的增删链表的增删原理需要注意,重点因为存储空间并非连续存在,不能在改变链表结构时使其断开,否则将难以再次找到到原来的标记 增加 a的next改为a1的next a1的next改为a 删除 a1的next改为a2的next a2的值赋给e 释放a2 4.ArrayList相关4-1.ArrayList线程安全问题ArrayList本身是线程不安全的,如果在多线程情况下使用可以考虑一下两种方案 Collections.synchronizedList(List list)方法返回一个线程安全的ArrayList类 concurrent并发包下的CopyOneWriteArrayList类 4-2.ArrayList实现的部分接口ArrayList实现了List接口,继承了AbstractList (维持集合结构的本身需求) ArrayList实现了Serialization接口,可以序列化传输 ArrayList实现了RandomAccess接口,支持快速随机访问(实际上通过下标实现快速随机访问) ArrayList实现了Cloneable接口,可以被克隆 4-3.扩容的选择集合中的结构都支持自动扩容 如ArrayList的扩容机制是1.5倍(1.6和1.7的区别(16/15)) ArrayList可以指定初始大小也可以默认(10个单位),使用时可以根据业务需求,通过构造设置初始容量, 这里考虑的因素是集合自动扩容对性能的一个损耗,如果提前知道集合内元素的大概数量,那么初始容量可以设置大一些,从而减少自动扩容的损耗 也可以通过ensureCapacity方法来指定扩容的长度(使用场景了解较少) 4-4.数组的底层实现数组的引用+下标*数组数据类型的大小—&gt;获得该元素的数据内容]]></content>
      <categories>
        <category>SE基础</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[JAVAEE-继承]]></title>
    <url>%2F2018%2F02%2F06%2FjavaSE-%E7%BB%A7%E6%89%BF%2F</url>
    <content type="text"><![CDATA[JAVAEE-继承1.通过继承扩展POJO子类扩展父类时,可以使用该方式 注入父类属性并进行扩展(注意父类需要有无参构造) 当多模块时,特殊的pojo有可能出现模块间循环依赖问题,那么根据业务情况可以使用如下方法,配在对应位置(非Common) 12345678910111213141516171819202122232425262728293031323334353637383940import com.e3mall.pojo.TbItem;/** * @author DonY15 * @description * @create 2018\7\28 0028 */public class Item extends TbItem &#123; /** * 通过构造注入父类属性值 * @param item */ public Item(TbItem item) &#123; this.setId( item.getId()); this.setTitle(item.getTitle()); this.setSellPoint(item.getSellPoint()); this.setPrice( item.getPrice()); this.setNum(item.getNum()) ; this.setBarcode(item.getBarcode()); this.setImage( item.getImage()); this.setCid( item.getCid()); this.setStatus(item.getStatus()) ; this.setCreated( item.getCreated()); this.setUpdated( item.getUpdated()) ; &#125; /** * 对TbItem扩展,将图片字符串转为字符串数组 * @return */ public String[] getImages() &#123; String image = this.getImage(); if (image!=null&amp;&amp;!"".equals(image))&#123; String[] split = image.split(","); return split; &#125; return null; &#125;&#125;]]></content>
      <categories>
        <category>SE基础</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Nginx基础原理]]></title>
    <url>%2F2018%2F02%2F04%2FNginx%E5%9F%BA%E7%A1%80%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[Nginx基础原理[TOC] 1.概念面向性能设计的Http服务器,内存占用少,稳定性高,也是轻量级的网页服务器/反向代理服务器/电子邮件代理服务器等 Nginx单独使用足以支撑5W的并发连接,可以作为负载均衡的入口,根据使用情况来分发给不同的tomcat 百度、京东、新浪、网易、腾讯、淘宝等都在使用Nginx 2.组成Nginx由内核和模块组成，其中，内核的设计非常微小和简洁，完成的工作也非常简单，仅仅通过查找配置文件将客户端请求映射到一个location block（location是Nginx配置中的一个指令，用于URL匹配），而在这个location中所配置的每个指令将会启动不同的模块去完成相应的工作。 Nginx的模块从结构上分为核心模块、基础模块和第三方模块： ​ 核心模块：HTTP模块、EVENT模块和MAIL模块 ​ 基础模块：HTTP Access模块、HTTP FastCGI模块、HTTP Proxy模块和HTTP Rewrite模块， ​ 第三方模块：HTTP Upstream Request Hash模块、Notice模块和HTTP Access Key模块。 用户根据自己的需要开发的模块都属于第三方模块。正是有了这么多模块的支撑，Nginx的功能才会如此强大。 Nginx原理和优化:https://www.cnblogs.com/linguoguo/p/5511293.html(很棒的文章) 3.作用 反向代理:位于原始服务器后面,客户端访问原始服务器后,原始服务器会去反向代理服务器获取需要的资源(服务器端) 正向代理:位于客户端和原始服务器之间,客户端请求该代理服务器,该代理服务器再去访问原始服务器,响应原路返回(客户端,局域网访问网络) 正向代理的典型用途是为在防火墙内的局域网客户端提供访问Internet的途径。 正向代理还可以使用缓冲特性减少网络使用率。 反向代理的典型用途是将防火墙后面的服务器提供给Internet用户访问。 反向代理还可以为后端的多台服务器提供负载平衡，或为后端较慢的服务器提供缓冲服务。 负载均衡:Nginx最常用的功能之一,将工作分摊多个操作单元上执行,需要反向代理跳转到负载均衡 HTTP服务器:Nginx本身就是静态资源服务器,Nginx可以很方便的实现动静分离 动静分离: nginx还可以对数据进行压缩，对一些图片、html、css、js等文件进行缓存、从而实现动静分离等等优化功能，在网站做优化的时候非常的有用。 所谓的动静分离，可以理解为我们完全可以将动态的请求都交给tomcat处理，静态的请求都交给nginx来处理，这是非常容易做到的事情。 Nginx基础功能和工作原理:https://blog.csdn.net/wy757510722/article/details/75267431(很棒的文章) (待更新) 4.Nginx配置详细清单 server 配置静态资源 端口或者域名区分 proxy_pass 配置反向代理 upstream 配置负载均衡及权重 端口版:http://www.cnblogs.com/dancesir/p/9253043.html 集群搭建:https://blog.csdn.net/u012453843/article/details/69664821 5.Nginx负载均衡策略对于单独的Nginx而言,通过Nginx服务器搭建Tomcat等服务器集群(可以设置权重)可以提高基础的并发 6.Keepalived结合Nginx实现高可用 Keepalived绑定Nginx主从服务器的健康状态,备份服务器通过心跳机制检测主服务器是否ok(心跳包) Keepalived可以绑定vip(Virtual IP Address)动态绑定虚拟IP,在谁身上就用谁(一般发到主服务器) 主服务器宕机的时候,备份服务器会和keepalived绑定(主服务器起来后重新获得vip) Keepalived结合高可用使用:https://blog.csdn.net/u012453843/article/details/69668663 7.负载均衡策略当并发超过Nginx上限的处理(应用层)7-1.F5硬负载(4层分发)(经费充足)如果并发超过5W,可以处理硬负载并发问题(从传输层开始处理,效果更好) 7-2.LVS(Linux Virtual Server)(4层分发)(经济实惠)实现硬负载60%的性能 7-3.使用阿里云服务器均衡负载SLB8.Keepalived结合LVS实现高可用(类似Keepalived和Nginx的高可用)]]></content>
      <categories>
        <category>框架</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[FastDFS 基础原理]]></title>
    <url>%2F2017%2F12%2F06%2FFastDfs%E5%9F%BA%E7%A1%80%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[FastDFS 基础原理[TOC] 1.深度优先搜索Depth First Search 分布式文件系统 无向图算法概念(一种递归原理) 先按照一条边进行搜索,当遇到第一个节点时,对它相邻的其他节点进行搜索并标记为已查找的节点(会查找完第一条节点的最深层后返回)详细见算法目录(持续更新) 2.FastDFS–结构FastDFS服务有三个角色:跟踪服务器(tracker server)、存储服务器(storage server)和客户端(client) 主要解决了海量数据存储问题 ,特别适合以中小文件（建议范围：4KB &lt; file_size &lt;500MB）为载体的在线服务。 2-1.跟踪器Tracker :主要做调度工作，相当于mvc中的controller的角色，在访问上起负载均衡的作用。跟踪器和存储节点都可以由一台或多台服务器构成，跟踪器和存储节点中的服务器均可以随时增加或下线而不会影响线上服务，其中跟踪器中的所有服务器都是对等的，可以根据服务器的压力情况随时增加或减少。 跟踪器Tracker负责管理所有的Storage和group，本身不需要持久化任何数据,直接增加机器就可以拓展tracker,每个Storage在启动后会连接Tracker，并周期性保持联系. 2-2.存储服务器Storage:以group为最小单位,方便实现 应用隔离、负载均衡、副本数定制（group内storage server数量即为该group的副本数）,建议同一group内的配置尽量相同,减少资源浪费(storage依赖于本地文件系统) 每个group内的Storage线程同步,地位平等 2-3.客户端Client:基本文件访问接口:比如upload、download、append、delete等，以客户端库的方式提供给用户使用。 3.FastDFS–运行 tracker 当集群中不止一个tracker server时，由于tracker之间是完全对等的关系，客户端在upload文件时可以任意选择一个trakcer。 group 当tracker接收到upload file的请求时，会为该文件分配一个可以存储该文件的group，支持如下选择group的规则： Round robin，所有的group间轮询 Specified group，指定某一个确定的group Load balance，剩余存储空间多多group优先 storage 当选定group后，tracker会在group内选择一个storage server给客户端，支持如下选择storage的规则： Round robin，在group内的所有storage间轮询 First server ordered by ip，按ip排序 First server ordered by priority，按优先级排序（优先级在storage上配置） storage path 当分配好storage server后，客户端将向storage发送写文件请求，storage将会为文件分配一个数据存储目录，支持如下规则： Round robin，多个存储目录间轮询 剩余存储空间最多的优先 Fileid 选定存储目录之后，storage会为文件生一个Fileid，由storage server ip、文件创建时间、文件大小、文件crc32和一个随机数拼接而成，然后将这个二进制串进行base64编码，转换为可打印的字符串。 选择两级目录 当选定存储目录之后，storage会为文件分配一个fileid，每个存储目录下有两级256*256的子目录，storage会按文件fileid进行两次hash（猜测），路由到其中一个子目录，然后将文件以fileid为文件名存储到该子目录下。 生成文件名 当文件存储到某个子目录后，即认为该文件存储成功，接下来会为该文件生成一个文件名，文件名由group、存储目录、两级子目录、fileid、文件后缀名（由客户端指定，主要用于区分文件类型）拼接而成。 文件同步 写文件时，客户端将文件写至group内一个storage server即认为写文件成功，storage server写完文件后，会由后台线程将文件同步至 [同group] 内其他的storage server。storage的同步进度会作为元数据的一部分汇报到tracker上，tracke在选择读storage的时候会以同步进度作为参考。 Download file 客户端upload file成功后，会拿到一个storage生成的文件名，接下来客户端根据这个文件名即可访问到该文件。 4.FastDFS–特点轻量级分布式文件系统,功能包括文件存储、文件同步、文件访问（文件上传、文件下载） 优势: 解决大容量存储和负载均衡,可以水平扩容(增加分组增加设备,没有上线) 高可用,FastDFS集群能够做到当提供服务的Nginx挂掉后,自动切换另一台Nginx设备 4-1.小文件合并存储解决问题: 本地文件系统inode数量有限，从而存储的小文件数量也就受到限制。 多级目录+目录里很多文件，导致访问文件的开销很大（可能导致很多次IO） 按小文件存储，备份与恢复的效率低 FastDFS在V3.0版本里引入小文件合并存储的机制，可将多个小文件存储到一个大的文件（trunk file），为了支持这个机制，FastDFS生成的文件fileid需要额外增加16个字节 4-2.HTTP访问支持客户端可以通过http协议来下载文件，tracker在接收到请求时，通过http的redirect机制将请求[重定向]至文件所在的storage上；除了内置的http协议外，FastDFS还提供了通过apache或nginx扩展模块下载文件的支持。 4-3.负载均衡group机制本身可用来做负载均衡，但这只是一种静态的负载均衡机制，需要预先知道应用的访问特性；同时group机制也导致不可能在group之间迁移数据来做动态负载均衡。 5.FastDFS基础使用步骤导入pom(注意该jar需要自己github项目用maven生成happy100) 123456&lt;!-- fastdfs --&gt;&lt;dependency&gt; &lt;groupId&gt;org.csource&lt;/groupId&gt; &lt;artifactId&gt;fastdfs-client-java&lt;/artifactId&gt; &lt;version&gt;1.27-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; 123创建配置文件 client.conftracker_server=服务器的ip或域名:22122 7步使用入门 12345678910111213141516171819202122//1.加载配置文件(必须全路径) ClientGlobal.init(全路径+ &quot;client.conf&quot;); //2、创建一个TrackerClient对象。 TrackerClient trackerClient = new TrackerClient(); //3.通过trackerClient对象Connection连接到TrackerServer TrackerServer trackerServer = trackerClient.getConnection(); //4.创建空的StorageServer StorageServer storageServer = null; //5.通过TrackerServer和StorageServer 创建StorageClient StorageClient storageClient = new StorageClient(trackerServer, storageServer); //6.使用storageClient的upload_file方法上传到FastDFS服务器,返回String[]数组 //参数:第一个name是文件全路径,第二个ext是扩展名(去掉.),第三个是源数据List&lt;&gt;可不写 String[] strings = storageClient.upload_file(&quot;f:/qf_logo.jpg&quot;, &quot;jpg&quot;, null); //7.解析使用返回的String[] ,该结果集 拼接后 是访问上传文件的url System.out.println(Arrays.toString(strings)); http://www.dony15.com/group1/M00/00/00/Cgs2JVtEPTmAc1B6AAIryNEeIAM372.jpg 以上为原生过程,在真正使用时,可以将其封装成工具类使用,简便高效 6.FastDFS–使用小结 分别配置Tracker地址(上传存储使用)和Storage地址(响应回显使用) 接收前段file文件后,将名字拆分重塑后存储 响应url则拼接Storage地址生成 每次上传文件后都会返回一个地址，用户需要自己保存此地址。 前段设计:将整个编辑内容存进一个由事件控制的表单,当图片上传的时候不会影响到表单的完整性,而且可以依靠上传时间来动态生成回显方案,将url放进input中,清除不必要的组件(可能影响表单提交完整性的部分) 为了支持大容量，存储节点（服务器）采用了分卷（或分组）的组织方式。存储系统由一个或多个卷组成，卷与卷之间的文件是相互独立的，所有卷的文件容量累加就是整个存储系统中的文件容量。一个卷可以由一台或多台存储服务器组成，一个卷下的存储服务器中的文件都是相同的，卷中的多台存储服务器起到了冗余备份和负载均衡的作用。 注意:spring-mvc中除了要配置上传解析器之外,还需要将String的字符串指定为UTF-8(默认8859-1) 7.FastDFS原理系列文章(转发)https://blog.csdn.net/hfty290/article/details/42076205]]></content>
      <categories>
        <category>框架</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[FreeMarker结合Nginx|FTP基础使用]]></title>
    <url>%2F2017%2F12%2F02%2FFreeMarker%E5%92%8CNginx_FTP%E5%8E%9F%E7%90%86%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[FreeMarker结合Nginx|FTP基础使用[TOC] 目前做页面模板引擎主流使用Thymeleaf(效率更高),本文主要介绍FreeMarker的相关知识 传送门:Thymeleaf基础原理https://blog.csdn.net/abap_brave/article/details/53009149 传送门:Thymeleaf快速使用https://blog.csdn.net/u014042066/article/details/75614906 1.FreeMarker1.介绍 FreeMarker是一个模板引擎,一个基于模板生成文件的通用工具,由纯java代码编写 FreeMarker不是一个Web框架,而是适合Web框架的一个组件 FreeMarker与容器无关,更加通用,而且免费 数值类型:| String | 数值(不区分浮点) | boolean | 日期 | 集合 |等大部分类型 2.使用 引入jar包 建立模板 进行输出 2.FTP结合1.介绍FTP连接分主动模式和被动模式 主动模式(port)使用N(发送数据) 和N+1(发送FTP命令)两个端口,一般20 21 固定端口,可能造成数据被拦截窃取 被动模式(pasv)使用21 和P&gt;1024所有端口 不固定大范围端口,可能造服务器服务器被攻击 解决方案分析:https://blog.csdn.net/u014774781/article/details/48376633 FTP传送门(待更新) 2.使用FreeMarker生成静态页面后,可以通过FTP发送到服务器指定的位置存放 3.Nginx结合1.介绍Nginx是一个Http服务器,可以将服务器上的静态文件通过Http协议展现给客户端 2.使用Nginx将FreeMarker发送来的静态页面以url的方式发送到客户端完成一套静态部署 修改服务器中Nginx的配置,将静态页面的位置改为一个逻辑路径,通过这个逻辑路径即可完成对静态资源的访问 (注意,需要提前将样式copy进去) Nginx传送门(待更新) 4. 开发使用将FreeMarker整合进SSM中广告位详情为例: Common层中建立广告位实例 dao层和业务逻辑层实现对广告位的增删改查,并且增加导出静态页功能 导出静态页功能整合了FreeMarker/FTP连接的功能 将指定的数据拉到FreeMarker中生成模板,然后写出到磁盘中, 再通过FTP工具,将本生成的模板上传到服务器中指定的位置存储 注意需要在服务器对应的位置提前将CSS/JS等静态资源导入 配置Nginx的nginx.conf文件,改变指定用户,指定端口和静态资源的逻辑路径 完成后通过访问地址栏服务器地址+逻辑路径+网页名 即可访问静态资源(主页默认80端口不需要写,其他端口需要在服务器地址栏后面:端口号)]]></content>
      <categories>
        <category>组件</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[javaSE-数据类型]]></title>
    <url>%2F2017%2F12%2F02%2FjavaSE-%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[javaSE-数据类型1.基本数据类型分类1-1基本数据类型(又叫原生类或内置类型) 整数：byte，short，int，long（默认是int类型） 浮点类型： float，double（默认是double类型） 字符类型：char 布尔类型：boolean 1-2引用数据类型数组，类，接口 ,枚举类型,注解类型； 基本数据类型之间除了boolean，其他数据类型之间可以任意的相互转换（强制转化或默认转换） 1-3默认值问题基本类型的值就是一个数字，一个字符，或者一个布尔值。存放在栈空间中，未初始化时为随机值(正常无法使用,编译期异常)。 引用类型是一个对象类型，值是指向内存空间的引用，就是地址。所指向的内存空间有默认值. 1-4基本数据类型优点在栈内存中,速度很快,每次开辟的空间,都可以实现栈内数据共享 1-5JVM对基本数据类型和引用数据类型的分配JVM虚拟机对基本数据类型和引用数据类型的分配策略是不同的 基本数据类型:分配数据类型实际大小的内存 引用数据类型:分配一个指向堆内存的引用 1-6被final修饰(编译期对常量识别)当数据被final修饰时,即转换为常量,此时对该数据类型做运算只会考虑数据的范围,只要不超过范围即可运行 2.基本数据类型包装类2-1.包装类Byte,Integer,Short,Long,Float,Double,Boolean,Character 2-2区别存放位置/内存消耗/值址类型 2-3.场景集合/持久层接收数据库(如查找数值)/指定字符串类型等 2-4.自动拆装箱java5.0以后,添加自动拆装箱功能,就可以不必显示的进行类型转换，系统会自动的按照需要进行数据类型的转换。 手动Integer拆装箱方法 1234Integer valueOf(String s/int i) 两种装箱 int parseInt(String s) 拆箱----int intValue() 拆箱(直接. 不需要参数的拆箱方法) 2-5.包装类型和泛型集合的关系在java中，所有的泛型集合存放的值或者变量统一转换为Object类型。 因为Object是所有类的祖类,因此这个转化过程都不需要强转 此时无论是写int类型还是Integer类型,存入集合都会转为Object 123456789public static void main(String[] args) &#123; int a=1123; Integer b=22222; List list=new ArrayList&lt;&gt;(); list.add(a); list.add(b); System.out.println(Integer.parseInt(list.get(0).toString())==1123); //true &#125; 注意 集合中存储的元素都是引用类型的引用,int是在栈中的基本数据类型,是无法直接存入集合中的,此时需要装箱 上文提过,java5.0之后,添加了自动拆装箱的功能,所以在使用时一般不会出现问题,但底层确实调用了装箱过程 3.数据类型的设计模式3-1享元设计模式如果整型字面量的值在-128到127之间，那么不会new新的Integer对象，而是直接引用常量池中的Integer对象java中基本类型的包装类的大部分都实现了常量池技术 这些类是Byte,Short,Integer,Long,Character,Boolean,另外两种浮点数类型的包装类则没有实现。 另外Byte,Short,Integer,Long,Character这5种整型的包装类也只是在对应值小于等于127时才可使用常量池，也即对象不负责创建和管理大于127的这些类的对象。 3-2字符串常量池]]></content>
      <categories>
        <category>SE基础</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[java POI辅助框架基础]]></title>
    <url>%2F2017%2F09%2F18%2Fjava%20POI%E8%BE%85%E5%8A%A9%E6%A1%86%E6%9E%B6%2F</url>
    <content type="text"><![CDATA[java POI辅助框架基础1.概念 Apache POI 是用Java编写的免费开源的跨平台的 Java API，Apache POI提供API给Java程式对Microsoft Office格式档案读和写的功能。 pache POI 是创建和维护操作各种符合Office Open XML（OOXML）标准和微软的OLE 2复合文档格式（OLE2）的Java API。用它可以使用Java读取和创建,修改MS Excel文件.而且,还可以使用Java读取和创建MS Word和MSPowerPoint文件。Apache POI 提供Java操作Excel解决方案（适用于Excel97-2008）。 2.POI框架的类库： HSSF － 提供读写Microsoft Excel格式档案的功能。 XSSF － 提供读写Microsoft Excel OOXML格式档案的功能。 常用 HWPF － 提供读写Microsoft Word格式档案的功能。 HSLF － 提供读写Microsoft PowerPoint格式档案的功能。 HDGF － 提供读写Microsoft Visio格式档案的功能。 3.明确组成一个EXCEL文件需要多少对象：（1）一个excel表格123Workbook wb = new HSSFWorkbook(); //xlsWorkbook xb = new XSSFWorkbook(); //xlsx实现同一接口 （2）一个工作表格（sheet）：1Sheet sheet = wb.getSheetAt(0);1 （3）一行（row）：1HSSFRow row1 = sheet.createRow(0);1 （4）一个单元格（cell）：1Cell cell = cells.next()1 （5）单元格格式（cellstyle）：12HSSFCellStyle style4 = wb.createCellStyle()12 （6）单元格内容格式（HSSFDataFormat ）：1HSSFDataFormat format= wb.createDataFormat(); https://blog.csdn.net/Jack__Frost/article/details/77498797]]></content>
      <categories>
        <category>框架</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Struts2基础]]></title>
    <url>%2F2017%2F09%2F15%2FStruts2%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[Struts2基础[TOC] 1.简介1-1.概念轻量级的MVC框架，主要解决了请求分发的问题，重心在控制层和表现层。低侵入性，与业务代码的耦合度很低。Struts2实现了MVC，并提供了一系列API，采用模式化方式简化业务开发过程。 1-2.对比Servlet 优点：业务代码解耦，提高开发效率 缺点：执行效率偏低，需要使用反射、解析XML等技术手段，结构复杂 1-3.不同MVC框架实现Servlet Spring ​ 此处Servlet应该为DispatcherServlet Spring前端控制器 Struts2 2.Struts2使用2-1.导入jar1234567&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.struts&lt;/groupId&gt; &lt;artifactId&gt;struts2-core&lt;/artifactId&gt; &lt;version&gt;2.5.13&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 2-2.web.xml中配置前端控制器Filter123456789&lt;!--Struts2核心过滤器--&gt;&lt;filter&gt; &lt;filter-name&gt;Struts2&lt;/filter-name&gt; &lt;filter-class&gt;org.apache.struts2.dispatcher.filter.StrutsPrepareAndExecuteFilter&lt;/filter-class&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;Struts2&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt; 2-3.创建struts.xml（格式可以参考核心包根路径下的DTD文件，struts-default.xml）123456789101112131415161718192021222324&lt;struts&gt; &lt;!-- package：包，用于对Action进行封装 name：包名，根元素下可以有多个包，彼此不能重名 extends：继承，用于指定继承的包，相当于将继承包下的配置信息复制到当前包 namespace：命名空间，用于规定Action的访问路径，必须“/”开头 --&gt; &lt;package name=&quot;test01&quot; namespace=&quot;/test01&quot; extends=&quot;struts-default&quot;&gt; &lt;!--action：业务控制器，用于注册业务控制器组件 name：action名称，用于规定Action的访问路径 class：业务控制器组件，用于指定业务控制器对应的类 method：方法，用于指定访问当前action时要调用的方法 *请求URL：http://ip:port/projectName/namespace/ActionName.action --&gt; &lt;action name=&quot;hello&quot; class=&quot;test01.konrad.action.HelloAction&quot; method=&quot;execute&quot;&gt; &lt;!--result：输出组件，用于转发、重定向、直接输出 name：名称，一个action下可以有多个result，彼此不能重名 默认值转发，元素内设置转发的页面 --&gt; &lt;result name=&quot;success&quot;&gt; /hello.jsp &lt;/result&gt; &lt;/action&gt; &lt;/package&gt;&lt;/struts&gt; 2-4.编写Action前端控制器 定义需要的属性,并完善getter and setter 方法public修饰 返回值类型String(返回值与struts.xml-&gt;action-&gt;result的name属性匹配，即根据此返回值找到对应result) 参数列表为空 123456789101112131415161718192021package action;import com.opensymphony.xwork2.Action;public class HelloWorldAction implements Action &#123; //请求中传递的参数和返回给页面的值都定义成属性 //必须要给属性写getter/setter方法 private String username; private String message; //getter/setter略，自己一定要写 @Override public String execute() throws Exception &#123; //查看请求中传递的参数 System.out.println(username); //改变这个message,会自动传递给页面 message = &quot;hello:&quot; + username; //SUCCESS是Action中的常量,值是success return SUCCESS; &#125;&#125; 2-5.创建JSP页面12 3.参数传递3-1.基本属性注入Action（页面，Action） 3-2.域模型/对象注入Action（页面，Action） 3-3.页面取Action数据1.EL表达式1&lt;h1&gt;$&#123;user.name&#125;&lt;/h1&gt; 2.OGNL4.OGNL4-1.概念Object Graph Navigation Language，是一门功能强大的表达式语言，类似于EL(JSTL表达式语言)。Strut2默认采用OGNL表达式访问Action的数据，实际上是通过ValueStack对象来访问Action。 4-2.用法在Struts2中，OGNL表达式要结合Struts2标签来访问数据 EL：${user.userName} &lt;==&gt; OGNL：&lt;s:property value=”user.userName”&gt; 访问基本属性 &lt;s:property value=”属性名”/&gt; 访问实体对象 &lt;s:property value=”对象名.属性名”/&gt; 访问数组/集合 &lt;s:property value=”someArray[1]”/&gt; | &lt;s:property value=”someList[1]”/&gt; 访问Map &lt;s:property value=”someMap.key” /&gt; 运算 &lt;s:property value=”‘My name is’ + name” /&gt; 调用方法 &lt;s:property value=”name.toUpperCase()” /&gt; 创建集合 &lt;s:property value=”{‘a’,’b’,’c’}” /&gt; ArrayList 创建Map &lt;s:property value=”#{‘mm’:’MM’,’nn’:’NN’}” /&gt; LinkedHashMap 5.ValueStack5-1.概念是Struts2中，Action向页面传递数据的媒介，封装了Action的数据，并允许JSP通过OGNL来对其访问 5-2.原理 5-3.访问ValueStack 1.通过&lt;s:debug&gt;观察其结构 2.输出栈顶：&lt;s:property /&gt; 3.访问Context对象： - OGNL表达式以”#”开头 - 以key来访问context对象的值，即”#key”得到context中某属性值 4.迭代集合 5.按数字迭代 5-4.ValueStack栈顶的变化 - 默认情况下栈顶为Action - 循环过程中，栈顶为循环变量（集合迭代时，循环变量是集合中的对象，即栈顶为实体对象，可以以实体对象为root来写OGNL表达式；数字迭代时，循环变量是数字，不能以数字为实体对象，需要通过var声明变量名，以”#变量名”来引用，此情况下，是从context对象中取出值） - 循环结束后，栈顶变回Action 5-5.EL表达式访问ValueStack a）EL也是从ValueStack中取的值 b）EL默认的取值范围是page，request，session，application c）Struts2重写的request的getAttribute方法，先试图从原始request中取值，如果没取到再从ValueStack中取值 6.Action基本原理6-1.大核心组件 FC：前端控制器，负责统一的分发请求 Action：业务控制器，负责处理某一类业务 ValueStack：Action与JSP数据交互的媒介 Interceptor：拦截器，负责扩展Action，处理Action的共通事务 Result：负责输出的组件 Tags：标签，负责显示数据、生成框体 6-2.获取Session的方式 a）ActionContext - ActionContext.getContext().getSesion()，返回Map&lt;String, Object&gt; b）ServletActionContext - ServletActionContext.getRequest().getSession()，返回HttpSession c）SessionAware（推荐使用） - 让Action实现SessionAware接口 - 实现setSession(Map&lt;String, Object&gt; session)方法，Struts2会在实例化Action后调用方法，通过方法参数将Session对象注入进来 - 定义成员变量，接收注入进来的Session对象 7.Result原理7-1.介绍用于做输出的组件，用于向页面输出一些内容，转发、重定向可以理解为特殊方式的输出。每一个Result实际上是一个类，这些类都实现了共同的接口Result。Struts2预置了10种类型的Result，定义在strtus-default.xml 7-2.Result类型a）dispatcher：用于转发的result，可以将请求转发给JSP，这种类型的Result对应的类为ServletDispacherResult，通过default=”true”指定该Result为Struts2默认的Result类型。 b）stream：用于向页面输出二进制数据，此种类型的Result可以将二进制数据输出到请求发起端，对应类为StreamResult 1234&lt;result name=&quot;success&quot; type=&quot;stream&quot;&gt; &lt;!--codeStream 为定义在Action的输入流InputStream --&gt; &lt;param name=&quot;inputName&quot;&gt;codeStream&lt;/param&gt;&lt;/result&gt; c）redirectAction：用于将请求重定向给另外一个Action，对应类为ServletActionRedirectResult 123456789&lt;result name=&quot;login&quot; type=&quot;redirectAction&quot;&gt; &lt;!--若重定向的Action与当前Action在同一个namespace下，可以省略namespace--&gt; &lt;param name=&quot;namespace&quot;&gt; /命名空间 &lt;/param&gt; &lt;param name=&quot;actionName&quot;&gt; action名 &lt;/param&gt;&lt;/result&gt; d）json：用于向页面输出json格式的数据，可以将json字符串输出到请求发起端。对应类为JSONResult 1234567891011&lt;result name=&quot;success&quot; type=&quot;json&quot;&gt; &lt;!--输出一个Action属性 指定属性为基本类型，则直接返回该属性值 如果指定属性为实体对象，则返回格式&#123;&quot;code&quot;:&quot;as1&quot;,&quot;name&quot;:&quot;hk&quot;&#125; --&gt; &lt;param name=&quot;root&quot;&gt;属性名&lt;/param&gt; &lt;!--输出多个Action属性--&gt; &lt;param name=&quot;includeProperties&quot;&gt;属性名1,属性名2...&lt;/param&gt; &lt;!--输出所有属性，不需要param标签--&gt; &lt;/result&gt; json需要导包，修改package继承关系为json-default 8.UI标签12345678910111213141516171.表单 &lt;s:form action=&quot;&quot; method=&quot;&quot; theme=&quot;simple&quot; &gt;&lt;/s:form&gt; 2.文本框 &lt;s:textfield name=&quot;userName&quot; /&gt; 3.布尔框 &lt;s:checkbox name=&quot;marry&quot; /&gt; 4.单选框 &lt;s:radio name=&quot;sex&quot; list=&quot;#&#123;&apos;M&apos;:&apos;男&apos;,&apos;F&apos;:&apos;女&apos;&#125;&quot;/&gt; 静态初始化 &lt;s:radio name=&quot;favoriteCities&quot; list=&quot;cities&quot; listKey=&quot;cityCode&quot; listValue=&quot;cityName&quot; /&gt; 动态初始化 5.多选框 &lt;s:checkboxlist name=&quot;travelCities&quot; list=&quot;#&#123;&apos;01&apos;:&apos;北京&apos;,&apos;02&apos;:&apos;上海&apos;,&apos;03&apos;:&apos;广州&apos;&#125;&quot; /&gt; 静态初始化 &lt;s:checkboxlist name=&quot;travelCities&quot; list=&quot;cities&quot; listKey=&quot;cityCode&quot; listValue=&quot;cityName&quot; /&gt; 动态初始化 6.下拉选 &lt;s:select name=&quot;home&quot; list=&quot;#&#123;&apos;01&apos;:&apos;北京&apos;,&apos;02&apos;:&apos;上海&apos;,&apos;03&apos;:&apos;广州&apos;&#125;&quot; /&gt; 静态初始化 &lt;s:select name=&quot;home&quot; list=&quot;cities&quot; listKey=&quot;cityCode&quot; listValue=&quot;cityName&quot; /&gt; 动态初始化 9.拦截器9-1.用途拦截器适合封装一些通用处理，便于重复利用。例如请求参数传递给Action属性，日志的记录，权限检查，事务处理等。拦截器是通过配置方式调用，因此使用方法比较灵活，便于维护和扩展。 9-2.使用步骤1.创建拦截器组件（创建一个类，实现Interceptor接口，并实现intercept方法;也可以继承MethodFilterInterceptor，这种方式可以使action中某个方法不进行拦截） 12345public String intercept(ActionInvocation invocation)&#123; //拦截器--前部分处理 invocation.invoke(); //拦截器--后续处理 &#125; 2.注册拦截器123456&lt;package&gt; &lt;interceptors&gt; &lt;interceptor name=&quot;别名&quot; class=&quot;实现类&quot;/&gt; &lt;!--其他拦截器--&gt; &lt;/interceptors&gt;&lt;/package&gt; 3.引用拦截器（哪个Action希望被拦截器扩展，需要在此action配置下，引用拦截器） 1234567&lt;action&gt; &lt;!--手动的使用一次系统默认的拦截器--&gt; &lt;interceptor-ref name=&quot;defaultStack&quot;/&gt; &lt;interceptor-ref name=&quot;拦截器别名&quot;/&gt; &lt;!--可以写多个--&gt; &lt;!--可以使用excludeMethods参数属性，设置不过滤的方法--&gt;&lt;/action&gt; 4.拦截器栈1234&lt;interceptor-stack name=&quot;myStack&quot;&gt; &lt;interceptor-ref name=&quot;拦截器别名1&quot;/&gt; &lt;interceptor-ref name=&quot;拦截器别名2&quot;/&gt;&lt;/interceptor-stack&gt; 5.FileUpload拦截器a）原理：首先FileUpload拦截器将表单中提交的文件，以临时文件的形式保存到服务器临时路径下。之后FileUpload拦截器将该临时文件对象注入给Action，Action自主处理该临时文件。最后FileUpload拦截器删除临时文件。 12345678910b）使用步骤导包 commons-io.jarAction：定义File类型属性(如some)，接受拦截器注入的临时文件对象。若想要获取原始文件名，要定义String类型属性，属性名为File类型属性+FileName(如someFileName)表单设置：method=&quot;post&quot;， enctype=&quot;multipart/form-data&quot; c）设置限制（Struts2文件上传默认最大值为2097152B,即2M）在struts.xml中重置默认限制值 &lt;constant name=&quot;struts.multipart.maxSize&quot; value=&quot;5000000&quot; /&gt; 10.数据校验Action类继承ActionSupport，ActionSupport中有一个validate方法进行数据校验 11. 国际化12.返回JSON12-1.导入jar包12345&lt;dependency&gt; &lt;groupId&gt;org.apache.struts&lt;/groupId&gt; &lt;artifactId&gt;struts2-json-plugin&lt;/artifactId&gt; &lt;version&gt;2.5.13&lt;/version&gt;&lt;/dependency&gt; 12-2.Action类12345678910public class JsonAction extends ActionSupport &#123; private Map&lt;String, Object&gt; resultMap; //getter/setter略 public String getJson() &#123; resultMap=new HashMap&lt;&gt;(); resultMap.put(&quot;key1&quot;,123); resultMap.put(&quot;key2&quot;,&quot;abc&quot;); return SUCCESS; &#125;&#125; 12-3.xml中继承123456&lt;package name=&quot;default&quot; namespace=&quot;/&quot; extends=&quot;struts-default,json-default&quot;&gt; &lt;action name=&quot;json&quot; class=&quot;action.JsonAction&quot; method=&quot;getJson&quot;&gt; &lt;result type=&quot;json&quot;&gt; &lt;param name=&quot;root&quot;&gt;resultMap&lt;/param&gt; &lt;/result&gt; &lt;/action&gt; …查询文档吧(눈‸눈)写不动了,下次更新 古老的传送门SSH传送门:http://www.cnblogs.com/konrad/p/6901273.html hibernate知识点梳理:http://www.cnblogs.com/konrad/p/6391962.html]]></content>
      <categories>
        <category>框架</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[服务器搭建(持续更新)]]></title>
    <url>%2F2017%2F07%2F14%2F%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[服务器搭建集合[TOC] 1.ShadowsocksR多用户一件脚本系统要求:CentOS 6+ / Debian 6+ / Ubuntu 14.04 + 脚本特点： 所有步骤都可以通过 Shell 脚本中文交互 操作。 支持 限制 用户速度 支持 限制 用户设备数 支持 限制 用户总流量 支持 定时 流量清零 支持 显示 当前连接IP 支持 显示 SS/SSR连接+二维码 支持 一键安装 BBR 支持 一键安装 锐速 支持 一键安装 LotServer 支持 一键封禁 垃圾邮件(SMAP)/BT/PT 一键安装指令: 1wget -N --no-check-certificate https://makeai.cn/bash/ssrmu.sh &amp;&amp; chmod +x ssrmu.sh &amp;&amp; bash ssrmu.sh 文件位置 安装目录：/usr/local/shadowsocksr 配置文件：/usr/local/shadowsocksr/user-config.json 数据文件：/usr/local/shadowsocksr/mudb.json 启动 ShadowsocksR：service ssrmu start 停止 ShadowsocksR：service ssrmu stop 重启 ShadowsocksR：service ssrmu restart 查看 ShadowsocksR状态：service ssrmu status Linux中提示-bash: wget: command not found的解决方法 CentOS:yum install wget -y Debian/Ubuntu:apt-get install -y wget 详细传送门:https://www.bbaaz.com/thread-7-1-1.html]]></content>
      <categories>
        <category>服务器</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Ajax基础服务]]></title>
    <url>%2F2017%2F07%2F10%2FAjax%E5%9F%BA%E7%A1%80%E6%9C%8D%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[Ajax… (暂时不想更…ಠ╭╮ಠ) 1.Ajax概念2.Ajax组成/作用3.Ajax在JS/JQ中的使用4.Ajax跨域服务ajax默认关闭跨域服务功能,有两种方案可以开启,一种是jsonp和callback前后端都修改 方案一(处理前后端)前端 1234567.ajax(&#123; type:&quot;get&quot;, //请求方式 async:true, //是否异步 url:&quot;http://www.domain.net/url&quot;, dataType:&quot;jsonp&quot;, //跨域json请求一定是jsonp,js默认发送callback(自动生成,也可指定的字符串) data:&#123;&quot;query&quot;:&quot;civilnews&quot;&#125;, ... 后端 123456789@RequestMapping(&quot;info.html&quot;)@ResponseBodypublic String check(String callback, HttpServletRequest request) &#123; //从cookie中获取票据 String token = CookieUtils.getCookieValue(request, TOKEN_KEY); //查询用户信息 TravelResult result = userService.getUserByToken(token); return callback + &quot;(&quot; + JsonUtil.getJSON(result) + &quot;)&quot;; //返回callback拼接Json&#125; 方案二(后端拦截器处理)粗粒度拦截 12345678910111213141516171819202122232425262728package com.jgonet.filter; import java.io.IOException; import javax.servlet.Filter; import javax.servlet.FilterChain; import javax.servlet.FilterConfig; import javax.servlet.ServletException; import javax.servlet.ServletRequest; import javax.servlet.ServletResponse; import javax.servlet.http.HttpServletResponse; public class HeaderFilter implements Filter &#123; public void doFilter(ServletRequest request, ServletResponse resp, FilterChain chain) throws IOException, ServletException &#123; HttpServletResponse response = (HttpServletResponse) resp; response.setHeader(&quot;Access-Control-Allow-Origin&quot;, &quot;*&quot;); //解决跨域访问报错 response.setHeader(&quot;Access-Control-Allow-Methods&quot;, &quot;POST, PUT, GET, OPTIONS, DELETE&quot;); response.setHeader(&quot;Access-Control-Max-Age&quot;, &quot;3600&quot;); //设置过期时间 response.setHeader(&quot;Access-Control-Allow-Headers&quot;, &quot;Origin, X-Requested-With, Content-Type, Accept, client_id, uuid, Authorization&quot;); response.setHeader(&quot;Cache-Control&quot;, &quot;no-cache, no-store, must-revalidate&quot;); // 支持HTTP 1.1. response.setHeader(&quot;Pragma&quot;, &quot;no-cache&quot;); // 支持HTTP 1.0. response.setHeader(&quot;Expires&quot;, &quot;0&quot;); chain.doFilter(request, resp); &#125; public void init(FilterConfig filterConfig) &#123;&#125; public void destroy() &#123;&#125; web.xml 12345678&lt;filter&gt; &lt;filter-name&gt;HeaderFilter&lt;/filter-name&gt; &lt;filter-class&gt;com.jgonet.filter.HeaderFilter&lt;/filter-class&gt;&lt;!--你过滤器的包 --&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;HeaderFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;!-- 你开放的接口前缀 --&gt; &lt;/filter-mapping&gt; 方案三(后端方法处理)精确细粒度拦截时使用,普通拦截使用拦截即可 123需要的方法设置响应头即可response.setHeader(&quot;Access-Control-Allow-Origin&quot;, &quot;*&quot;);response.setHeader(&quot;Access-Control-Allow-Methods&quot;, &quot;POST, PUT, GET, OPTIONS, DELETE&quot;); 5.Ajax结合单点登录流程SSO（single sign-on） 登录查询账号密码,返回Token Token返回时存进Redis中一份(以JSESSION+xxx+token为Key, JsonUtil.getJSON(user)为value) 将Token放进Cookie中,用户请求服务器时,服务器会将Cookie中的信息取出作为Key和Redis中的Key对比,来判断是否登录,从而返回前端状态即可 6.Ajax常见问题]]></content>
      <categories>
        <category>Web基础</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Log日志整理]]></title>
    <url>%2F2017%2F07%2F06%2FLog%E6%97%A5%E5%BF%97%E6%95%B4%E7%90%86%2F</url>
    <content type="text"><![CDATA[Log日志整理1.全局异常处理器将dao/service等异常抛出,统一在controller中捕获 1234//1.打印控制台//2.写日志//3.发邮件/短信//4.展示友好的错误页面(甩锅) POM 12345678&lt;!-- 日志处理 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;$&#123;slf4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- 邮箱另导 --&gt; 1-1.log4j.propertiesslf4j-api | slf4j-log4j :支持各种日志工具的平台(一般用log4j) log4j:log4j自己的日志工具 12345678910111213141516171819#DEBUG 模式 A3写出日志 STDOUT控制台输出 MAIL 输出到邮箱log4j.rootLogger=DEBUG,A3,STDOUT#控制台输出log4j.appender.STDOUT=org.apache.log4j.ConsoleAppenderlog4j.appender.STDOUT.layout=org.apache.log4j.PatternLayout#日志格式log4j.appender.STDOUT.layout.ConversionPattern=[%p] [%l] %10.10c - %m%n#日志写出 RollingFileAppender 持续写出log4j.appender.A3=org.apache.log4j.RollingFileAppender#日志名 server.loglog4j.appender.A3.file=logs/server.log#最大单个日志1024KB,超过则新建一个日志文件log4j.appender.A3.MaxFileSize=1024KB log4j.appender.A3.MaxBackupIndex=10log4j.appender.A3.layout=org.apache.log4j.PatternLayout#日志格式log4j.appender.A3.layout.ConversionPattern=\n\n[%-5p] %d&#123;yyyy-MM-dd HH\:mm\:ss,SSS&#125; method\:%l%n%m%n 1-2.GlobalExceptionResolver123456789101112131415161718192021222324252627282930313233343536import com.e3mall.search.mail.ErrorLogMail;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.web.servlet.HandlerExceptionResolver;import org.springframework.web.servlet.ModelAndView;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;/** * @author DonY15 * @description 全局异常处理器 * @create 2018\7\27 0027 */public class GlobalExceptionResolver implements HandlerExceptionResolver &#123; private static Logger logger=LoggerFactory.getLogger(GlobalExceptionResolver.class); @Override public ModelAndView resolveException(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) &#123; //1.打印控制台 ex.printStackTrace(); //2.写日志 logger.debug("测试日志:==================[debug]======================="); logger.info("系统发生异常了:==============[info]========================"); logger.error("系统发生异常:===============[error]=======================",ex); //3.发送邮件/短信(略)// ErrorLogMail.sendHtmlMail("邮箱异常检测:"+ex.toString()); //4.错误页面 ModelAndView modelAndView = new ModelAndView(); modelAndView.setViewName("error/exception"); return modelAndView; &#125;&#125; 1-3.ErrorLogMail(未生效)12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667/** * @author DonY15 * @description * @create 2018\7\27 0027 */import org.springframework.mail.MailException;import org.springframework.mail.javamail.JavaMailSenderImpl;import org.springframework.mail.javamail.MimeMessageHelper;import javax.mail.MessagingException;import javax.mail.internet.MimeMessage;import java.io.UnsupportedEncodingException;import java.util.Properties;public class ErrorLogMail &#123; private static final String HOST = "smtp.163.com"; private static final Integer PORT = 25; private static final String USERNAME = "625432639@163.com"; private static final String PASSWORD = "68835230ZZ"; private static final String EMAILFORM = "625432639@163.com"; private static JavaMailSenderImpl mailSender = createMailSender(); /** * 邮件发送器 * * @return 配置好的工具 */ private static JavaMailSenderImpl createMailSender() &#123; JavaMailSenderImpl sender = new JavaMailSenderImpl(); sender.setHost(HOST); sender.setPort(PORT); sender.setUsername(USERNAME); sender.setPassword(PASSWORD); sender.setDefaultEncoding("Utf-8"); Properties p = new Properties(); p.setProperty("mail.smtp.timeout", "25000"); p.setProperty("mail.smtp.auth", "false"); sender.setJavaMailProperties(p); return sender; &#125; /** * 发送邮件 * * @param html 发送内容 * @throws MessagingException 异常 * @throws UnsupportedEncodingException 异常 */ public static void sendHtmlMail(String html) &#123; try &#123; MimeMessage mimeMessage = mailSender.createMimeMessage(); // 设置utf-8或GBK编码，否则邮件会有乱码 MimeMessageHelper messageHelper = new MimeMessageHelper(mimeMessage, true, "UTF-8"); messageHelper.setFrom(EMAILFORM, "DonY15"); messageHelper.setTo("625432639@qq.com"); messageHelper.setSubject("ErrorLog"); messageHelper.setText(html, true); mailSender.send(mimeMessage); &#125; catch (MessagingException e) &#123; e.printStackTrace(); &#125; catch (UnsupportedEncodingException e) &#123; e.printStackTrace(); &#125; catch (MailException e) &#123; e.printStackTrace(); &#125; &#125;&#125;]]></content>
      <categories>
        <category>组件</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[javaSE-java优点]]></title>
    <url>%2F2017%2F07%2F05%2Fjava%E5%9F%BA%E7%A1%80SE-java%E4%BC%98%E7%82%B9%2F</url>
    <content type="text"><![CDATA[javaSE-java优点[TOC] 1.面向对象1-1.封装将复杂的数据封装起来,预留一个简单的接口, 使用者通过这个接口来使用. 封装能简化对象使用的同时能提高该对象的安全性 1-2.继承1-2-1.继承的概念 继承可以实现功能的扩展,提高复用性,简化开发 java支持单继承不支持多继承 构造器和private定义的属性/方法不能被继承(super可以调用父类方法和属性/构造) 1-2-2.继承中初始化顺序首先是类的结构:属性(类属性和实例属性) / 方法(类方法和实例方法) / 构造 / 初始化块(静态初始化块 / 实例初始化块)(假设代码块都包含) 类初始化阶段 在类加载机制的准备阶段,为所有的类属性和初始化块分配内存空间, 在类加载机制首次的初始化阶段进行初始化(如果该类有父类,则先为其父类初始化类属性和初始化代码块,一直往上追溯到Object最先执行,一个递归的过程) 对象初始化阶段 new构建对象时,先为对象的属性和初始化块分配内存,并按照顺序执行默认的初始化块, 如果存在父类,则先为父类对象的属性和初始化块分配空间,并按照顺序执行默认的初始化块,构造程序. 1-3.多态1-3-3.存在继承中1-3-2.父类引用指向子类对象1-3-3.子类重写父类方法多态基础提高https://www.cnblogs.com/chenssy/p/3372798.html 虚方法和非虚方法 静态类型和实际类型 静态分派和动态分派 …↓ 底层多态机制https://www.cnblogs.com/tsiangleo/p/4415628.html 1-4.抽象根据需求,抽象出合理的类 2.跨平台一次编译处处运行 跨平台原理 .java文件编译生成.class文件后,可以在不同系统的’JVM’上运行, JVM负责与系统底层交互 3.较好的安全性和稳定性3-1.安全性 内存需要通过对象实例的方式访问,防止’特洛伊’木马等欺骗手段访问对象的私有成员 禁止运行时堆栈溢出(防止蠕虫病毒) 禁止在自己处理空间外破坏内存 未经授权禁止读写文件 … 3-2.稳定性即鲁棒性(Robust ):健壮性 在异常情况下,系统生存的关键. 编译期和运行期检测异常.异常处理功能 GC垃圾回收机制 真数组,防止覆盖.通过下标0能顺序访问随后的元素 强类型机制 …. 4.支持Web开发5.GC机制6.完善的异常机制7.丰富的类库,去指针化]]></content>
      <categories>
        <category>SE基础</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[java-IO]]></title>
    <url>%2F2017%2F06%2F02%2Fjava-IO%2F</url>
    <content type="text"><![CDATA[1.文件上传方案一CommonsMultipartFile CommonsMultipartFile常用方法通过spring管理后实现文件上传,具体过程百度很多,如下 https://www.2cto.com/kf/201412/360788.html https://www.cnblogs.com/liaohongbin/p/7904536.html 较为完整的原生上传下载 https://blog.csdn.net/madun/article/details/8001266]]></content>
      <categories>
        <category>IO</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[javaSE-接口&抽象类]]></title>
    <url>%2F2017%2F05%2F23%2FjavaSE-%E6%8E%A5%E5%8F%A3%26%E6%8A%BD%E8%B1%A1%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[javaSE-接口&amp;抽象类1.接口和抽象类的异同1-1.interface &amp;&amp; abstract class不能实例化 抽象类和接口都不能够实例化，但可以定义抽象类和接口类型的引用。 抽象方法 有抽象方法的类必须被声明为抽象类或者接口，而抽象类未必要有抽象方法。 继承和实现 接口的实现类可以被直接实现多个接口,抽象类的子类只能被直接继承一个抽象类 一个类如果继承了某个抽象类或者实现了某个接口都需要对其中的抽象方法全部进行实现，否则该类仍然需要被声明为抽象类。 抽象 接口比抽象类更加抽象，因为抽象类中可以定义构造器，可以有抽象方法和具体方法，而接口中不能定义构造器而且在1.8以前的的方法全部都是抽象方法。 访问限定 抽象类中的成员可以是private、默认、protected、public的，而接口中的成员都是public的。 属性 抽象类中可以定义成员变量，而接口中定义的成员变量实际上都是常量。 1-2.注意!接口在1.8以后新特性:default 可以定义default 普通实现方法(可以被继承,但是同时实现两个同样default接口时,default必须被重写) 如果子类继承父类，父类中有b方法，该子类同时实现的接口中也有b方法（被default修饰），那么子类会继承父类的b方法而不是继承接口中的b方法 使用接口中类型时，仅仅需要实现抽象方法，default、static方法不需要强制自己实现类去再次实现 非default、static方法不能有实现，否则编译错误：Abstract methods do not specify a body default、static方法必须有具体的实现，否则编译错误：This method requires a body instead of a semicolon 可以拥有多个default方法 可以拥有多个static方法 staticjava8中为接口新增了一项功能：定义一个或者更多个静态方法。 类似于类中的静态方法，接口定义的静态方法可以独立于任何对象调用。 所以，在调用静态方法时，不需要实现接口，也不需要接口的实例，也就是说和调用类的静态方法的方式类似。 语法如：接口名字.静态方法名。 注意，实现接口的类或者子接口不会继承接口中的静态方法.]]></content>
      <categories>
        <category>SE基础</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[IDEA整合Git基础]]></title>
    <url>%2F2017%2F05%2F06%2FIDEA%E6%95%B4%E5%90%88Git%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[IDEA整合Git基础]]></content>
      <categories>
        <category>框架</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Git回顾]]></title>
    <url>%2F2017%2F05%2F06%2FGit%E5%9B%9E%E9%A1%BE%2F</url>
    <content type="text"><![CDATA[Git回顾[TOC] 小总结1234567891011[分支管理]git branch 查看分支git branch &lt;name&gt; 创建分支git checkout &lt;name&gt; 切换分支git checkout -b &lt;name&gt; 创建并切换分支git branch -d &lt;name&gt; 删除分支$ git merge --no-ff -m &quot;合并信息&quot; dev03 快速合并并保留合并记录--no-ff[提交&amp;&amp;克隆]$ git push -u origin master push到远方$ git clone https://github.com/dony15/Evolution.git clone到本地 1.IDEA整合Git使用1-1. 在本机指定的地方,用来git命令clone远程代码(首次即可) 1-2.安装好git,添加Git的启动文件到IDEA 1-3.用IDEA打开clone代码,并重新标记 1-4.此时运行代码,提示没有指定编译路径的信息(随便创建一个out之类的文件夹) 1-5.点击ok,将编译路径指向该文件夹,即可运行 [SUCCESS]此时代码拉取的基础操作我们就已经完成了 1-6.Idea中用Git管理代码的各种操作 (注意上图误区,并非只提交SRC即可,手误) 关于提交内容,根据具体业务,像 源,依赖配置信息,资源,依赖工程,引用jar文件,配置文件等一般需要上传 而开发工具配置信息,运行编译文件等不需要上传 2.简单的流程回顾创建一个版本库 2-1.创建仓库A)选择一个合适的地方，创建一个空目录： 1234567-----------------[Instruction]------------------$ mkdir learngit$ cd learngit$ pwd-------------------[Prompt]--------------------/Users/michael/learngit B)通过git init命令把这个目录变成Git可以管理的仓库：(初始化) 12345-----------------[Instruction]------------------$ git init-------------------[Prompt]--------------------Initialized empty Git repository in /Users/michael/learngit/.git/ 如果你没有看到.git目录，那是因为这个目录默认是隐藏的，用ls -ah命令就可以看见。 2-2.上传到仓库A)添加文件到仓库(实例readme.txt)(存放位置learngit(或者子目录下)) 1$ git add readme.txt //添加到到本地暂存区 B)完成上传 1234567-----------------[Instruction]------------------$ git commit -m &quot;read a new file&quot; //把暂存区的内容提交到当前本地分支-------------------[Prompt]--------------------[master (root-commit) aca27e4] read a new file 1 file changed, 1 insertion(+) create mode 100644 readme.txt 一个文件被改动,插入一行记录 总结AB上传示例 123$ git add file1.txt$ git add file2.txt file3.txt$ git commit -m &quot;add 3 files.&quot; 使用命令git add &lt;file&gt;，可反复多次使用，添加多个文件 使用命令git commit -m &lt;message&gt;，完成上传 2-3.查看工作区内容A)查看工作区被修改的文件(为了测试,提前修改未添加和提交) 12345678910111213-----------------[Instruction]------------------$ git status-------------------[Prompt]--------------------On branch masterChanges not staged for commit: //修改了尚未提交的内容 (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) //使用add添加要更新的内容 (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) //使用checkout --放弃对文件的修改 modified: readme.txt //修改文件 readme.txtno changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;)//没有为提交添加任何更改(使用“git添加”和/或“git commit -a”) B)查看详细的更改内容 123456789101112131415-----------------[Instruction]------------------$ git diff readme.txt-------------------[Prompt]--------------------diff --git a/readme.txt b/readme.txt index c2ed1e8..90f0f33 100644--- a/readme.txt+++ b/readme.txt@@ -1 +1,3 @@-Hello Word\ No newline at end of file+This This command is to update the file.+This is the second update.+This is the last update record.\ No newline at end of file C)查看后重新上传到仓库 12345678910111213141516-----------------[Instruction]------------------$ git add readme.txt-----------------[Instruction]------------------$ git commit -m &quot;add new readme&quot;-------------------[Prompt]--------------------[master 62c622f] add new readme 1 file changed, 3 insertions(+), 1 deletion(-)-----------------[Instruction]------------------$ git status-------------------[Prompt]--------------------On branch masternothing to commit, working tree clean //此时没有未提交的数据了和修改的 2-4.版本回退再次对readme.txt进行修改后测试 A)添加提交 123456789-----------------[Instruction]------------------$ git add readme.txt-----------------[Instruction]------------------$ git commit -m &quot;The third test is on&quot;-------------------[Prompt]--------------------[master 03b3138] The third test is on 1 file changed, 2 insertions(+), 3 deletions(-) B)查看详细更新日志 123456789101112131415161718192021-----------------[Instruction]------------------$ git log-------------------[Prompt]--------------------commit 03b3138b888b688ea429ccd860c5e84a3db4efa2 //commit id（版本号）,使用sha-1生成16进制防冲突Author: DonY15 &lt;37318228+625432639@users.noreply.github.com&gt; //作者Date: Thu Aug 9 19:59:10 2018 +0800 //更新时间 The third test is on //-m 后的更新提醒commit 62c622fc4d32bd081a5f0ea80bc501b9a97c3079Author: DonY15 &lt;37318228+625432639@users.noreply.github.com&gt;Date: Thu Aug 9 19:53:04 2018 +0800 add new readmecommit aca27e458ca3aa8492778bca7ab125815ddbbd5eAuthor: DonY15 &lt;37318228+625432639@users.noreply.github.com&gt;Date: Thu Aug 9 19:24:19 2018 +0800 read a new file C)如果详细更新日志过于繁琐,可以查看精简版 1234567-----------------[Instruction]------------------$ git log --pretty=oneline-------------------[Prompt]--------------------03b3138b888b688ea429ccd860c5e84a3db4efa2 The third test is on //这是-m 后面的更新提示,倒序展示62c622fc4d32bd081a5f0ea80bc501b9a97c3079 add new readmeaca27e458ca3aa8492778bca7ab125815ddbbd5e read a new file D)开始版本退回! git reset 重置命令 12345-----------------[Instruction]------------------$ git reset --hard HEAD^-------------------[Prompt]--------------------HEAD is now at 62c622f add new readme 注意 HEAD是表示当前的版本,也就是最新提交的版本, 上一个版本就是HEAD^ 上上个版本是HEAD^^ 当版本多时,可以用HEAD~100 来退回到100个版本以前 查看该文件,此时已经退回到上个版本 1234567-----------------[Instruction]------------------$ cat readme.txt-------------------[Prompt]--------------------This This command is to update the file.This is the second update.This is the last update record. 2-5.版本前进版本回退后将不显示最新的版本 可以通过重置指令再回到最新版本 A)前提是git窗口没有关闭,且能找到之前最新的commit id 12345-----------------[Instruction]------------------$ git reset --hard 03b3138b888b688ea429ccd860c5e84a3db4efa2 //id可以不用写完整,写到不重复即可-------------------[Prompt]--------------------HEAD is now at 03b3138 The third test is on 此时版本已经前进到指定的新版本了 B)当无法再当前窗口找到commit id时,如第二天以后 123456789-----------------[Instruction]------------------$ git reflog 查看指令历史-------------------[Prompt]--------------------03b3138 HEAD@&#123;0&#125;: reset: moving to 03b3138b888b688ea429ccd860c5e84a3db4efa262c622f HEAD@&#123;1&#125;: reset: moving to HEAD^03b3138 HEAD@&#123;2&#125;: commit: The third test is on62c622f HEAD@&#123;3&#125;: commit: add new readmeaca27e4 HEAD@&#123;4&#125;: commit (initial): read a new file 通过此方法也可以查到commit id 前缀,通过前缀即可查找到指定版本 2-51.工作区和暂存区概念测试 A)对readme.txt修改,创建LICENSE (对比两种状态) 12345678910111213141516171819202122-----------------[Instruction]------------------//创建一个文本文件,写点东西$ vim LICENSE-----------------[Instruction]------------------//查看状态$ git status-------------------[Prompt]--------------------On branch masterChanges not staged for commit: (use &quot;git add &lt;file&gt;...&quot; to update what will be committed) (use &quot;git checkout -- &lt;file&gt;...&quot; to discard changes in working directory) modified: readme.txtUntracked files: (use &quot;git add &lt;file&gt;...&quot; to include in what will be committed) LICENSEno changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;) 此时提醒,readme的修改状态已经被管理检测到修改,但是没有添加到暂存区 而LICENSE则属于Untracked状态,从来没有被add添加过 B)执行两次add添加到暂存区 &amp;&amp; 执行commit命令将暂存区内容上传到当前本地分支 123456789-----------------[Instruction]------------------$ git add readme.txt$ git add LICENSE$ git commit -m &quot;The staging area to the workspace&quot;-------------------[Prompt]--------------------[master 13853f9] The staging area to the workspace 2 files changed, 2 insertions(+), 2 deletions(-) create mode 100644 LICENSE 所以，git add命令实际上就是把要提交的所有修改放到暂存区（Stage），然后，执行git commit就可以一次性把暂存区的所有修改提交到分支。 C)执行git status再次查看工作区修改状态 123456-----------------[Instruction]------------------$ git status-------------------[Prompt]--------------------On branch masternothing to commit, working tree clean 一旦提交后，如果你又没有对工作区做任何修改，那么工作区就是“干净”的 2-6.Git的跟踪修改每次修改，如果不用git add到暂存区，那就不会加入到commit中,如: 第一次修改readme.txt 第一次add readme.txt 第二次修改readme.txt commit提交 此时,第二次的修改便不会生效,如果想生效,继续add readme.txt再commit提交即可 正常情况下也可以这样操作: 第一次修改readme.txt 第二次修改readme.txt 第一次add readme.txt commit提交 所有的数据则会被提交到本地分支 1-7.Git的修改 当你改乱了工作区某个文件的内容，想直接丢弃工作区的修改时，用命令git checkout -- file。 当你不但改乱了工作区某个文件的内容，还添加到了暂存区时，想丢弃修改，分两步， 第一步用命令git reset HEAD &lt;file&gt;，就回到了1， 第二步按1操作。 已经提交了不合适的修改到版本库时，想要撤销本次提交，参考版本回退，不过前提是没有推送到远程库。 2-8.删除文件命令git rm用于删除一个文件。如果一个文件已经被提交到版本库，那么你永远不用担心误删，但是要小心，你只能恢复文件到最新版本，你会丢失最近一次提交后你修改的内容。 3.远程仓库操作3-1.搭建远程仓库通道A)创建SSH Key 1$ ssh-keygen -t rsa -C &quot;youremail@example.com&quot; B)GitHub添加公钥 3-2.创建/关联远程仓库A)GitHub上创建一个仓库(略) B)关联这个远程仓库(需要输入账号和密码) 1$ git remote add origin https://github.com/dony15/Evolution.git origin 是默认远程仓库的意思,可以修改 C)首次推送远端需要加-u 123456789101112131415-----------------[Instruction]------------------$ git push -u origin master-------------------[Prompt]--------------------Fatal: HttpRequestException encountered.Username for &apos;https://github.com&apos;: 625432639@qq.comCounting objects: 13, done.Delta compression using up to 8 threads.Compressing objects: 100% (6/6), done.Writing objects: 100% (13/13), 1.06 KiB | 0 bytes/s, done.Total 13 (delta 1), reused 0 (delta 0)remote: Resolving deltas: 100% (1/1), done.To https://github.com/dony15/Evolution.git * [new branch] master -&gt; masterBranch master set up to track remote branch master from origin. 以后推送这样就可以 1$ git push origin master 3-3.克隆到本地12345678910111213141516-----------------[Instruction]------------------$ git clone https://github.com/dony15/Evolution.git-------------------[Prompt]--------------------Cloning into &apos;Evolution&apos;...remote: Counting objects: 13, done.remote: Compressing objects: 100% (5/5), done.remote: Total 13 (delta 1), reused 13 (delta 1), pack-reused 0Unpacking objects: 100% (13/13), done.-----------------[Instruction]------------------$ cd Evolution/$ ls-------------------[Prompt]--------------------LICENSE readme.txt 4.分支操作管理1234567891011查看分支：git branch创建分支：git branch &lt;name&gt;切换分支：git checkout &lt;name&gt;创建+切换分支：git checkout -b &lt;name&gt;合并某分支到当前分支：git merge &lt;name&gt;删除分支：git branch -d &lt;name&gt; 5.解决分支冲突A)测试创建分支dev02,并修改提交readme.txt 12345678910111213141516171819202122-----------------[Instruction]------------------$ git checkout -b dev02 //创建并切换到dev02分支上-------------------[Prompt]--------------------Switched to a new branch &apos;dev02&apos;-----------------[Instruction]------------------$ git branch //查看分支-------------------[Prompt]-------------------- dev01* dev02 //此时使用分支已经切换到dev02 master-----------------[Instruction]------------------$ git add readme.txt $ git commit -m &quot;add Branch file A&quot; //修改readme.txt后提交-------------------[Prompt]--------------------[dev02 2a625ef] add chongtu 1 file changed, 2 insertions(+), 1 deletion(-) B)master中修改提交readme.txt 1234567-----------------[Instruction]------------------$ git add readme.txt$ git commit -m &quot;add Principal branch of conflict&quot;-------------------[Prompt]--------------------[master 59dea59] add Principal branch of conflict 1 file changed, 2 insertions(+), 1 deletion(-) C)合并分支和master的代码$ git merge dev02 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051-----------------[Instruction]------------------$ git merge dev02 //git的快速合并命令-------------------[Prompt]--------------------Auto-merging readme.txtCONFLICT (content): Merge conflict in readme.txt //提示readme.txt合并冲突Automatic merge failed; fix conflicts and then commit the result. //自动合并失败;修复冲突，然后提交结果。-----------------[Instruction]------------------$ git status //使用查看状态来查看详细问题-------------------[Prompt]--------------------On branch masterYour branch is ahead of &apos;origin/master&apos; by 1 commit. (use &quot;git push&quot; to publish your local commits)You have unmerged paths. (fix conflicts and run &quot;git commit&quot;) (use &quot;git merge --abort&quot; to abort the merge)Unmerged paths: (use &quot;git add &lt;file&gt;...&quot; to mark resolution) both modified: readme.txtno changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;)-----------------[Instruction]------------------$ git diff readme.txt //查看详细分支修改内容-------------------[Prompt]--------------------diff --cc readme.txtindex 6b4e414,73c648e..0000000--- a/readme.txt+++ b/readme.txt@@@ -1,2 -1,2 +1,6 @@@ Workspaces and staging areas- 合并分支测试-主分支 -测试分支,解决分支冲突问题++&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD //master的修改内容++合并分支测试-主分支++======= //分割线的++测试分支,解决分支冲突问题 ++&gt;&gt;&gt;&gt;&gt;&gt;&gt; dev02 //dev02的修改内容-------------------[Prompt]--------------------注意此时本地文件readme.txt中的内容也为改成响应的两套Workspaces and staging areas&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEAD合并分支测试-主分支=======测试分支,解决分支冲突问题&gt;&gt;&gt;&gt;&gt;&gt;&gt; dev02 这种情况下git无法使用git merge进行快速合并,则出现冲突问题 D)删除指定的冲突后提交 123456-----------------[Instruction]------------------$ git add readme.txt$ git commit -m &quot;第二次合并&quot;-------------------[Prompt]--------------------[master ae51c0e] 第二次合并 //此时冲突文件即可进行合并 E)查看时间轴$ git log --graph --pretty=oneline --abbrev-commit 12345678910111213-----------------[Instruction]------------------$ git log --graph --pretty=oneline --abbrev-commit-------------------[Prompt]--------------------* ae51c0e 第二次合并|\| * 2a625ef add chongtu* | 59dea59 add Principal branch of conflict|/* 13853f9 The staging area to the workspace* 03b3138 The third test is on* 62c622f add new readme* aca27e4 read a new file F)最后合并完,删除分支即可 12345-----------------[Instruction]------------------$ git branch -d dev02 //删除分支-------------------[Prompt]--------------------Deleted branch dev02 (was 2a625ef). 6.分支管理策略使用–no-ff 合并后的历史有分支，能看出来曾经做过合并，而fast forward合并就看不出来曾经做过合并。 1234567891011121314151617181920212223-----------------[Instruction]------------------$ git checkout -b dev03$ git add readme.txt //注意添加的是新修改的readme.txt 如果未修改则无法commit提交哦$ git commit -m &quot;add readme.txt to dev03&quot;$ git checkout master //切换回主分支$ git merge --no-ff -m &quot;merge with no-ff&quot; dev03 //合并分支$ git log --graph --pretty=oneline --abbrev-commit //查看分支详细流程日志-------------------[Prompt]--------------------* c7562a6 merge with no-ff|\| * 1a027fc add merge 2|/* ae51c0e 第二次合并|\| * 2a625ef add chongtu* | 59dea59 add Principal branch of conflict|/* 13853f9 The staging area to the workspace* 03b3138 The third test is on* 62c622f add new readme* aca27e4 read a new file 7.多人协作流程回顾(待更新) 8.标签管理(待更新) 9.自定义Git(待更新)]]></content>
      <categories>
        <category>框架</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[jQuery基础(实用部分)整理]]></title>
    <url>%2F2017%2F04%2F17%2FjQuery%E5%9F%BA%E7%A1%80(%E5%AE%9E%E7%94%A8%E9%83%A8%E5%88%86)%E6%95%B4%E7%90%86%2F</url>
    <content type="text"><![CDATA[jQuery基础(实用部分)整理[TOC] 1.选择器1-1基础选择器 ID选择器$(“#id”) 标签选择器$(“input”) 类选择器$(“.test”) 通配符选择器$(“*”) 组选择器(“#id,input,.test”) … 1-2层级选择器 包含选择器$(“div input”) 子类选择器$(“div &gt; input”) 相邻选择器$(“input+button”) input后面的一个button生效 兄弟选择器$(“input~button”) input后面的同级都生效 1-3属性选择器属性选择器$(“input[value=’小黑’]”) 1-4伪类选择器 $(“p:first”) 第一个p标签 $(“p:last”) 最后一个p标签 $(“p:eq(0)”) 第0个下标的p标签 $(“p:even”) 偶数行的p标签 $(“p:odd”) 奇数行的p标签 …(很多) 2.jQuery元素操作var aa=$(“#aaa”); 值/属性/样式 aa.val() 获得aa的value属性值 aa.val(“aaaaa”) 设置aa的value值 aa.attr(“xxx”) 获取aa的xxx属性的值 aa.attr(“xxx”,”yyy”) 设置aa的xxx属性的值为yyy aa.removeAttr(“xxx”) 移除aa的xxx属性 aa.css(“xxx”) 读取css样式xxx aa.css(“xxx”,”red”) 设置css样式xxx aa.css(“xxx”,””) 清空css样式xxx var bb=$(“#bbb”);标签文本/纯文本 bb.html() 获得bb的子节点内容 bb.html(“bbbbb“) 设置bb的子节点内容 bb.text() 获取bb内纯文本内容 bb.text(“bobobobo”) 设置bb内纯文本内容 var cc=$(“#ccc”);class的操作 cc.addClass(“ccc”) 设置cc的class为ccc cc.removeClass(“ccc”) 移除cc的class,ccc cc.hasClass(“ccc”) 判断cc是否拥有ccc这个Class cc.remove() 移除cc元素 cc.is(“cc”)判断是否有cc这个选择器型?? before prepend append after 追加位置 3.jQuery动画隐藏显示 ​ hide() show() 淡入淡出 ​ fadeIn() fadeOut() 纵向显示消失 ​ slideDown() slideUp() 开关显示隐藏 ​ toggle() 4.事件 click :点击事件 dbclick:双击事件 mouseover:鼠标移入 mouseleave:鼠标移出 change:输入改变 keydown:键盘按下 keyup:键盘弹起 focus:获得焦点 blur:失去焦点 5.jQuery和Dom转换123dom转jQuery $(dom)jQuery转dom $(jquery).get(0) 或者$(jquery)[0] 注意:jQuery中没有null,如果不存在,则显示长度为0的Object;;dom中如果不存在,则显示null 6.工具6-1 each遍历123456789101112131415161718$(function()&#123; //index 是当前元素的索引 //obj是dom对象 $(&quot;input&quot;).each(function(index,obj)&#123; $(obj).bind(&apos;click&apos;,function()&#123; //当前节点的指定祖父节点中,find寻找td子类, //该td子类指定伪类选择器为eq即第1个td, //结合子类选择器,找第一个td中的子类a即可 //var a= $(this).parents(&quot;tr&quot;).find(&quot;td:eq(0)&gt;a&quot;); var td= $(this).parents(&quot;tr&quot;).find(&quot;td:eq(0)&quot;); var te=$(&quot;td&gt;a&quot;).text(); var res=&quot;&lt;input type=&apos;text&apos; value=&apos;&quot;+te+&quot;&apos;/&gt;&quot;; td.html(res); &#125;) &#125;) &#125;)]]></content>
      <categories>
        <category>Web基础</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[GitHub 博客快速搭建]]></title>
    <url>%2F2017%2F03%2F02%2FGitHub%E5%8D%9A%E5%AE%A2%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[GitHub 博客快速搭建[TOC] 环境:Win7 搭建流程 Node.js | Hexo | Next(themes) 基础 首先安装Node.js 注意Path指定位置(影响到balabala一些配置的存放的位置,默认C盘,建议改) Node.js安装好后,选择一个文件夹安装Hexo(此处为搭建Blog的位置) 将GitHub账号的博客地址添加到Hexo的配置文件中(根目录 _config.yml),并将部署方式改为Git(老版本是GitHub方式) 根据指令部署后即可完成基础的博客搭建,此时查看博客仓库是否上传了静态资源(如果上传了则代表搭建成功) 短暂的延迟后进入博客网页即可看到搭建的博客 写博客的方式–&gt;将编写的md文章放在posts下,然后 hexo g d 部署一下即可(每次方式用这个指令就可以上传文章了,文章会被自适应解析) 参考https://www.cnblogs.com/fengxiongZz/p/7707219.html 进阶 Hexo中的themes是主题设定的位置,可以选择主题,教程中选择Next的基础主题(没有追求可以凑合用( • ̀ω•́ )✧) themes中的(_config.yml)是主题的配置,里面可以根据提示做自己的简单配置,包括菜单的增减和修改,布局等等,如下 123456789# Directorysource_dir: sourcepublic_dir: publictag_dir: tagsarchive_dir: archivescategory_dir: categoriescode_dir: downloads/codei18n_dir: :langskip_render: 根据教程和注释完成自己的布局即可 参考http://www.cnblogs.com/fengxiongZz/p/7707568.html 进阶加强 完成这些想玩点花的话可以去官网或者GitHub找喜欢的themes修改使用,教程百度一大堆( • ̀ω•́ )✧ 一大波官网主题:https://hexo.io/themes/ 第三方的插件口头整合 第三方登录(Github) 评论功能 站内搜索 站内统计 交互式背景 网易云播放器插件 将网站的所有图片通过url委托给第三方云图片服务器(七牛云存储10G免费) … 维护技巧 当不能保证在同一台电脑上传文章时,可以选择master分离的方式或者将博客部署在自己的远程服务器上]]></content>
      <categories>
        <category>搭建</category>
      </categories>
  </entry>
</search>
